{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rank_bm25 import BM25Okapi\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import Literal, Optional, TypedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLCiteDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    create dataset\n",
    "    - init\n",
    "    - len\n",
    "    - getitem\n",
    "    '''\n",
    "    def __init__(self, texts: list[str]):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 30 02:16:29 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           On  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              22W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           On  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              35W / 250W |  15878MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_size::: 2690\n",
      "test_data_size::: 299\n"
     ]
    }
   ],
   "source": [
    "csv_dataset = pd.read_csv(\"/data/group1/z40436a/ME/URL_Citation_Classification_Intermediate/data/all_data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "seed = 111 # fixed\n",
    "train_df, eval_df = train_test_split(csv_dataset, test_size = 0.1, random_state=seed)\n",
    "print(\"train_data_size:::\", len(train_df))\n",
    "print(\"test_data_size:::\", len(eval_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "CITE_TOKEN = \"[URL_CITE]\"\n",
    "\n",
    "def replace_tag(sentences: pd.Series) -> list[str]:\n",
    "    # replace [Cite_****] to [Cite] token\n",
    "    rule = re.compile(r'\\[Cite[^\\[\\] ]*\\]')\n",
    "    sentences_replaced:list[str] = list()\n",
    "    for sentence in sentences:\n",
    "        sentences_replaced.append(rule.sub(CITE_TOKEN, sentence))\n",
    "\n",
    "    return sentences_replaced\n",
    "\n",
    "def get_3sent(paragraphs:list[str]) -> list[str]:\n",
    "    ret:list[list[str]] = list()\n",
    "    for paragraph in paragraphs:\n",
    "        sentences: list[str] = nltk.sent_tokenize(paragraph)\n",
    "        if not len(sentences):\n",
    "            print('!!!')\n",
    "        if len(sentences) < 4:\n",
    "            ret.append(sentences)\n",
    "            continue\n",
    "        else:\n",
    "            for i in range(len(sentences)):\n",
    "                if CITE_TOKEN in sentences[i]:\n",
    "                    if i == 0:\n",
    "                        ret.append(sentences[i:i+2])\n",
    "                    elif i == len(sentences)-1:\n",
    "                        ret.append(sentences[i-1:i+1])\n",
    "                    else:\n",
    "                        ret.append(sentences[i-1:i+2])\n",
    "                    break\n",
    "                if i == len(sentences)-1:\n",
    "                    # print(sentences)\n",
    "                    pass\n",
    "    cont_3sent = [\" \".join(sent) for sent in ret]\n",
    "    return cont_3sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_icl(file_path:str) -> list[list[int]]:\n",
    "    '''\n",
    "    return icl_idx top-k (from left)\n",
    "    '''\n",
    "    icl_idxs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line == '\\n':\n",
    "                break\n",
    "            icl_idxs.append(json.loads(line))\n",
    "    return icl_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_path = f\"/data/group1/z40436a/ME/URL_Citation_Classification_Intermediate/icl/random/{str(seed)}.txt\"\n",
    "icl_idxs = read_icl(icl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inst(train_df:pd.DataFrame, test_df:pd.DataFrame, icl_method:str, k:int=5) -> list[str]:\n",
    "    texts: list[str] = []\n",
    "\n",
    "    icl_idxs = read_icl(f\"/data/group1/z40436a/ME/URL_Citation_Classification_Intermediate/icl/{icl_method}/{str(seed)}.txt\")\n",
    "    \n",
    "    train_replaced_sentences = replace_tag(train_df['citation-paragraph'])\n",
    "    train_conts = get_3sent(train_replaced_sentences)\n",
    "\n",
    "    test_replaced_sentences = replace_tag(test_df['citation-paragraph'])\n",
    "    test_conts = get_3sent(test_replaced_sentences)\n",
    "\n",
    "    for test_cont, (i, row) in zip(test_conts, test_df.iterrows()):\n",
    "        reset_idx = 0\n",
    "        instruction = [\n",
    "            {\"role\":\"System\", \"content\": f\"\"\"Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\\n\n",
    "Here is the classification schema for the artifact type:\n",
    "1. Tool: toolkit, software, system\n",
    "2. Code: codebase, library, API\n",
    "3. Dataset: corpus, image, sets\n",
    "4. Knowledge: lexicon, knowledge graph\n",
    "5. DataSource: source data for the Dataset/Knowledge\n",
    "6. Document: specifications, guidelines\n",
    "7. Paper: scholarly papers\n",
    "8. Media: games, music, videos\n",
    "9. Website: services, homepages\n",
    "10. Mixed: citations referring to multiple resources\n",
    "    \n",
    "Here is the classification schema for the citation reason:\n",
    "1. Use: Used in the citing paper’s research\n",
    "2. Produce: First produced or released by the citing paper’s research\n",
    "3. Compare: Compared with other resources\n",
    "4. Extend: Used in the citing paper’s research but are improved, upgraded, or changed during the research\n",
    "5. Introduce: The resources or the related information\n",
    "6. Other: The URL citation does not belong to the above categories\"\"\"}\n",
    "        ]\n",
    "\n",
    "        if k == 0:\n",
    "            pass\n",
    "        elif k > 0 and k <=5:\n",
    "            for top_k in range(k):\n",
    "                icl_idx = icl_idxs[reset_idx][top_k]\n",
    "                icl_df = train_df.iloc[icl_idx]\n",
    "                # print(icl_df)\n",
    "                icl_input = f\"\"\"Please classify the artifact type and the citation reason for the following URL and citation sentence.\n",
    "URL: {icl_df['url']}\n",
    "Citation Context: {train_conts[icl_idx]}\n",
    "Footnote or Reference text (if exists): {icl_df['citation-info']}\n",
    "Section Titles (if exists): {icl_df['passage-title']}\"\"\"\n",
    "                instruction.append({\"role\":\"user\", \"content\": icl_input})\n",
    "                instruction.append({\"role\":\"assistant\", \"content\": f\"\"\"TYPE: {icl_df['type']}\\nFUNCTION: {row['function'].split(\"（\")[0]}\"\"\"})\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "        test_input = f\"\"\"Please classify the artifact type and the citation reason for the following URL and citation sentence.\n",
    "URL: {row['url']}\n",
    "Citation Context: {test_cont}\n",
    "Footnote or Reference text (if exists): {row['citation-info']}\n",
    "Section Titles (if exists): {row['passage-title']}\"\"\"\n",
    "        instruction.append({\"user\": test_input})\n",
    "\n",
    "        reset_idx += 1\n",
    "\n",
    "        texts.append(instruction)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len is OK!, len is 299\n"
     ]
    }
   ],
   "source": [
    "### test_code create_inst\n",
    "k = 5\n",
    "random_icl = create_inst(train_df, eval_df, \"random\", k)\n",
    "bm25_icl = create_inst(train_df, eval_df, \"bm25\", k)\n",
    "encoder_icl = create_inst(train_df, eval_df, \"encoder\", k)\n",
    "\n",
    "if len(random_icl) == len(bm25_icl) == len(encoder_icl):\n",
    "    print(f\"len is OK!, len is {len(random_icl)}\")\n",
    "\n",
    "if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'System', 'content': 'Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\\n\\nHere is the classification schema for the artifact type:\\n1. Tool: toolkit, software, system\\n2. Code: codebase, library, API\\n3. Dataset: corpus, image, sets\\n4. Knowledge: lexicon, knowledge graph\\n5. DataSource: source data for the Dataset/Knowledge\\n6. Document: specifications, guidelines\\n7. Paper: scholarly papers\\n8. Media: games, music, videos\\n9. Website: services, homepages\\n10. Mixed: citations referring to multiple resources\\n    \\nHere is the classification schema for the citation reason:\\n1. Use: Used in the citing paper’s research\\n2. Produce: First produced or released by the citing paper’s research\\n3. Compare: Compared with other resources\\n4. Extend: Used in the citing paper’s research but are improved, upgraded, or changed during the research\\n5. Introduce: The resources or the related information\\n6. Other: The URL citation does not belong to the above categories'}, {'role': 'user', 'content': \"Please classify the artifact type and the citation reason for the following URL and citation sentence.\\nURL:  http://ufal.mff.cuni.cz/\\nCitation Context: Most of the labels [URL_CITE] are self-explanatory: Pa-tient (PAT), Actor (ACT), Time (TWHEN), Effect (EFF), Location (LOC), Manner (MANN), Ad-dressee (ADDR), Extent (EXT). CPHR marks the nominal part of a complex predicate, as in “to have [a plan] CPHR ”, and DIR3 indicates destination.\\nFootnote or Reference text (if exists): 2 http://ufal.mff.cuni.cz/ ∼ toman/pcedt/en/functors.html\\nSection Titles (if exists):  ['5 Results', '5.2 Argument Classification']\"}, {'role': 'assistant', 'content': 'TYPE: Knowledge\\nFUNCTION: Use'}, {'role': 'user', 'content': \"Please classify the artifact type and the citation reason for the following URL and citation sentence.\\nURL:  http://www.lpl.univ-\\nCitation Context: Multext-East References (Copernicus 106). [URL_CITE] http://www.lpl.univ-\\nFootnote or Reference text (if exists): nan\\nSection Titles (if exists):  ['3 The Methodology', '3.5 Handling Unknown Words']\"}, {'role': 'assistant', 'content': 'TYPE: Paper\\nFUNCTION: Use'}, {'role': 'user', 'content': \"Please classify the artifact type and the citation reason for the following URL and citation sentence.\\nURL:  http://www.aclweb.org/anthology/P16-1101\\nCitation Context: Recent work has explored neural network mod-els for supertagging in TAG (Kasai et al., 2017) and CCG (Xu et al., 2015; Lewis et al., 2016; Vaswani et al., 2016; Xu, 2016 [URL_CITE] ), and has shown that such models substantially improve perfor-mance beyond non-neural models. We extend pre-viously proposed BiLSTM-based models (Lewis et al., 2016; Kasai et al., 2017) in three ways: 1) we add character-level Convolutional Neural Net-works (CNNs) to the input layer, 2) we perform concatenation of both directions of the LSTM not only after the final layer but also after each layer, and 3) we use a modified BiLSTM with highway connections.\\nFootnote or Reference text (if exists): Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. In ACL. Association for Computational Linguistics, Berlin, Germany, pages 1064–1074. http://www.aclweb.org/anthology/P16-1101.\\nSection Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model']\"}, {'role': 'assistant', 'content': 'TYPE: Paper\\nFUNCTION: Use'}, {'role': 'user', 'content': \"Please classify the artifact type and the citation reason for the following URL and citation sentence.\\nURL:  https://writing.wisc.edu/Handbook/Transitions.html\\nCitation Context: The first set of features that we use are length and count-based features, such as word length, word count, sentence length, count of transition phrases [URL_CITE] etc. (Persing and Ng, 2015; Zesch et al., 2015).\\nFootnote or Reference text (if exists): 6 https://writing.wisc.edu/Handbook/Transitions.html\\nSection Titles (if exists):  ['4 Features', '4.1 Text-based Features']\"}, {'role': 'assistant', 'content': 'TYPE: Document\\nFUNCTION: Use'}, {'role': 'user', 'content': \"Please classify the artifact type and the citation reason for the following URL and citation sentence.\\nURL:  http://www.verify-sy.com\\nCitation Context: Claim Extraction We consider two websites as the source of our claims. V ERIFY [URL_CITE] is a project that was established to expose false claims made about the war in Syria and other related Middle Eastern issues. It is an independent platform that debunks claims made by all parties to the conflict.\\nFootnote or Reference text (if exists): 4 http://www.verify-sy.com\\nSection Titles (if exists):  ['3 The Corpus']\"}, {'role': 'assistant', 'content': 'TYPE: Website\\nFUNCTION: Use'}, {'user': \"Please classify the artifact type and the citation reason for the following URL and citation sentence.\\nURL:  https://github.com/salaniz/pycocoevalcap\\nCitation Context: We use implementations of BLEU, METEOR, and ROUGE using Microsoft MS COCO evaluation scripts [URL_CITE] . We removed question marks, periods, and exclamation marks from references and candi-dates when evaluating with BLEU, METEOR, and ROUGE.\\nFootnote or Reference text (if exists): 4 https://github.com/salaniz/pycocoevalcap\\nSection Titles (if exists):  ['B Details on Baselines']\"}]\n",
      "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n",
      "\n",
      "Here is the classification schema for the artifact type:\n",
      "1. Tool: toolkit, software, system\n",
      "2. Code: codebase, library, API\n",
      "3. Dataset: corpus, image, sets\n",
      "4. Knowledge: lexicon, knowledge graph\n",
      "5. DataSource: source data for the Dataset/Knowledge\n",
      "6. Document: specifications, guidelines\n",
      "7. Paper: scholarly papers\n",
      "8. Media: games, music, videos\n",
      "9. Website: services, homepages\n",
      "10. Mixed: citations referring to multiple resources\n",
      "    \n",
      "Here is the classification schema for the citation reason:\n",
      "1. Use: Used in the citing paper’s research\n",
      "2. Produce: First produced or released by the citing paper’s research\n",
      "3. Compare: Compared with other resources\n",
      "4. Extend: Used in the citing paper’s research but are improved, upgraded, or changed during the research\n",
      "5. Introduce: The resources or the related information\n",
      "6. Other: The URL citation does not belong to the above categories\n",
      "Please classify the artifact type and the citation reason for the following URL and citation sentence.\n",
      "URL:  http://ufal.mff.cuni.cz/\n",
      "Citation Context: Most of the labels [URL_CITE] are self-explanatory: Pa-tient (PAT), Actor (ACT), Time (TWHEN), Effect (EFF), Location (LOC), Manner (MANN), Ad-dressee (ADDR), Extent (EXT). CPHR marks the nominal part of a complex predicate, as in “to have [a plan] CPHR ”, and DIR3 indicates destination.\n",
      "Footnote or Reference text (if exists): 2 http://ufal.mff.cuni.cz/ ∼ toman/pcedt/en/functors.html\n",
      "Section Titles (if exists):  ['5 Results', '5.2 Argument Classification']\n",
      "TYPE: Knowledge\n",
      "FUNCTION: Use\n",
      "Please classify the artifact type and the citation reason for the following URL and citation sentence.\n",
      "URL:  http://www.lpl.univ-\n",
      "Citation Context: Multext-East References (Copernicus 106). [URL_CITE] http://www.lpl.univ-\n",
      "Footnote or Reference text (if exists): nan\n",
      "Section Titles (if exists):  ['3 The Methodology', '3.5 Handling Unknown Words']\n",
      "TYPE: Paper\n",
      "FUNCTION: Use\n",
      "Please classify the artifact type and the citation reason for the following URL and citation sentence.\n",
      "URL:  http://www.aclweb.org/anthology/P16-1101\n",
      "Citation Context: Recent work has explored neural network mod-els for supertagging in TAG (Kasai et al., 2017) and CCG (Xu et al., 2015; Lewis et al., 2016; Vaswani et al., 2016; Xu, 2016 [URL_CITE] ), and has shown that such models substantially improve perfor-mance beyond non-neural models. We extend pre-viously proposed BiLSTM-based models (Lewis et al., 2016; Kasai et al., 2017) in three ways: 1) we add character-level Convolutional Neural Net-works (CNNs) to the input layer, 2) we perform concatenation of both directions of the LSTM not only after the final layer but also after each layer, and 3) we use a modified BiLSTM with highway connections.\n",
      "Footnote or Reference text (if exists): Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. In ACL. Association for Computational Linguistics, Berlin, Germany, pages 1064–1074. http://www.aclweb.org/anthology/P16-1101.\n",
      "Section Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model']\n",
      "TYPE: Paper\n",
      "FUNCTION: Use\n",
      "Please classify the artifact type and the citation reason for the following URL and citation sentence.\n",
      "URL:  https://writing.wisc.edu/Handbook/Transitions.html\n",
      "Citation Context: The first set of features that we use are length and count-based features, such as word length, word count, sentence length, count of transition phrases [URL_CITE] etc. (Persing and Ng, 2015; Zesch et al., 2015).\n",
      "Footnote or Reference text (if exists): 6 https://writing.wisc.edu/Handbook/Transitions.html\n",
      "Section Titles (if exists):  ['4 Features', '4.1 Text-based Features']\n",
      "TYPE: Document\n",
      "FUNCTION: Use\n",
      "Please classify the artifact type and the citation reason for the following URL and citation sentence.\n",
      "URL:  http://www.verify-sy.com\n",
      "Citation Context: Claim Extraction We consider two websites as the source of our claims. V ERIFY [URL_CITE] is a project that was established to expose false claims made about the war in Syria and other related Middle Eastern issues. It is an independent platform that debunks claims made by all parties to the conflict.\n",
      "Footnote or Reference text (if exists): 4 http://www.verify-sy.com\n",
      "Section Titles (if exists):  ['3 The Corpus']\n",
      "TYPE: Website\n",
      "FUNCTION: Use\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(texts)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "texts = create_inst(train_df, eval_df, \"random\", k=5)[0]\n",
    "print(texts)\n",
    "for part in texts:\n",
    "    print(part['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_dir = f\"/data/group1/z40436a/ME/URL_Citation_Classification_Intermediate/icl/{ICL_METHOD}\"\n",
    "with open(f\"{output_dir}/{str(seed)}.txt\", \"w\") as jsonl_file:\n",
    "    for icl in icls:\n",
    "        json.dump(icl, jsonl_file)\n",
    "        jsonl_file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME_241211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
