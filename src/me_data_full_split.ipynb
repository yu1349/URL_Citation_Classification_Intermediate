{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>passage-title</th>\n",
       "      <th>citation-info</th>\n",
       "      <th>citation-paragraph</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>citation-type</th>\n",
       "      <th>tsunokake_id</th>\n",
       "      <th>choice_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mdelhoneux/uuparser-compos...</td>\n",
       "      <td>['4 Composition in a K&amp;G Parser']</td>\n",
       "      <td>4 The code can be found at https://github.com/...</td>\n",
       "      <td>Parser We use UUParser, a variant of the K&amp;G t...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Code</td>\n",
       "      <td>2019</td>\n",
       "      <td>Footnote</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://hdl.handle.net/11234/1-2364</td>\n",
       "      <td>['5 What Correlates with Difficulty?']</td>\n",
       "      <td>Milan Straka and Jana Strakov. 2017. Tokenizin...</td>\n",
       "      <td>Head-POS Entropy Dehouck and Denis (2018) prop...</td>\n",
       "      <td>Material</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>2019</td>\n",
       "      <td>Reference</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://sjmielke.com/papers/tokenize/</td>\n",
       "      <td>['D Data selection: Europarl']</td>\n",
       "      <td>31 http://sjmielke.com/papers/tokenize/</td>\n",
       "      <td>Finally, it should be said that the text in Co...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Tool</td>\n",
       "      <td>2019</td>\n",
       "      <td>Footnote</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://developer.twitter.com/en/docs.html</td>\n",
       "      <td>['2 Problem Formulation', '2.2 Data']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>• Negative examples: We have col-lected 1% of ...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Tool</td>\n",
       "      <td>2019</td>\n",
       "      <td>Body</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.mturk.com/</td>\n",
       "      <td>['5 User study']</td>\n",
       "      <td>Amazon. 2005. MTurk. (https://www.mturk.com/).</td>\n",
       "      <td>To verify whether human evaluators are in agre...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Tool</td>\n",
       "      <td>2019</td>\n",
       "      <td>Reference</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0   https://github.com/mdelhoneux/uuparser-compos...   \n",
       "1                 http://hdl.handle.net/11234/1-2364   \n",
       "2               http://sjmielke.com/papers/tokenize/   \n",
       "3         https://developer.twitter.com/en/docs.html   \n",
       "4                             https://www.mturk.com/   \n",
       "\n",
       "                             passage-title  \\\n",
       "0        ['4 Composition in a K&G Parser']   \n",
       "1   ['5 What Correlates with Difficulty?']   \n",
       "2           ['D Data selection: Europarl']   \n",
       "3    ['2 Problem Formulation', '2.2 Data']   \n",
       "4                         ['5 User study']   \n",
       "\n",
       "                                       citation-info  \\\n",
       "0  4 The code can be found at https://github.com/...   \n",
       "1  Milan Straka and Jana Strakov. 2017. Tokenizin...   \n",
       "2            31 http://sjmielke.com/papers/tokenize/   \n",
       "3                                                NaN   \n",
       "4     Amazon. 2005. MTurk. (https://www.mturk.com/).   \n",
       "\n",
       "                                  citation-paragraph      role       type  \\\n",
       "0  Parser We use UUParser, a variant of the K&G t...    Method       Code   \n",
       "1  Head-POS Entropy Dehouck and Denis (2018) prop...  Material  Knowledge   \n",
       "2  Finally, it should be said that the text in Co...    Method       Tool   \n",
       "3  • Negative examples: We have col-lected 1% of ...    Method       Tool   \n",
       "4  To verify whether human evaluators are in agre...    Method       Tool   \n",
       "\n",
       "   year citation-type  tsunokake_id  choice_id  \n",
       "0  2019      Footnote             0          0  \n",
       "1  2019     Reference             1          1  \n",
       "2  2019      Footnote             2          2  \n",
       "3  2019          Body             5          3  \n",
       "4  2019     Reference             6          4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "full_data = pd.read_csv('./data/all_data.csv', encoding=\"utf-8\", usecols=['id', 'url', 'passage-title', 'citation-info', 'citation-paragraph', 'citation-type', 'role','type', 'year'], index_col=0)\n",
    "full_data['tsunokake_id'] = full_data.index\n",
    "## 使用するのはRoleがMaterialとMethodであるもののみ\n",
    "choice_data = full_data.query(\"role == 'Method' | role == 'Material'\").reset_index().drop('id', axis=1)\n",
    "## choice_dataのインデックスを保存\n",
    "choice_data['choice_id'] = choice_data.index\n",
    "display(choice_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(2001),\n",
       " np.int64(2002),\n",
       " np.int64(2003),\n",
       " np.int64(2004),\n",
       " np.int64(2005),\n",
       " np.int64(2006),\n",
       " np.int64(2007),\n",
       " np.int64(2008),\n",
       " np.int64(2009),\n",
       " np.int64(2010),\n",
       " np.int64(2011),\n",
       " np.int64(2012),\n",
       " np.int64(2013),\n",
       " np.int64(2014),\n",
       " np.int64(2015),\n",
       " np.int64(2016),\n",
       " np.int64(2017),\n",
       " np.int64(2018),\n",
       " np.int64(2019),\n",
       " np.int64(2020),\n",
       " np.int64(2021)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(choice_data['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>passage-title</th>\n",
       "      <th>citation-info</th>\n",
       "      <th>citation-paragraph</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>citation-type</th>\n",
       "      <th>tsunokake_id</th>\n",
       "      <th>choice_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://github.com/doug919/entity_based_narra...</td>\n",
       "      <td>['1 Introduction']</td>\n",
       "      <td>1 https://github.com/doug919/entity_ based_nar...</td>\n",
       "      <td>The evaluated downstream tasks include two cha...</td>\n",
       "      <td>Material</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>2021</td>\n",
       "      <td>Footnote</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://github.com/luyaojie/text2event</td>\n",
       "      <td>['1 Introduction']</td>\n",
       "      <td>1 Our source codes are openly available at htt...</td>\n",
       "      <td>We conducted experiments [Cite_Footnote_1] on ...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Code</td>\n",
       "      <td>2021</td>\n",
       "      <td>Footnote</td>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://archive.org/download/</td>\n",
       "      <td>['3 Analysis Setup', '3.1 Experiment Procedure']</td>\n",
       "      <td>1 The snapshot is available at https://archive...</td>\n",
       "      <td>Our goal is to analyze the influence in downst...</td>\n",
       "      <td>Material</td>\n",
       "      <td>Dataset</td>\n",
       "      <td>2021</td>\n",
       "      <td>Footnote</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>http://commoncrawl.org/2016/10/newsdatasetava...</td>\n",
       "      <td>['mixture of corpus 5 used to pre-train BART.']</td>\n",
       "      <td>Sebastian Nagel. 2016. Cc-news. URL: http://we...</td>\n",
       "      <td>5 Similar to RoBERTa, BART uses the combinatio...</td>\n",
       "      <td>Material</td>\n",
       "      <td>Dataset</td>\n",
       "      <td>2021</td>\n",
       "      <td>Reference</td>\n",
       "      <td>68</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>https://github.com/facebookresearch/DPR/blob/...</td>\n",
       "      <td>['D Reproducibility', 'D.1 Dataset Details']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We obtain closed-book QA datasets from [Cite] ...</td>\n",
       "      <td>Material</td>\n",
       "      <td>DataSource</td>\n",
       "      <td>2021</td>\n",
       "      <td>Body</td>\n",
       "      <td>69</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "46   https://github.com/doug919/entity_based_narra...   \n",
       "48             https://github.com/luyaojie/text2event   \n",
       "49                      https://archive.org/download/   \n",
       "50   http://commoncrawl.org/2016/10/newsdatasetava...   \n",
       "51   https://github.com/facebookresearch/DPR/blob/...   \n",
       "\n",
       "                                        passage-title  \\\n",
       "46                                 ['1 Introduction']   \n",
       "48                                 ['1 Introduction']   \n",
       "49   ['3 Analysis Setup', '3.1 Experiment Procedure']   \n",
       "50    ['mixture of corpus 5 used to pre-train BART.']   \n",
       "51       ['D Reproducibility', 'D.1 Dataset Details']   \n",
       "\n",
       "                                        citation-info  \\\n",
       "46  1 https://github.com/doug919/entity_ based_nar...   \n",
       "48  1 Our source codes are openly available at htt...   \n",
       "49  1 The snapshot is available at https://archive...   \n",
       "50  Sebastian Nagel. 2016. Cc-news. URL: http://we...   \n",
       "51                                                NaN   \n",
       "\n",
       "                                   citation-paragraph      role        type  \\\n",
       "46  The evaluated downstream tasks include two cha...  Material   Knowledge   \n",
       "48  We conducted experiments [Cite_Footnote_1] on ...    Method        Code   \n",
       "49  Our goal is to analyze the influence in downst...  Material     Dataset   \n",
       "50  5 Similar to RoBERTa, BART uses the combinatio...  Material     Dataset   \n",
       "51  We obtain closed-book QA datasets from [Cite] ...  Material  DataSource   \n",
       "\n",
       "    year citation-type  tsunokake_id  choice_id  \n",
       "46  2021      Footnote            63         46  \n",
       "48  2021      Footnote            66         48  \n",
       "49  2021      Footnote            67         49  \n",
       "50  2021     Reference            68         50  \n",
       "51  2021          Body            69         51  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>passage-title</th>\n",
       "      <th>citation-info</th>\n",
       "      <th>citation-paragraph</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>citation-type</th>\n",
       "      <th>tsunokake_id</th>\n",
       "      <th>choice_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mdelhoneux/uuparser-compos...</td>\n",
       "      <td>['4 Composition in a K&amp;G Parser']</td>\n",
       "      <td>4 The code can be found at https://github.com/...</td>\n",
       "      <td>Parser We use UUParser, a variant of the K&amp;G t...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Code</td>\n",
       "      <td>2019</td>\n",
       "      <td>Footnote</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://hdl.handle.net/11234/1-2364</td>\n",
       "      <td>['5 What Correlates with Difficulty?']</td>\n",
       "      <td>Milan Straka and Jana Strakov. 2017. Tokenizin...</td>\n",
       "      <td>Head-POS Entropy Dehouck and Denis (2018) prop...</td>\n",
       "      <td>Material</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>2019</td>\n",
       "      <td>Reference</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://sjmielke.com/papers/tokenize/</td>\n",
       "      <td>['D Data selection: Europarl']</td>\n",
       "      <td>31 http://sjmielke.com/papers/tokenize/</td>\n",
       "      <td>Finally, it should be said that the text in Co...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Tool</td>\n",
       "      <td>2019</td>\n",
       "      <td>Footnote</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://developer.twitter.com/en/docs.html</td>\n",
       "      <td>['2 Problem Formulation', '2.2 Data']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>• Negative examples: We have col-lected 1% of ...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Tool</td>\n",
       "      <td>2019</td>\n",
       "      <td>Body</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.mturk.com/</td>\n",
       "      <td>['5 User study']</td>\n",
       "      <td>Amazon. 2005. MTurk. (https://www.mturk.com/).</td>\n",
       "      <td>To verify whether human evaluators are in agre...</td>\n",
       "      <td>Method</td>\n",
       "      <td>Tool</td>\n",
       "      <td>2019</td>\n",
       "      <td>Reference</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0   https://github.com/mdelhoneux/uuparser-compos...   \n",
       "1                 http://hdl.handle.net/11234/1-2364   \n",
       "2               http://sjmielke.com/papers/tokenize/   \n",
       "3         https://developer.twitter.com/en/docs.html   \n",
       "4                             https://www.mturk.com/   \n",
       "\n",
       "                             passage-title  \\\n",
       "0        ['4 Composition in a K&G Parser']   \n",
       "1   ['5 What Correlates with Difficulty?']   \n",
       "2           ['D Data selection: Europarl']   \n",
       "3    ['2 Problem Formulation', '2.2 Data']   \n",
       "4                         ['5 User study']   \n",
       "\n",
       "                                       citation-info  \\\n",
       "0  4 The code can be found at https://github.com/...   \n",
       "1  Milan Straka and Jana Strakov. 2017. Tokenizin...   \n",
       "2            31 http://sjmielke.com/papers/tokenize/   \n",
       "3                                                NaN   \n",
       "4     Amazon. 2005. MTurk. (https://www.mturk.com/).   \n",
       "\n",
       "                                  citation-paragraph      role       type  \\\n",
       "0  Parser We use UUParser, a variant of the K&G t...    Method       Code   \n",
       "1  Head-POS Entropy Dehouck and Denis (2018) prop...  Material  Knowledge   \n",
       "2  Finally, it should be said that the text in Co...    Method       Tool   \n",
       "3  • Negative examples: We have col-lected 1% of ...    Method       Tool   \n",
       "4  To verify whether human evaluators are in agre...    Method       Tool   \n",
       "\n",
       "   year citation-type  tsunokake_id  choice_id  \n",
       "0  2019      Footnote             0          0  \n",
       "1  2019     Reference             1          1  \n",
       "2  2019      Footnote             2          2  \n",
       "3  2019          Body             5          3  \n",
       "4  2019     Reference             6          4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size::: 1655\n",
      "test_size::: 317\n",
      "train_ids::: Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "       ...\n",
      "       1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971],\n",
      "      dtype='int64', length=1655)\n",
      "test_ids::: Index([  46,   48,   49,   50,   51,   52,   53,   65,   66,   68,\n",
      "       ...\n",
      "       1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1957, 1958],\n",
      "      dtype='int64', length=317)\n"
     ]
    }
   ],
   "source": [
    "# split train & test based on \"year\"\n",
    "## full test data = 317\n",
    "## test_dataを2021年（最新論文）\n",
    "test_df = choice_data.query(\"year==2021\")\n",
    "## それ以外を学習データとして使用\n",
    "train_df = choice_data.query(\"year<2021\")\n",
    "display(test_df.head())\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"train_size:::\", len(train_df))\n",
    "print(\"test_size:::\", len(test_df))\n",
    "\n",
    "print(\"train_ids:::\", train_df.index)\n",
    "print(\"test_ids:::\", test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2020: 320, 2019: 270, 2018: 229, 2016: 143, 2015: 122, 2014: 84, 2017: 83, 2013: 69, 2012: 65, 2010: 46, 2009: 41, 2006: 39, 2007: 33, 2005: 28, 2011: 28, 2008: 24, 2003: 12, 2004: 9, 2002: 7, 2001: 3})\n"
     ]
    }
   ],
   "source": [
    "# check years of train_df\n",
    "print(Counter(train_df['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_years(lst, index, seed: int = 0):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 各年のインデックスを格納\n",
    "    year_indices = defaultdict(list)\n",
    "    for i, year in enumerate(lst):\n",
    "        year_indices[year].append(i)\n",
    "        # print(year)\n",
    "\n",
    "    # 各年のインデックスをシャッフル（バランスよく選ぶため）\n",
    "    for year in year_indices:\n",
    "        random.shuffle(year_indices[year])\n",
    "\n",
    "    # 年ごとにラウンドロビンでインデックスを選択\n",
    "    lst1_indices = []\n",
    "    available_years = list(year_indices.keys())\n",
    "\n",
    "    while len(lst1_indices) < index and available_years:\n",
    "        for year in available_years[:]:  # `[:]` でコピーを作成して反復中の変更に対応\n",
    "            if year_indices[year]:  # まだ選べるデータがある場合\n",
    "                lst1_indices.append(year_indices[year].pop(0))\n",
    "                if len(lst1_indices) >= index:  # 目標数に達したら終了\n",
    "                    break\n",
    "            elif not year_indices[year]:  # その年のデータが尽きたらリストから削除\n",
    "                print('hello')\n",
    "                print(year)\n",
    "                available_years.remove(year)\n",
    "\n",
    "    # 残りのデータを lst2 に格納\n",
    "    lst2_indices = [i for i in range(len(lst)) if i not in lst1_indices]\n",
    "\n",
    "    return lst1_indices, lst2_indices\n",
    "\n",
    "# ==== 動作確認 ====\n",
    "# lst = [2001, 2002, 2001, 2003, 2002, 2001, 2003, 2003, 2002, 2001]\n",
    "# index = 6\n",
    "# lst1_indices, lst2_indices = split_years(lst, index, seed=0)\n",
    "\n",
    "# print(\"lst1:\", [lst[i] for i in lst1_indices])\n",
    "# print(\"lst2:\", [lst[i] for i in lst2_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "2001\n",
      "hello\n",
      "2002\n",
      "hello\n",
      "2004\n",
      "hello\n",
      "2003\n"
     ]
    }
   ],
   "source": [
    "# 各年号が開発に含まれるように分割\n",
    "## 返されるのはリストのインデックス=train_dfのreset_index\n",
    "reset_dev_ids, reset_train_ids = split_years(train_df['year'].to_list(), len(test_df))\n",
    "## 最初のchoice_dataのidに変換\n",
    "dev_ids = [int(train_df.iloc[reset_dev_id]['choice_id']) for reset_dev_id in reset_dev_ids]\n",
    "train_ids = [int(train_df.iloc[reset_train_id]['choice_id']) for reset_train_id in reset_train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[804, 1116, 547, 16, 1435, 829, 1908, 988, 147, 1656, 736, 1306, 1871, 313, 121, 123, 1257, 562, 312, 1621, 652, 7, 13, 1153, 142, 551, 1859, 977, 375, 64, 1346, 1483, 735, 449, 141, 409, 1258, 289, 1743, 454, 626, 8, 1623, 1354, 18, 754, 89, 1094, 713, 575, 1303, 1680, 1476, 315, 1931, 607, 874, 452, 1744, 684, 1470, 865, 1723, 428, 166, 1002, 722, 884, 516, 1048, 1867, 281, 832, 529, 308, 1968, 1830, 288, 1246, 322, 771, 1626, 589, 1436, 877, 1343, 1407, 1685, 691, 926, 577, 352, 1357, 1010, 1062, 1683, 1498, 1619, 345, 867, 948, 1530, 1485, 1224, 1424, 150, 514, 602, 872, 1565, 351, 1938, 265, 1061, 1827, 1596, 1245, 1072, 774, 12, 1349, 17, 689, 1861, 1814, 908, 1182, 1844, 1563, 85, 530, 1930, 1058, 1351, 451, 1620, 136, 226, 1374, 1582, 1486, 212, 180, 1507, 1840, 609, 382, 419, 1693, 317, 120, 1448, 1526, 1500, 272, 765, 1914, 117, 143, 105, 91, 1023, 43, 1649, 1040, 557, 1907, 1356, 122, 1933, 211, 283, 198, 1514, 1912, 176, 882, 870, 1265, 1614, 888, 688, 420, 1237, 1618, 443, 1855, 1096, 290, 102, 773, 11, 1397, 938, 1742, 330, 714, 645, 1517, 1681, 84, 1670, 310, 1059, 1828, 1589, 229, 340, 1913, 15, 678, 1718, 1813, 1785, 1069, 220, 1523, 363, 435, 309, 1285, 1684, 564, 231, 398, 1628, 222, 1385, 26, 1290, 1794, 890, 384, 282, 975, 647, 1663, 1353, 392, 14, 762, 1373, 1492, 661, 279, 998, 958, 600, 1309, 1682, 371, 496, 1294, 1260, 1916, 1590, 395, 1724, 1466, 1884, 1482, 1508, 1174, 887, 421, 914, 1425, 720, 1348, 1256, 335, 813, 859, 548, 835, 1091, 1341, 1300, 712, 598, 705, 873, 746, 646, 1856, 1694, 563, 1084, 570, 1725, 779, 755, 1342, 1022, 957, 1583, 1143, 1564, 1474, 592, 1934, 1765, 393, 208, 467, 201, 932, 1218, 1860, 1088, 1566, 966, 1337, 1671, 1792, 532, 1967]\n",
      "[0, 1, 2, 3, 4, 5, 6, 9, 10, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 100, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 118, 119, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 144, 146, 148, 149, 151, 160, 161, 162, 163, 164, 165, 167, 169, 170, 175, 177, 178, 179, 181, 182, 183, 184, 185, 195, 196, 197, 199, 202, 206, 207, 209, 210, 213, 214, 215, 216, 217, 218, 219, 221, 223, 224, 225, 227, 228, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 271, 273, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 311, 314, 316, 318, 319, 320, 321, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 336, 337, 338, 339, 341, 342, 343, 344, 346, 347, 348, 349, 350, 353, 354, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 376, 377, 378, 379, 380, 381, 383, 385, 386, 387, 390, 391, 394, 396, 397, 399, 410, 411, 412, 413, 414, 415, 416, 422, 423, 424, 425, 426, 427, 429, 430, 431, 432, 433, 434, 436, 437, 438, 439, 440, 441, 442, 444, 445, 446, 447, 448, 450, 453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 483, 484, 485, 486, 487, 488, 489, 492, 493, 494, 495, 497, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 531, 533, 534, 535, 536, 537, 538, 539, 543, 544, 545, 546, 549, 550, 552, 553, 554, 555, 556, 558, 559, 560, 561, 565, 566, 567, 568, 569, 571, 572, 573, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 590, 591, 593, 594, 595, 599, 601, 603, 604, 605, 606, 608, 611, 612, 613, 614, 615, 616, 617, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 648, 649, 650, 651, 653, 654, 655, 656, 657, 658, 659, 660, 662, 663, 666, 667, 668, 669, 670, 671, 675, 676, 677, 679, 683, 685, 686, 687, 690, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 706, 707, 708, 709, 710, 711, 715, 716, 717, 718, 719, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 737, 738, 739, 740, 744, 745, 747, 748, 750, 751, 752, 753, 756, 757, 758, 759, 760, 761, 763, 764, 766, 768, 769, 770, 772, 776, 777, 778, 780, 781, 782, 783, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 800, 801, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 830, 833, 834, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 860, 862, 863, 864, 866, 868, 869, 871, 876, 878, 879, 880, 881, 883, 885, 886, 889, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 923, 924, 925, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 951, 952, 955, 956, 959, 963, 964, 965, 972, 973, 974, 976, 985, 986, 987, 989, 990, 991, 992, 997, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1024, 1025, 1026, 1027, 1028, 1033, 1034, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1060, 1063, 1064, 1065, 1066, 1067, 1068, 1070, 1071, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1085, 1086, 1087, 1089, 1090, 1092, 1095, 1097, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1114, 1115, 1117, 1118, 1119, 1120, 1122, 1123, 1125, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1157, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1216, 1217, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1247, 1248, 1249, 1250, 1254, 1255, 1259, 1261, 1262, 1263, 1264, 1266, 1267, 1268, 1269, 1270, 1271, 1277, 1284, 1286, 1287, 1288, 1289, 1291, 1292, 1293, 1296, 1297, 1298, 1299, 1301, 1302, 1304, 1307, 1308, 1310, 1311, 1312, 1313, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1338, 1339, 1340, 1344, 1345, 1347, 1350, 1352, 1355, 1361, 1362, 1363, 1367, 1368, 1369, 1371, 1372, 1375, 1376, 1377, 1378, 1380, 1381, 1382, 1383, 1384, 1386, 1387, 1389, 1390, 1391, 1396, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1410, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1428, 1429, 1430, 1431, 1432, 1433, 1437, 1438, 1439, 1440, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1467, 1468, 1469, 1471, 1472, 1473, 1475, 1477, 1478, 1479, 1480, 1481, 1484, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1497, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1518, 1520, 1521, 1522, 1524, 1525, 1527, 1528, 1529, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1553, 1554, 1555, 1560, 1561, 1562, 1567, 1568, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1584, 1585, 1586, 1587, 1588, 1591, 1592, 1593, 1594, 1595, 1597, 1599, 1600, 1601, 1602, 1603, 1604, 1611, 1612, 1613, 1615, 1616, 1617, 1622, 1624, 1625, 1627, 1629, 1630, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1650, 1651, 1652, 1653, 1654, 1657, 1658, 1659, 1660, 1661, 1662, 1664, 1665, 1666, 1667, 1668, 1669, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1745, 1746, 1747, 1748, 1754, 1755, 1756, 1757, 1762, 1763, 1764, 1766, 1770, 1771, 1772, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1786, 1787, 1788, 1789, 1790, 1791, 1793, 1795, 1796, 1797, 1798, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1809, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1826, 1829, 1837, 1838, 1839, 1841, 1842, 1843, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1857, 1858, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1872, 1874, 1875, 1876, 1877, 1878, 1880, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1909, 1910, 1911, 1915, 1917, 1932, 1935, 1936, 1937, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1969, 1970, 1971]\n"
     ]
    }
   ],
   "source": [
    "# インデックスの確認\n",
    "print(dev_ids)\n",
    "print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev::: Counter({np.int64(2019): 18, np.int64(2014): 18, np.int64(2005): 18, np.int64(2009): 18, np.int64(2015): 18, np.int64(2011): 18, np.int64(2020): 18, np.int64(2016): 18, np.int64(2013): 18, np.int64(2018): 18, np.int64(2008): 18, np.int64(2017): 18, np.int64(2012): 18, np.int64(2010): 18, np.int64(2007): 17, np.int64(2006): 17, np.int64(2003): 12, np.int64(2004): 9, np.int64(2002): 7, np.int64(2001): 3})\n",
      "train::: Counter({np.int64(2020): 302, np.int64(2019): 252, np.int64(2018): 211, np.int64(2016): 125, np.int64(2015): 104, np.int64(2014): 66, np.int64(2017): 65, np.int64(2013): 51, np.int64(2012): 47, np.int64(2010): 28, np.int64(2009): 23, np.int64(2006): 22, np.int64(2007): 16, np.int64(2005): 10, np.int64(2011): 10, np.int64(2008): 6})\n"
     ]
    }
   ],
   "source": [
    "# 開発と学習の確認\n",
    "dev_count = []\n",
    "for id in dev_ids:\n",
    "    dev_count.append(choice_data.iloc[id]['year'])\n",
    "print(\"dev:::\", Counter(dev_count))\n",
    "train_count = []\n",
    "for id in train_ids:\n",
    "    train_count.append(choice_data.iloc[id]['year'])\n",
    "print(\"train:::\", Counter(train_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# サイズチェック\n",
    "if (len(dev_ids) == len(test_df)) and (len(train_ids) + len(dev_ids) + len(test_df) == len(train_df) + len(test_df)):\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data/full_data_split', exist_ok=True)\n",
    "with open('./data/full_data_split/test_ids.txt', 'w') as test_idx_file:\n",
    "    for test_id in test_df['choice_id'].to_list():\n",
    "        test_idx_file.write(str(test_id)+'\\n')\n",
    "\n",
    "with open('./data/full_data_split/dev_ids.txt', 'w') as dev_idx_file:\n",
    "    for dev_id in dev_ids:\n",
    "        dev_idx_file.write(str(dev_id)+'\\n')\n",
    "\n",
    "with open('./data/full_data_split/train_ids.txt', 'w') as train_idx_file:\n",
    "    for train_id in train_ids:\n",
    "        train_idx_file.write(str(train_id)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME_241211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
