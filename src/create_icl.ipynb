{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rank_bm25 import BM25Okapi\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import Literal, Optional, TypedDict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLCiteDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    create dataset\n",
    "    - init\n",
    "    - len\n",
    "    - getitem\n",
    "    '''\n",
    "    def __init__(self, texts: list[str]):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 30 00:22:24 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           On  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              23W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           On  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              36W / 250W |  15878MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_size::: 2690\n",
      "test_data_size::: 299\n"
     ]
    }
   ],
   "source": [
    "csv_dataset = pd.read_csv(\"/data/group1/z40436a/ME/URL_Citation_Classification_Intermediate/data/all_data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "seed = 111 # fixed\n",
    "train_df, eval_df = train_test_split(csv_dataset, test_size = 0.1, random_state=seed)\n",
    "print(\"train_data_size:::\", len(train_df))\n",
    "print(\"test_data_size:::\", len(eval_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "CITE_TOKEN = \"[URL_CITE]\"\n",
    "\n",
    "def replace_tag(sentences: pd.Series) -> list[str]:\n",
    "    # replace [Cite_****] to [Cite] token\n",
    "    rule = re.compile(r'\\[Cite[^\\[\\] ]*\\]')\n",
    "    sentences_replaced:list[str] = list()\n",
    "    for sentence in sentences:\n",
    "        sentences_replaced.append(rule.sub(CITE_TOKEN, sentence))\n",
    "\n",
    "    return sentences_replaced\n",
    "\n",
    "def get_3sent(paragraphs:list[str]) -> list[str]:\n",
    "    ret:list[list[str]] = list()\n",
    "    for paragraph in paragraphs:\n",
    "        sentences: list[str] = nltk.sent_tokenize(paragraph)\n",
    "        if not len(sentences):\n",
    "            print('!!!')\n",
    "        if len(sentences) < 4:\n",
    "            ret.append(sentences)\n",
    "            continue\n",
    "        else:\n",
    "            for i in range(len(sentences)):\n",
    "                if CITE_TOKEN in sentences[i]:\n",
    "                    if i == 0:\n",
    "                        ret.append(sentences[i:i+2])\n",
    "                    elif i == len(sentences)-1:\n",
    "                        ret.append(sentences[i-1:i+1])\n",
    "                    else:\n",
    "                        ret.append(sentences[i-1:i+2])\n",
    "                    break\n",
    "                if i == len(sentences)-1:\n",
    "                    # print(sentences)\n",
    "                    pass\n",
    "    cont_3sent = [\" \".join(sent) for sent in ret]\n",
    "    return cont_3sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_icl(train_df:pd.DataFrame, test_df:pd.DataFrame, method:str, k:int=5) -> list[list[str]]:\n",
    "    icl_idxs: list[list[str]] = []\n",
    "\n",
    "    train_replaced_sentences = replace_tag(train_df['citation-paragraph'])\n",
    "    test_replaced_sentences = replace_tag(test_df['citation-paragraph'])\n",
    "\n",
    "    # check\n",
    "    print(len(train_replaced_sentences))\n",
    "    print(len(test_replaced_sentences))\n",
    "\n",
    "    train_cont_3sent = get_3sent(train_replaced_sentences)\n",
    "    test_cont_3sent = get_3sent(test_replaced_sentences)\n",
    "\n",
    "    # check\n",
    "    print(len(train_cont_3sent))\n",
    "    print(len(test_cont_3sent))\n",
    "\n",
    "    # random\n",
    "    if method == \"random\":\n",
    "        for cont, (i, row) in zip(test_cont_3sent, test_df.iterrows()):\n",
    "            random.seed(i)\n",
    "            icl_idxs.append(random.sample(range(len(train_cont_3sent)), k))\n",
    "\n",
    "    #bm25\n",
    "    elif method == \"bm25\":\n",
    "        tokenized_corpus = [cont.split(\" \") for cont in train_cont_3sent]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        for cont, (i, row) in zip(test_cont_3sent, test_df.iterrows()):\n",
    "            bm25_scores = bm25.get_scores(cont.split(\" \"))\n",
    "            icl_idxs.append(np.argsort(bm25_scores)[-k:][::-1].tolist())\n",
    "    elif method == \"encoder\":\n",
    "        model = SentenceTransformer(\"intfloat/multilingual-e5-base\")\n",
    "\n",
    "        tokenized_corpus = model.encode(train_cont_3sent, convert_to_tensor=True)\n",
    "        for cont, (i, row) in zip(test_cont_3sent, test_df.iterrows()):\n",
    "            tokenized_query = model.encode(test_cont_3sent)\n",
    "            cos_scores = util.cos_sim(tokenized_query, tokenized_corpus)[0]\n",
    "\n",
    "            icl_idxs.append(np.argsort(-cos_scores)[:k].tolist())\n",
    "    else:\n",
    "        print(\"select other method\")\n",
    "    \n",
    "    return icl_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2690\n",
      "299\n",
      "2690\n",
      "299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05159c976ca744f9bcf44aa98127f0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977cdeb301764f97b49f99036db1d7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/179k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69705b2f1d2a4028a1e4e07856247472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdedb64666d14f3a9da686e496ec90e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6b57d156f848aeb569e16c6c941ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fed43136fce4a95a552daf9a98071c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd1a0b8a85248a1b4985191aff1b20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5261724db1e44cd28cdc6a17b97a0db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3595180f6322452da9a14dfc5c1dfb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8457c5af3ee24623bb4402aca82ac210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ICL_METHOD \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m icls \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_icl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mICL_METHOD\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[98], line 38\u001b[0m, in \u001b[0;36mcreate_icl\u001b[0;34m(train_df, test_df, method, k)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cont, (i, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(test_cont_3sent, test_df\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[1;32m     37\u001b[0m         tokenized_query \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(test_cont_3sent)\n\u001b[0;32m---> 38\u001b[0m         cos_scores \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_corpus\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m         icl_idxs\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mcos_scores)[:k]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ME_241211/lib/python3.12/site-packages/sentence_transformers/util.py:108\u001b[0m, in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    106\u001b[0m a_norm \u001b[38;5;241m=\u001b[39m normalize_embeddings(a)\n\u001b[1;32m    107\u001b[0m b_norm \u001b[38;5;241m=\u001b[39m normalize_embeddings(b)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_norm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
     ]
    }
   ],
   "source": [
    "ICL_METHOD = \"encoder\"\n",
    "icls = create_icl(train_df, eval_df, method=ICL_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2091, 2125, 973, 2553, 208], [2378, 1155, 1587, 2322, 2400], [818, 16, 716, 2124, 2150], [1485, 363, 1518, 924, 1400], [905, 1773, 712, 1968, 1067], [765, 498, 1508, 506, 375], [2434, 2020, 1375, 1130, 1064], [1009, 2538, 2380, 1741, 1976], [595, 2220, 1959, 2424, 112], [2333, 2520, 1854, 761, 674], [1537, 628, 719, 1905, 1563], [1506, 1211, 364, 1250, 2448], [1901, 614, 45, 1711, 650], [2011, 1102, 180, 1819, 686], [1441, 1498, 1321, 2375, 1831], [2074, 962, 2208, 1963, 1181], [1745, 1950, 4, 1393, 2605], [1540, 2666, 1326, 2290, 2003], [922, 875, 2261, 2473, 2421], [2060, 1664, 641, 570, 1215], [1272, 1002, 1702, 1574, 446], [703, 342, 368, 2368, 1784], [280, 2402, 56, 2294, 1035], [71, 1677, 837, 530, 2686], [1730, 1427, 2493, 958, 2520], [2398, 1852, 255, 975, 1959], [205, 2074, 2009, 801, 847], [232, 1797, 1087, 910, 1433], [833, 2478, 1954, 2060, 859], [582, 1305, 1947, 340, 2373], [491, 2200, 1667, 884, 1559], [1845, 2474, 1791, 464, 1938], [868, 449, 1493, 1901, 122], [1514, 1039, 2191, 223, 287], [992, 2118, 1664, 1562, 147], [1033, 1233, 2399, 1055, 1452], [127, 801, 2206, 2094, 1347], [978, 740, 1204, 1558, 295], [981, 1817, 700, 60, 1416], [636, 51, 790, 1807, 1889], [972, 2587, 740, 228, 2395], [1083, 1409, 2590, 1800, 615], [2222, 718, 837, 1097, 792], [2067, 403, 1519, 347, 1967], [1171, 453, 393, 2290, 558], [991, 1799, 93, 893, 760], [592, 1197, 614, 1330, 786], [2490, 2525, 396, 2273, 2484], [2677, 184, 1682, 2053, 1874], [1943, 1222, 2053, 2484, 273], [2129, 1742, 1119, 1802, 2651], [543, 1194, 1078, 2111, 1036], [1645, 1211, 901, 105, 1311], [2059, 632, 960, 1418, 2154], [321, 2233, 1046, 444, 196], [232, 1256, 1653, 953, 16], [1163, 1845, 1832, 233, 163], [832, 1538, 1992, 851, 1817], [2386, 2103, 301, 1986, 1595], [734, 1359, 1504, 1129, 1883], [306, 70, 2281, 1916, 2167], [2055, 2487, 210, 461, 2061], [1643, 2291, 868, 1058, 369], [1974, 308, 508, 2074, 566], [1735, 2048, 645, 1625, 1893], [2462, 707, 2405, 767, 1622], [255, 2016, 2603, 921, 860], [2007, 912, 1823, 2374, 2161], [1208, 956, 1268, 2249, 1533], [869, 266, 122, 2018, 1088], [2642, 2143, 2185, 910, 433], [1829, 351, 2603, 293, 251], [947, 299, 609, 669, 2397], [465, 930, 2028, 2485, 2002], [207, 897, 1397, 1413, 1828], [2293, 775, 1258, 1630, 138], [285, 201, 1670, 572, 1221], [1700, 1274, 561, 2385, 493], [1340, 1139, 2499, 1516, 800], [27, 1419, 890, 587, 1627], [354, 2168, 617, 76, 374], [381, 2068, 1652, 2389, 2007], [833, 1701, 1264, 2618, 697], [1496, 498, 921, 82, 549], [2283, 2207, 2266, 1667, 1944], [2113, 1224, 2185, 2367, 2520], [957, 1495, 1021, 1791, 731], [2511, 2548, 1521, 118, 1917], [698, 1726, 1867, 1468, 2016], [2659, 2078, 2656, 119, 856], [2202, 1155, 843, 2079, 2177], [2017, 2276, 1113, 280, 570], [752, 1583, 2624, 1142, 1818], [791, 2173, 273, 1199, 263], [2159, 1685, 995, 2450, 24], [290, 226, 1321, 1171, 1549], [1183, 2045, 2126, 1564, 2116], [1021, 598, 1454, 225, 1354], [2471, 1809, 115, 1352, 970], [1477, 1159, 1606, 53, 2321], [78, 1980, 1595, 1323, 2129], [1230, 1588, 1130, 1648, 736], [163, 107, 271, 2523, 1273], [764, 778, 407, 225, 953], [731, 1286, 488, 2583, 93], [1204, 2245, 2407, 459, 758], [1160, 1389, 861, 708, 2460], [2542, 2625, 1596, 632, 1642], [463, 2483, 2409, 164, 391], [621, 727, 2098, 1530, 441], [2269, 1305, 1860, 1990, 229], [2529, 1509, 313, 1456, 524], [2239, 747, 508, 1147, 1239], [720, 411, 2242, 559, 579], [928, 1517, 1537, 517, 791], [1243, 2242, 778, 419, 2678], [238, 1696, 207, 2408, 1827], [1993, 213, 1774, 1751, 1718], [422, 1033, 2348, 2531, 2186], [1452, 836, 1558, 365, 1072], [1707, 2609, 1849, 574, 2228], [227, 1464, 669, 1518, 1676], [1838, 1489, 2584, 1926, 1795], [2105, 1520, 1199, 2160, 843], [2549, 2027, 690, 973, 1705], [1978, 1634, 2201, 1681, 2347], [670, 1913, 1023, 558, 482], [2422, 1429, 2378, 444, 8], [900, 652, 2043, 763, 949], [2314, 1382, 1874, 273, 1637], [1326, 617, 1617, 2666, 197], [995, 2579, 1947, 2234, 1710], [2011, 814, 1091, 603, 218], [986, 2360, 2290, 1106, 87], [2072, 1856, 1384, 2285, 2177], [1396, 169, 2064, 2657, 791], [2250, 2444, 881, 802, 1857], [1546, 2281, 1339, 1416, 2426], [901, 1746, 2029, 1941, 1785], [706, 713, 2004, 1029, 735], [1013, 727, 76, 2267, 1495], [946, 1546, 314, 2688, 714], [2038, 415, 1751, 1147, 2336], [274, 2684, 1216, 1896, 1327], [1118, 2649, 2599, 1640, 1969], [1338, 2395, 1484, 1038, 1510], [1985, 1124, 460, 493, 1374], [569, 1954, 2521, 1429, 1744], [866, 1374, 1042, 371, 969], [1076, 2296, 1463, 238, 2402], [1113, 672, 2243, 2530, 978], [2518, 2398, 996, 2479, 148], [2349, 1914, 172, 679, 2632], [160, 1965, 1544, 1284, 620], [2643, 857, 1116, 1874, 279], [387, 1025, 937, 2500, 2457], [735, 2526, 1772, 2073, 262], [2208, 70, 1260, 1344, 1902], [2456, 768, 1059, 1010, 1815], [1867, 36, 2320, 1234, 2207], [2135, 1636, 1592, 813, 948], [1974, 2529, 2359, 584, 1987], [852, 2280, 2359, 2068, 341], [664, 1965, 2340, 841, 2285], [2255, 1395, 939, 406, 573], [1189, 2534, 1957, 1393, 1681], [1573, 517, 1136, 2489, 76], [371, 173, 2015, 2459, 870], [2663, 595, 2689, 1564, 132], [1357, 1006, 2203, 1508, 2246], [2593, 1747, 496, 1709, 1952], [1352, 2595, 886, 683, 1396], [7, 1930, 513, 2262, 1800], [167, 768, 189, 1958, 1436], [815, 1133, 1460, 2111, 438], [1861, 716, 2578, 2564, 81], [1099, 223, 2099, 1981, 1519], [173, 1557, 686, 471, 438], [2615, 1788, 855, 1621, 2073], [1775, 124, 718, 153, 2236], [2211, 62, 542, 668, 86], [2115, 157, 1383, 1612, 362], [774, 131, 997, 875, 1201], [770, 1458, 1596, 1567, 573], [2689, 2639, 178, 1029, 2027], [751, 1609, 2067, 143, 1108], [2689, 902, 2350, 925, 896], [1062, 1781, 454, 1017, 2], [185, 1545, 698, 256, 1541], [1634, 2360, 859, 1031, 1915], [1113, 1710, 1998, 1055, 335], [2278, 442, 677, 1349, 2329], [1373, 2474, 2052, 980, 2188], [2529, 1294, 1304, 421, 736], [2187, 1102, 220, 1014, 439], [1990, 1467, 2571, 351, 1016], [2014, 1044, 752, 2326, 2310], [1723, 1293, 728, 2572, 597], [1510, 581, 905, 2458, 479], [353, 384, 1425, 2329, 2608], [2219, 1718, 2026, 283, 412], [2444, 57, 2611, 223, 21], [2641, 605, 2233, 1435, 170], [560, 1588, 181, 1894, 1217], [2198, 611, 2079, 1890, 343], [368, 1769, 2616, 317, 328], [2075, 2020, 355, 1707, 574], [1652, 2605, 159, 1662, 1432], [2355, 1199, 1528, 272, 1943], [2138, 1242, 2654, 21, 709], [1069, 1820, 493, 1861, 659], [2550, 1527, 2320, 1249, 1571], [1613, 2629, 1616, 410, 903], [44, 1050, 1072, 2270, 742], [1707, 1994, 1573, 896, 2403], [205, 1060, 2119, 1363, 2430], [700, 621, 1449, 786, 1546], [2595, 902, 1935, 549, 1706], [2621, 815, 2479, 728, 588], [1156, 398, 820, 554, 862], [851, 859, 164, 333, 1416], [342, 988, 352, 2617, 244], [1803, 1488, 1896, 2337, 1954], [1487, 1136, 2662, 2166, 2459], [703, 372, 1264, 872, 1303], [1162, 20, 1694, 309, 587], [2385, 1216, 2326, 615, 244], [1453, 894, 969, 811, 1798], [189, 366, 1229, 1857, 812], [1917, 760, 883, 418, 1481], [677, 2269, 1291, 1466, 962], [1723, 1751, 1203, 2315, 747], [2471, 2542, 1382, 1922, 1861], [1513, 1240, 138, 1114, 2225], [395, 1599, 2477, 154, 2661], [455, 1037, 2323, 1604, 947], [2342, 1188, 1458, 2499, 1272], [1583, 1223, 1274, 2170, 726], [157, 1171, 589, 1894, 1515], [767, 606, 1634, 1455, 1530], [2491, 2004, 19, 655, 1474], [266, 2056, 1217, 820, 1708], [2473, 1011, 2188, 340, 1682], [1143, 1485, 1751, 354, 1290], [1001, 1971, 1837, 1816, 923], [140, 1360, 877, 414, 984], [326, 2594, 1565, 493, 717], [2486, 151, 2668, 1992, 252], [826, 1312, 754, 1912, 878], [2036, 2467, 1983, 622, 710], [494, 856, 2390, 300, 287], [2375, 1129, 1901, 2622, 634], [920, 2112, 1370, 2294, 2517], [1817, 1976, 930, 427, 409], [1517, 1897, 1595, 819, 1216], [1692, 930, 843, 87, 2470], [778, 2212, 2200, 184, 1908], [2107, 197, 2160, 2615, 897], [2335, 2347, 2319, 1206, 1912], [2663, 2118, 2043, 2512, 834], [1309, 1868, 1677, 1243, 569], [634, 7, 341, 293, 15], [1426, 898, 1527, 594, 1232], [2053, 1106, 208, 2686, 2448], [748, 1402, 2261, 1102, 1884], [2564, 2538, 1035, 375, 851], [1583, 1083, 2234, 177, 2128], [1817, 2627, 2389, 172, 2530], [618, 78, 1606, 1140, 1287], [1932, 104, 1862, 554, 1854], [1982, 130, 2627, 2253, 2411], [1349, 2104, 2465, 2508, 2371], [2624, 2167, 253, 449, 1719], [683, 1472, 1048, 762, 1470], [581, 2259, 1036, 615, 1398], [217, 59, 2149, 1008, 2601], [498, 240, 1149, 366, 1634], [494, 340, 1482, 757, 302], [1896, 2511, 1529, 1094, 567], [2474, 1244, 2280, 1980, 1605], [525, 992, 610, 1888, 1467], [226, 1328, 2623, 2605, 2395], [6, 2523, 2207, 2489, 1242], [98, 1139, 1889, 1289, 882], [941, 2323, 2243, 2681, 144], [850, 2629, 755, 1969, 1950], [1436, 85, 1317, 2458, 100], [429, 1438, 52, 937, 1136], [1143, 2152, 803, 228, 2344], [1622, 460, 33, 1418, 1259], [2204, 2156, 646, 152, 2547], [486, 784, 613, 1707, 422], [1236, 479, 1508, 1125, 1899], [668, 1167, 497, 952, 1416], [137, 1962, 1002, 1726, 1123], [953, 2421, 847, 1926, 1248], [162, 823, 890, 1293, 2383], [1849, 1544, 497, 1302, 2605], [2402, 88, 1484, 215, 355]]\n"
     ]
    }
   ],
   "source": [
    "print(icls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_dir = f\"/data/group1/z40436a/ME/URL_Citation_Classification_Intermediate/icl/{ICL_METHOD}\"\n",
    "with open(f\"{output_dir}/{str(seed)}.txt\", \"w\") as jsonl_file:\n",
    "    for icl in icls:\n",
    "        json.dump(icl, jsonl_file)\n",
    "        jsonl_file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME_241211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
