[
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://scikit-learn.org\nCitation Context: There are many successful frameworks such as S TANFORD C ORE NLP (Manning et al., 2014), NLTK (Bird et al., 2009), and SPA C Y for NLP, L UCENE and S OLR for Information Retrieval, and SCIKIT - LEARN [URL_CITE] , P Y T ORCH and T ENSOR - F LOW (Abadi et al., 2015) for general Machine Learning (ML) with a special focus on Deep Learning (DL), among others. All of these frame-works touch upon several aspects of Machine Reading, but none of them offers dedicated sup-port for modern MR pipelines.\nFootnote or Reference text (if exists): 4 http://scikit-learn.org\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/D14-1162\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe (Pen-nington et al., 2014) [URL_CITE] , and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): Jeffrey Pennington, Richard Socher, and Christo-pher D. Manning. 2014. GloVe: Global Vectors for Word Representation. In Empirical Methods in Nat-ural Language Processing (EMNLP). pages 1532\u2013 1543. http://www.aclweb.org/anthology/D14-1162.\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://people.kyb.tuebingen.mpg.de/suvrit/work/progs/movmf.html\nCitation Context: We sampled [URL_CITE] 100 objects from each of the ten dis-tributions (clusters), and made a dataset of 1,000 ob-jects in total.\nFootnote or Reference text (if exists): 1 We used the random sampling code available at http: //people.kyb.tuebingen.mpg.de/suvrit/work/progs/movmf.html (Banerjee et al., 2005).\nSection Titles (if exists):  ['300']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cs.stanford.edu/\nCitation Context: We see many opportunities for improvement, considering the poor performance of oracle training relative to the super-vised state-of-the-art, and in turn the poor perfor-mance of unsupervised state-of-the-art relative to the oracle models. [URL_CITE] To this end, it would be instructive to understand both the linguistic and statistical na-ture of the sweet spot, and to test its universality.\nFootnote or Reference text (if exists): 11 To facilitate future work, all of our models are publicly available at http://cs.stanford.edu/ \u223c valentin/.\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Supplement** - The cited URL provides access to the models developed in the paper, making it supplementary material that supports the research findings."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlm.nih.gov/mesh/meshhome.html\nCitation Context: After finding concept boundaries, we determine the probability distribution for each concept over 4 possible types (TEST, TRE, PROB or NULL). These probability distributions are found using a multi-class SVM classifier (Chang and Lin, 2011). Fea-tures used for training this classifier include con-cept tokens, full text of concept, bi-grams, head-word, suffixes of headword, capitalization pattern, shallow parse constituent, Metamap type of concept, MetaMap type of headword, occurrence of concept in MeSH (Url4, 2013) [URL_CITE] and SNOMED CT (Url5, 2013), MeSH and SNOMED CT descriptors.\nFootnote or Reference text (if exists): Url4. 2013. Mesh: Medical subject headings (http://www.nlm.nih.gov/mesh/meshhome.html) (ac-cessed july 1, 2013).\nSection Titles (if exists):  ['2 Identifying Medical Concepts']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pld/BMM_labels/\nCitation Context: To facilitate the search and avoid local minima, several heuris-tics and a look-ahead procedure are used to im-prove the performance of the algorithm. We use the BMM implementation provided by Borensztajn and Zuidema (2007) [URL_CITE] .\nFootnote or Reference text (if exists): 5 https://github.com/pld/BMM_labels/\nSection Titles (if exists):  ['3 Method', '3.3.2 Constituency labelling']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://132.70.6.148:at:8080/exploration\nCitation Context: The web application of our system is available [URL_CITE] http://132.70.6.148:at:8080/exploration\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Application to the Health-care Domain']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a web application, which is a way to demonstrate or interact with the system described in the paper"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: http://www.dh.uni-leipzig.de/wo/projects/open-greek-and-latin-project/\nCitation Context: Due to availability of digitised epigraphic corpora, P YTHIA has been trained on ancient Greek (hence-forth, \"AG\") inscriptions, written in the ancient Greek language between 7 th century BCE and 5 th century CE. We chose AG epigraphy as a case study for two reasons: a) the variability of contents and context of the AG epigraphic record makes it an excellent challenge for NLP; b) several digital AG textual corpora have been recently created, the largest ones being PHI (The Packard Humanities Institute, 2005; Gawlinski, 2017) for epigraphy; Perseus (Smith et al., 2000) and First1KGreek (Crane et al., 2014) [URL_CITE] for ancient literary texts.\nFootnote or Reference text (if exists): Gregory Ralph Crane, Monica Berti, Annette Ge\u00dfner, Matthew Munson, and Tabea Selle. 2014. Open greek and latin project. http://www.dh.uni-leipzig.de/wo/projects/open-greek-and-latin-project/. Ac-cessed on 2019-04-24.\nSection Titles (if exists): [\\'3 Generating PHI-ML\\']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://nlp.stanford.edu/software/GloVe-1.2.zip\nCitation Context: In our experiments with DIORA, we use a tree- LSTM with a hidden dimension of 50, and train for a maximum of 5 epochs with a batch size of 128. We use the GloVe framework [URL_CITE] (Pennington et al., 2014) to pretrain word-embeddings for our corpus; using an embedding size of 16.\nFootnote or Reference text (if exists): 4 https://nlp.stanford.edu/software/GloVe-1.2.zip\nSection Titles (if exists):  ['3 Method', '3.3.1 Constituency structure induction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jialuli-luka/SyntaxVLN\nCitation Context: We also show that our agent is better at aligning instructions with the cur-rent visual information via qualitative visual-izations. [URL_CITE]\nFootnote or Reference text (if exists): 1 Code and models: https://github.com/jialuli-luka/SyntaxVLN\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool within the research process,  specifically for comparing and evaluating the performance of their agent.\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://archive.org/details/stackexchange\nCitation Context: The service implementation is based on Scala and the Play Framework. Our implementation con-tains data readers that allow to index InsuranceQA (Feng et al., 2015) and all publicly available dumps of the StackExchange platform. [URL_CITE] Researchers can easily add new datasets by implementing a single data reader class.\nFootnote or Reference text (if exists): 2 https://archive.org/details/ stackexchange\nSection Titles (if exists):  ['3 Candidate Retrieval']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mallet.cs.umass.edu/\nCitation Context: Under the circumstances that the average length of negation sentences is almost as long as that of speculation ones (29.28 vs 29.77), shorter negation scopes mean that more tokens do not belong to the scopes, indicating more negative instances. The imbalance between positive and negative instances has negative effects on both the baseline and the 5 [URL_CITE] http://mallet.cs.umass.edu/ CNN-based models for negation scope detection.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Experimentation', '4.3 Experimental Results on Abstracts']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.yelp.com/dataset\nCitation Context: We use one of the classic NLP tasks that commonly suffer profanity issues - text style transfer, to eval-uate the effectiveness of the proposed framework. Particularly, we conduct experiments on a subset of the widely used Yelp dataset [URL_CITE] . The dataset consists of product reviews aligned with sentiment ratings from 1 to 5.\nFootnote or Reference text (if exists): 2 https://www.yelp.com/dataset\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://youtu.be/6LgUzia_3pM\nCitation Context: Stage two was the main experiment, where par-ticipants had to post-edit segments with different quality QE annotations in the two visualizations, as described in detail below. In order to successfully perform stage two of the experiment, the partici-pants received an explanation of all of the proto-type\u2019s features and pointers regarding the execution of the main experiment in a four minute introduc-tory video [URL_CITE] . After the video, translators were asked to try out MMPE with word-level QE in a trial project to get accustomed to the environment (for which we did not record data) before delving into the main experiment.\nFootnote or Reference text (if exists): 6 https://youtu.be/6LgUzia_3pM\nSection Titles (if exists):  ['4 Evaluation', '4.1 Method']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/International_English_Language_Testing_System\nCitation Context: Their learning progress is com-monly evaluated with classroom tests prepared by language instructors, quizzes in language learn-ing software such as Duolingo and Rosetta Stone, and by official standardized language proficiency tests such as TOEFL, IELTS, MET and others. In \u201chigh stakes\u201d scenarios, official language profi-ciency tests are the de-facto standards for language assessment; they are accepted by educational and professional institutions, and are taken by millions of language learners every year (for example, in 2016 over three million people took the IELTS test (IELTS, 2017) [URL_CITE] ). These tests probe language profi-ciency based on performance on various linguistic tasks, including grammar and vocabulary exams, reading and listening comprehension questions, as well as essay writing and speaking assignments.\nFootnote or Reference text (if exists): IELTS. 2017. International English language testing system \u2014 Wikipedia, the free encyclopedia. On-line; accessed November 2017. https://en.wikipedia.org/wiki/International_English_Language_Testing_System.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.msn.com/en-us/news\nCitation Context: We conducted experiments on a real-world news recommendation dataset collected from MSN News [URL_CITE] logs in one month (Dec. 13, 2018 to Jan. 12, 2019). The detailed statistics are shown in Ta-ble 1.\nFootnote or Reference text (if exists): 3 https://www.msn.com/en-us/news\nSection Titles (if exists):  ['3 Experiments', '3.1 Datasets and Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The data source is fundamental to the experiments conducted. \n* **TYPE: DataSource** - The URL points to the origin"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.statmt.org/wmt16/translation-task\nCitation Context: We evaluate our method on five widely used benchmark tasks: IWSLT14 German\u2192English translation (IWSLT14 De-En) , WMT16 English\u2194Romanian translation (WMT16 En-Ro/Ro-En) [URL_CITE] , and WMT14 English\u2194German translation (WMT14 En-De/De-En) . We strictly follow the dataset configurations of previous works.\nFootnote or Reference text (if exists): 2 https://www.statmt.org/wmt16/ translation-task\nSection Titles (if exists):  ['5 Experiments', '5.1 Experimental Setup 5.1.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://utexas.box.com/s/ekznoh08afi1kpkbf0hb\nCitation Context: Our account is also similar to that proposed by Erk (2015) [URL_CITE] . Erk suggests that distributional data influences semantic \u2018knowledge\u2019 : specifically, while a speaker may not know the extension of the word alligator, they maintain an information state which models properties of alligators (for instance, that they are animals).\nFootnote or Reference text (if exists): Katrin Erk. 2015. What do you know about an alli-gator when you know the company it keeps? Un-published draft. https://utexas.box.com/s/ekznoh08afi1kpkbf0hb.\nSection Titles (if exists):  ['2 Related Work', '2.1 Formal Distributional Semantics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hdl.handle.net/11234/1-1983xxx\nCitation Context: We evaluate the proposed framework on the Stan-ford Dependency (SD) conversion of the English Penn Treebank (PTB 3.0) and the Universal De-pendencies (UD 2.2) (Nivre et al., 2018) [URL_CITE] tree-banks used in CoNLL 2018 shared task(Zeman et al., 2018). For English, we use the standard train/dev/test splits of PTB (train=\u00a72-21, dev=\u00a722, test=\u00a723), POS tags were assigned using the Stan-ford tagger with 10-way jackknifing of the training corpus (accuracy \u2248 97.3%). For 12 languages se-lected from UD 2.2, we use CoNLL 2018 shared task\u2019s official train/dev/test splits, POS tags were assigned by the UDPipe (Straka et al., 2016).\nFootnote or Reference text (if exists): Joakim Nivre et al. 2018. Universal Dependencies 2.2. LINDAT/CLARIN digital library at the Insti-tute of Formal and Applied Linguistics, Charles Uni-versity, Prague, http://hdl.handle.net/11234/1-1983xxx.\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Material** - The cited resource is a dataset (Universal Dependencies 2.2) used in the experiments. \n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tmikolov/word2vec\nCitation Context: The dimension of word embeddings is set to 200, which is initialized with pre-trained word2vec vectors [URL_CITE] . The vocabulary is comprised of the most frequent 31,000 words.\nFootnote or Reference text (if exists): 3 https://github.com/tmikolov/word2vec\nSection Titles (if exists):  ['4 Experiments', '4.3 Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/Wikipedia:FA\nCitation Context: We applied the best-performing model from Section 3.3 trained on the entire WPEC to automatically classify all edits in the Wikipedia Quality Assessment Corpus (WPQAC) as presented in previous work (Daxenberger and Gurevych, 2012). WPQAC consists of 10 fea-tured and 10 non-featured articles [URL_CITE] , with an over-all number of 21,578 revisions (9,986 revisions from featured articles and 11,592 from non-featured articles), extracted from the April 2011 English Wikipedia dump. The articles in WPQAC are care-fully chosen to form comparable pairs of featured and non-featured articles, which should reduce the noise of external influences on edit activity such as popularity or visibility.\nFootnote or Reference text (if exists): 7 http://en.wikipedia.org/wiki/Wikipedia: FA\nSection Titles (if exists):  ['5 A closer look at edit sequences: Mining collaboration patterns']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.texar.io.1\nCitation Context: The versatile toolkit also fosters technique sharing across different text generation tasks. Texar supports both TensorFlow and PyTorch, and is released under Apache License 2.0 at [URL_CITE] https: //www.texar.io. 1\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - Texar is presented as a tool used in the research context, specifically for text generation tasks. \n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/KILT/blob/master/scripts/donwload\nCitation Context: We obtain closed-book QA datasets from https://github.com/facebookresearch/DPR/blob/master/data/downloaddata.py, knowledge-intensive language tasks from [URL_CITE] https://github.com/facebookresearch/KILT/blob/master/scripts/donwload all kilt data.py. We obtain ROPES, WIQA and QuaRTz from hug-gingface datasets (https://huggingface.co/datasets).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['D Reproducibility', 'D.1 Dataset Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://beaker.org/\nCitation Context: We supervise the Sentence Relevance module with a binary cross entropy loss for predicting these relevance labels when available. We used PyTorch (Paszke et al., 2017) and AllenNLP to implement our models and ran them on Beaker [URL_CITE] . For pre-training we use the same hyper-parameters of ESIM(Chen et al., 2017) as available in implementation of AllenNLP (Gardner et al., 2017) and fine-tune the model pa-rameters.\nFootnote or Reference text (if exists): 7 https://beaker.org/\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://bigml.cs.tsinghua.edu.cn/jun/stc.shtml/\nCitation Context: It is a sparsity-enhanced non-probabilistic topic model. We use the code released by the authors [URL_CITE] . We set the regularization constants as \u03bb = 0.3, \u03c1 = 0.0001 and the maximum number of itera-tions of hierarchical sparse coding, dictionary learning as 100.\nFootnote or Reference text (if exists): 5 http://bigml.cs.tsinghua.edu.cn/jun/stc.shtml/\nSection Titles (if exists):  ['4 Experiments', '4.1 Data and Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ryankiros/skip-thoughts/\nCitation Context: The encoder combines the sentence em-beddings to produce 4800-dimensional combine-skip vectors with the first 2400 dimensions being uni-skip model and the last 2400 bi-skip model. This work uses the 4800-dimensional vectors as they have been found to be the best performing in experiments [URL_CITE] . For training of the STGAN, the Skip-Thought encoder produces sentence embed-ding vectors which are labelled as real samples for GAN discriminator.\nFootnote or Reference text (if exists): 1 https://github.com/ryankiros/skip-thoughts/\nSection Titles (if exists):  ['3 Skip-Thought Generative Adversarial Network', '3.3 Model Architecture']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://openke.thunlp.org/\nCitation Context: Besides the toolkit, we also provide the pre-trained embeddings of several well-known large-scale KGs, which can be used directly for other relevant works without repeatedly spending much time for embedding KGs. In this paper, we mainly present the architecture design and implementa-tion of OpenKE, as well as the benchmark eval-uation results of some typical KE models im-plemented with OpenKE. Other related resources and details can be found on [URL_CITE] http://openke.thunlp.org/.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wikitravel.org/en/Wikitravel:Articletemplates/Sections\nCitation Context: Each article describes a city or a larger geo-graphic area that is of interest to tourists. In addition, all articles contain sections [URL_CITE] describing different as-pects of a city from a tourism point of view (e.g., places to see, transportation, shopping and eating). For our proof of concept, we performed IE only on the \u2018places to see\u2019 sections.\nFootnote or Reference text (if exists): 7 http://wikitravel.org/en/Wikitravel:Articletemplates/Sections\nSection Titles (if exists):  ['4 Human Subject Evaluations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce \n\n\nLet's break down why:\n\n* **ROLE: Supplement** - The citation provides information about the structure of Wikitravel articles, which supplements the main discussion about the human subject"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.acm.org/crossroads/xrds3-1/aied.html\nCitation Context: The architecture of iList includes a problem model, a constraint evaluator, a feedback manager, and a graphical user interface. Student model and pedagogical module, important components of a complete ITS (Beck et al., 1996) [URL_CITE] , have not been implemented yet, and will be included in a future version. Currently, the system provides only simple negative feedback in response to students\u2019 mistakes, as customary in constraint-based ITSs.\nFootnote or Reference text (if exists): Joseph Beck, Mia Stern, and Erik Haugsjaa. 1996. Applications of AI in education. ACM crossroads. http://www.acm.org/crossroads/xrds3-1/aied.html.\nSection Titles (if exists):  ['4 A tutoring system for linked lists']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mmoradi-iut/NLP-perturbation\nCitation Context: The perturbation methods were implemented in Python using the NLTK library. The source code is available at [URL_CITE] https://github.com/mmoradi-iut/NLP-perturbation.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Perturbation methods']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ntu.edu.au/education/langs/ielex/IE-DATA1\nCitation Context: Since we used automatic tools for preparing our corpus rather than careful linguistic analysis, our cognate list is much noiser in terms of the pres-ence of borrowed words and phonemeic transcrip-tion errors compared to the ones used by previous approaches (Swadesh, 1955; Dyen et al., 1997 [URL_CITE] ). The benefit of our mechanical preprocessing is that more cognate data can easily be made available, allowing us to effectively train richer models.\nFootnote or Reference text (if exists): I. Dyen, J.B. Kruskal, and P. Black. 1997. FILE IE-DATA1. Available at http://www.ntu.edu.au/education/langs/ielex/IE-DATA1.\nSection Titles (if exists):  ['4 Experiments', '4.1 Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Compare \n\n\nLet me explain the reasoning:\n\n* **ROLE: Material** - The cited resource is a dataset of cognate data used in previous research. This dataset is a material used for comparison"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/pytorch-pretrained-BERT\nCitation Context: In this work, we only focus on the masked token prediction. We use the PyTorch implementation of B ERT [URL_CITE] and the pre-trained weights for B ERT -large released by Devlin et al. (2018).\nFootnote or Reference text (if exists): 5 https://github.com/huggingface/ pytorch-pretrained-BERT\nSection Titles (if exists):  ['4 Model', '4.1 B ERT']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/vzhong/e3\nCitation Context: In addition, by explicitly highlighting which information still needs to be gathered, E 3 provides a more ex-plainable alternative to prior work. We release source code for our models and experiments at [URL_CITE] https://github.com/vzhong/e3.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.seas.upenn.edu/\u223cpdtb/tools.shtml#annotator\nCitation Context: The source of these files is Xinhua newswire. The annotation is carried out on the PDTB annotation tool [URL_CITE] .\nFootnote or Reference text (if exists): 3 http://www.seas.upenn.edu/\u223cpdtb/tools.shtml#annotator\nSection Titles (if exists):  ['4 Annotation experiment', '4.1 Set-up']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/salesforce/cove\nCitation Context: Both passage and question use a shared two-layers BiLSTM as the contextual encoding layer, which projects the lexicon embeddings to contextual embeddings. We concatenate a pre-trained 600-dimensional CoVe vectors [URL_CITE] (McCann et al., 2017) trained on German-English machine translation dataset, with the aforementioned lexicon embeddings as the fi-nal input of the contextual encoding layer, and also with the output of the first contextual encoding layer as the input of its second encoding layer. To reduce the parameter size, we use a maxout layer (Goodfellow et al., 2013) at each BiLSTM layer to shrink its dimension.\nFootnote or Reference text (if exists): 1 https://github.com/salesforce/cove\nSection Titles (if exists):  ['2 Proposed model: SAN']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/transformers\nCitation Context: The whole framework is built on Py-Torch (Paszke et al., 2019). The implementations of BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019) are borrowed from PyTorch Trans-formers (Wolf et al., 2019) [URL_CITE] . All evaluation code is from the PyTorch Transformers as well.\nFootnote or Reference text (if exists): 11 https://github.com/huggingface/ transformers\nSection Titles (if exists):  ['A Appendices', 'A.1 Full Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://casmacat.eu/corpus/global-voices.html\nCitation Context: Much of our data comes from WikiMatrix (Schwenk et al., 2019), a large collection of parallel data extracted from Wikipedia, and for more domain variety, we added Global Voices, [URL_CITE] EuroParl (Koehn, 2005) (random subset of to 100k sentence pairs per language pair), SETimes, United Nations (Eisele and Chen, 2010) (random sample of 1M sentence pairs per language pair). We also included WMT Kazakh\u2013English and Kazakh\u2013Russian data from WMT, to be able to evaluate on Kazakh.\nFootnote or Reference text (if exists): 10 http://casmacat.eu/corpus/global-voices.html\nSection Titles (if exists):  ['B Data Details for Replication']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/UFAL-DSG/tgen\nCitation Context: \u2022 TG EN : [URL_CITE] The system by Dus\u030cek and Jurc\u030c\u0131\u0301c\u030cek (2015) learns to incrementally generate deep-syntax dependency trees of candidate sentence plans (i.e. which MR elements to mention and the overall sentence structure). Surface realisation is performed using a separate, domain-independent rule-based module.\nFootnote or Reference text (if exists): 3 https://github.com/UFAL-DSG/tgen\nSection Titles (if exists):  ['2 End-to-End NLG Systems']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://git.io/JU0JJ\nCitation Context: It also sub-stantially outperforms the previous grounded model, with largest improvements on more \u2018abstract\u2019 categories (e.g., +55.1% recall on VPs). [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code is available at https://git.io/JU0JJ.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1109/ICDM.2015.68\nCitation Context: Domain-Specific Models Only LS 77.80 77.88 81.63 84.33 80.41 SVM 78.56 78.66 83.03 84.74 81.25 LR 79.73 80.14 84.54 86.10 82.63 MLP 81.70 81.65 85.45 85.95 83.69 Shared Model Only LS 78.40 79.76 84.67 85.73 82.14 SVM 79.16 80.97 85.15 86.06 82.83 LR 80.05 81.88 85.19 86.56 83.42 MLP 82.40 82.15 85.90 88.20 84.66 MAN-L2-MLP 82.05 83.45 86.45 88.85 85.20 MAN-NLL-MLP 81.85 83.10 85.75 89.10 84.95 Shared-Private Models RMTL 1 81.33 82.18 85.49 87.02 84.01 MTLGraph 2 79.66 81.84 83.69 87.06 83.06 CMSC-LS 3 82.10 82.40 86.12 87.56 84.55 CMSC-SVM 3 82.26 83.48 86.76 88.20 85.18 CMSC-LR 3 81.81 83.73 86.67 88.23 85.11 SP-MLP 82.00 84.05 86.85 87.30 85.05 MAN-L2-SP-MLP ( 82 \u00b10 .46 83.98 87.22* 88.53 85.55* .25) (\u00b10.17) (\u00b10.04) (\u00b10.19) (\u00b10.07) MAN-NLL-SP-MLP 82.98* 84.03 87.06 88.57* 85.66* (\u00b10.28) (\u00b10.16) (\u00b10.23) (\u00b10.15) (\u00b10.14) 1 Evgeniou and Pontil (2004) 2 Zhou et al. (2011) 3 Wu and Huang (2015) [URL_CITE] 3 Zhao et al. (2017)\nFootnote or Reference text (if exists): Fangzhao Wu and Yongfeng Huang. 2015. Collabora-tive multi-domain sentiment classification. In 2015 IEEE International Conference on Data Mining. pages 459\u2013468. https://doi.org/10.1109/ICDM.2015.68.\nSection Titles (if exists):  ['3 Theories of Multinomial Adversarial Networks']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Supplement\nTYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/soskek/bookcorpus\nCitation Context: The original BookCorpus (Zhu et al., 2015) is no longer avail-able, so we collect similar data from Smashwords, the original source of BookCorpus. [URL_CITE]\nFootnote or Reference text (if exists): 5 We collect our data using the Wikipedia XML dump https://dumps.wikimedia.org/mirrors.html and data-processing code https://github.com/attardi/wikiextractor, and a Smashwords crawler https://github.com/soskek/bookcorpus.\nSection Titles (if exists):  ['4 Models, Pretraining, & Fine-Tuning', '4.1 Pretraining']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://data.statmt.org/news-crawl/en/\nCitation Context: For semi-supervised learning, we sample addi-tional English monolingual data from News Crawl 2017. [URL_CITE] We randomly sample 5K, 10K, 20K, 50K, and 100K sentences, which are about half, equal, double, 5-times, 10-times the size of the parallel training set. For transfer and multilingual train-ing experiments, we use 12K, 23K, or 58K X-En (X=Czech/German/Russian/Chinese) parallel examples, which are equal, double, and 5-times the size of Chr-En training set.\nFootnote or Reference text (if exists): 18 http://data.statmt.org/news-crawl/en/\nSection Titles (if exists):  ['B Experimental Details', 'B.1 Data and Preprocessing']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ling.upenn.edu/hist-corpora/PPCEME-RELEASE-2/index.html\nCitation Context: 1 The other treebanks in the series cover Early Modern En-glish (Kroch et al., 2004) [URL_CITE] (1.8 million words), Middle Eng-lish (Kroch and Taylor, 2000) (1.2 million words), and Early English Correspondence (Taylor et al., 2006) (2.2 million words).\nFootnote or Reference text (if exists): Anthony Kroch, Beatrice Santorini, and Ariel Diertani. 2004. Penn-Helsinki Parsed Cor-pus of Early Modern English. http: //www.ling.upenn.edu/hist-corpora/ PPCEME-RELEASE-2/index.html.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tensorflow/models/tree/master/research/object_detection\nCitation Context: Out-of-vocabulary words are initialized with zero vectors. We adopt the \u201cssd resnet 50 fpn coco\u201d model from Tensorflow detection model zoo [URL_CITE] as the object detection mod-ule. The size of hidden states in the LSTM module is set to 200, and the size of the projected embed-ding for computing similarity between text spans and object labels is 512.\nFootnote or Reference text (if exists): 5 https://github.com/tensorflow/models/tree/master/research/object_detection\nSection Titles (if exists):  ['5 The Experiment', '5.2 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/P16-1101\nCitation Context: The input for each word is represented via con-catenation of a 100-dimensional embedding of the word, a 100-dimensional embedding of a predicted part of speech (POS) tag, and a 30-dimensional character-level representation from CNNs that have been found to capture morpho-logical information (Santos and Zadrozny, 2014; Chiu and Nichols, 2016; Ma and Hovy, 2016 [URL_CITE] ). The CNNs encode each character in a word by a 30 dimensional vector and 30 filters produce a 30 dimensional vector for the word.\nFootnote or Reference text (if exists): Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. In ACL. Association for Computational Linguistics, Berlin, Germany, pages 1064\u20131074. http://www.aclweb.org/anthology/P16-1101.\nSection Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model', '2.1.1 Input Representations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aclweb.org/anthology/P96-1011\nCitation Context: For our models, we adopt the pruning strate-gies in Lewis and Steedman (2014) and allow at most 50 categories per word, use a variable-width beam with \u03b2 = 0.00001, and utilize a tag dictio-nary, which maps frequent words to the possible supertags 7 . Unless otherwise stated, we only al-low normal form parses (Eisner, 1996 [URL_CITE] ; Hocken-maier and Bisk, 2010), choosing the same subset of the constraints as Lewis and Steedman (2014).\nFootnote or Reference text (if exists): Jason Eisner. 1996. Efficient Normal-Form Parsing for Combinatory Categorial Grammar. In 34th Annual Meeting of the Association for Computational Lin-guistics. http://aclweb.org/anthology/P96-1011.\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2002T31\nCitation Context: The MATRES dataset (Ning et al., 2018) has become a de facto standard for temporal order-ing of events. 1 It contains 13,577 pairs of events annotated with a temporal relation (Before, After, Equal, Vague) within 256 English documents (and 20 more for evaluation) from TimeBank 2 (Puste-jovsky et al., 2003), AQUAINT [URL_CITE] (Graff, 2002) and Platinum (UzZaman et al., 2013).\nFootnote or Reference text (if exists): 3 https://catalog.ldc.upenn.edu/ LDC2002T31\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1007/978-3-540-\nCitation Context: For any fixed F s , with either NLL or L2 loss, the optimum domain discriminator D \u21e4 is: grangian Multiplier to solve the minimum value of J D , and the details can be found in the Ap-pendix. We then have the following main theo-rems for the domain loss for F s : to its optimality, if D adopts the NLL loss: where JSD(\u00b7) is the generalized Jensen-Shannon Divergence (Lin, 1991) among multiple distribu-tions, defined as the average Kullback-Leibler di-vergence of each P i to the centroid P (Aslam and Pavlu, 2007) [URL_CITE] .\nFootnote or Reference text (if exists): Javed A. Aslam and Virgil Pavlu. 2007. Query hardness estimation using jensen-shannon di-vergence among multiple scoring functions. In Advances in Information Retrieval. Springer Berlin Heidelberg, Berlin, Heidelberg, pages 198\u2013209. https://doi.org/10.1007/978-3-540- 71496-5 20.\nSection Titles (if exists):  ['3 Theories of Multinomial Adversarial Networks']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\nCitation Context: ResNeXt WSL We first experiment with im-age representations obtained from pre-training a ResNeXt 32x48d model on nearly 1 billion pub-lic images (Mahajan et al., 2018), with subse-quent fine-tuning on the ImageNet1K dataset (Rus-sakovsky et al., 2015) [URL_CITE] . The output of this model is a 2048-dimensional vector, and we refer to these representations as \u201cResNeXt WSL\" features.\nFootnote or Reference text (if exists): 4 https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\nSection Titles (if exists): [\\'References\\']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a pre-trained model, which is a type of software artifact used as a building block in"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://code.google.com/p/ttc-project\nCitation Context: The French and English documents were then normalised through the following linguistic pre-processing steps: tokenisation, part-of-speech tag-ging, and lemmatisation. These steps were car-ried out using the TTC TermSuite [URL_CITE] that applies the same method to several languages including French and English. Finally, the function words were removed and the words occurring less than twice in the French part and in each English part were discarded.\nFootnote or Reference text (if exists): 4 http://code.google.com/p/ttc-project\nSection Titles (if exists):  ['3 Linguistic Resources', '3.1 Specialized Comparable Corpora']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://hadi763.wordpress.com/\nCitation Context: The first dataset, Web dataset, is scraped from Ro-man Urdu websites on news , poetry [URL_CITE] , SMS and blog . The second dataset, SMS dataset, is ob-tained from chopaal, an internet based group SMS service .\nFootnote or Reference text (if exists): 6 https://hadi763.wordpress.com/\nSection Titles (if exists):  ['4 Experimental Evaluation', '4.1 Dataset and Gold Standard']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf\nCitation Context: In this paper, we thus propose Multinomial Ad-versarial Networks (henceforth, MANs) for the task of multi-domain text classification. In contrast to standard adversarial networks (Goodfellow et al., 2014) [URL_CITE] , which serve as a tool for minimizing the divergence between two distributions (Nowozin et al., 2016), MANs represent a family of theoret-ically sound adversarial networks that, in contrast, leverage a multinomial discriminator to directly minimize the divergence among multiple proba-bility distributions. And just as binomial adversar-ial networks have been applied to numerous tasks (e.g.\nFootnote or Reference text (if exists): Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in Neural Information Processing Systems 27, Curran Associates, Inc., pages 2672\u20132680. http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Paper\nFUNCTION: Compare \n\n\nLet me explain:\n\n* **ROLE: Method** - The cited paper introduces the concept of Generative Adversarial Networks (GANs), which are a fundamental method used in the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use two sets of 300-dimensional pre-trained embeddings, word2vec 1 and GloVe [URL_CITE] , forming two channels for our network. For all datasets, we use 100 convolution filters each for window sizes of 3, 4, 5. Rectified Linear Units (ReLU) is chosen as the nonlinear function in the convolutional layer.\nFootnote or Reference text (if exists): 2 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['5 Experiments', '5.2 Training Details and Implementation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.isi.edu/~cyl/ROUGE\nCitation Context: For evaluation, we used the new automatic sum-mary evaluation metric, ROUGE [URL_CITE] , which was used for the first time in DUC 2004. ROUGE is a recall-based metric for fixed-length summaries which is based on n-gram co-occurence.\nFootnote or Reference text (if exists): 1 http://www.isi.edu/\u02dccyl/ROUGE\nSection Titles (if exists):  ['4 Experiments on DUC 2004 data', '4.1 DUC 2004 data and ROUGE']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/artetxem/monoses\nCitation Context: We thus conclude that, contrary to recent trend, future work in BLI should not focus exclusively in direct retrieval approaches, nor should BLI be the only evaluation task for cross-lingual embeddings. Our code is available at [URL_CITE] https://github.com/artetxem/monoses.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['6 Conclusions and future work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is presented as a tool used in the research, specifically to demonstrate the findings.\n* **TYPE: Code**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/\nCitation Context: This subset of word pairs was chosen using an adaptation of the Symmetric Delete spelling correction algorithm described by Garbe (2012) [URL_CITE] , which we denote as symDelete(\u00b7,\u00b7,\u00b7). This al-gorithm takes as arguments the target vocabulary, source vocabulary, and a constant k, and identifies all source-target word pairs that are identical af-ter k or fewer deletions from each word; that is, all pairs where each is reachable from the other with no more than k insertions and k deletions. For example, the Italian-English pair moderno-modern will be identified with k = 1, and the pair tollerante-tolerant will be identified with k = 2.\nFootnote or Reference text (if exists): Wolf Garbe. 2012. 1000x faster spelling correc-tion algorithm. http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/. Accessed: 2018-02-12.\nSection Titles (if exists):  ['4 Orthographic Similarity Adjustment']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2011T13\nCitation Context: We take the same character un-igram and bigram embeddings as Zhang et al. (2016), who pretrain embeddings using word2vec (Mikolov et al., 2013) on Chinese Gigaword [URL_CITE] . The vocabulary of subword is constructed with 200000 merge operations and the subword embeddings are also trained using word2vec (Heinzerling and Strube, 2018).\nFootnote or Reference text (if exists): 3 https://catalog.ldc.upenn.edu/LDC2011T13.\nSection Titles (if exists):  ['4 Experiments', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/rycolab/info-theoretic-probing\nCitation Context: We evaluate on a set of ten typologically diverse languages often under-represented in NLP research\u2014plus English\u2014 totalling eleven languages. Our implementa-tion is available in [URL_CITE] https://github.com/rycolab/info-theoretic-probing.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/clinc/oos-eval\nCitation Context: We use a recently-released dataset, CLINC150, [URL_CITE] for multi-domain intent detection (Larson et al., 2019). The CLINC150 dataset defines 150 types of intents in total (i.e., N = 150), where there are 10 different domains and 15 intents for each of them. Table 2 shows the dataset statistics.\nFootnote or Reference text (if exists): 3 https://github.com/clinc/oos-eval.\nSection Titles (if exists):  ['4 Experimental Settings', '4.1 Dataset: Multi-Domain Intent Detection']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/SinaWeibo\nCitation Context: To study the profile consistency identification prob-lem, we use data from Weibo [URL_CITE] , a popular and plenti-ful Chinese social media, in which people routinely respond to different posts and have publicly avail-able profiles, such as gender and location. We fol-low the protocol of the previous profile-based dia-logue dataset (Qian et al., 2018; Zheng et al., 2019) to collect Weibo post-response pairs, together with users\u2019 available profiles.\nFootnote or Reference text (if exists): 1 https://en.wikipedia.org/wiki/Sina Weibo\nSection Titles (if exists):  ['2 Dataset Preparation', '2.1 Data Collection']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://workshop2016.iwslt.org/\nCitation Context: We have evaluated these systems over three publicly-available datasets from the 2016 ACL Conference on Machine Translation (WMT16) and the 2016 International Workshop on Spoken Language Translation (IWSLT16) [URL_CITE] . Table 1 lists the datasets and their main features.\nFootnote or Reference text (if exists): 5 IWSLT16: https://workshop2016.iwslt.org/\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE:  Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://x-factr.github.io\nCitation Context: We run both the independent and confidence-based decoding methods with 3 M-LMs, and when avail-able 8 monolingual LMs, across 23 languages, [URL_CITE] with results shown in Fig. 3.\nFootnote or Reference text (if exists): 6 Check https://x-factr.github.io for latest results.\nSection Titles (if exists):  ['5 X-FACTR Benchmark Performance', '5.1 Experimental Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://bit.ly/2LObQhV\nCitation Context: To sample CPU power consumption, we use Intel\u2019s Running Average Power Limit interface. [URL_CITE]\nFootnote or Reference text (if exists): 3 RAPL power meter: https://bit.ly/2LObQhV\nSection Titles (if exists):  ['2 Methods']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.speech.sri.com/projects/srilm/\nCitation Context: \u2022 language models: Akamon can make use of one or many n-gram language models trained by using SRILM [URL_CITE] (Stolcke, 2002) or the Berke-ley language model toolkit, berkeleylm-1.0b3 (Pauls and Klein, 2011). The weights of multi-ple language models are tuned under minimum error rate training (MERT) (Och, 2003).\nFootnote or Reference text (if exists): 5 http://www.speech.sri.com/projects/srilm/\nSection Titles (if exists):  ['2 Akamon Toolkit Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cfilt.iitb.ac.in/cognitive-nlp/\nCitation Context: Secondly, we show that if a reader has understood the text com-pletely, their gaze behaviour is more reliable. Thirdly, we also release our dataset [URL_CITE] to help in further research in using gaze features in other tasks involving predicting the quality of texts.\nFootnote or Reference text (if exists): 3 The dataset can be downloaded from http://www.cfilt.iitb.ac.in/cognitive-nlp/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://ai.tencent.com/ailab/nlp/dialogue/datasets/grayscale_data_release.zip\nCitation Context: To facilitate further research, we have made our col-lected grayscale data publicly available. [URL_CITE] During training, we use these grayscale responses in a way adaptive to the training matching model. At each training epoch, ten different grayscale responses are used: the top 5 retrieval responses ranked by the current matching model and all 5 seq2seq gen-eration responses.\nFootnote or Reference text (if exists): 1 Related resources can be found at https: //ai.tencent.com/ailab/nlp/dialogue/ datasets/grayscale_data_release.zip\nSection Titles (if exists):  ['4 Experimental Setup', '4.3 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/kaushalshetty/Structured-Self-Attention\nCitation Context: Through the channel-attention network, we can observe the attention matrix A for each input doc-ument. By summing up the attention weights of each word embedding vector, we can visualize the overall attention for that word with the visualiza-tion tool [URL_CITE] . We randomly select three movies from IMDb testing set (See Figure 5).\nFootnote or Reference text (if exists): 5 The visualization tool is provided by https://github.com/kaushalshetty/ Structured-Self-Attention\nSection Titles (if exists):  ['3 Experiments & Analysis', '3.4 More Analysis in Rank-AE']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool** - The artifact is a code repository providing a visualization tool, which is a type of tool used in the research process.\n*"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.bitterlemons.org\nCitation Context: Our corpus consists of articles published on the bitterlemons website [URL_CITE] . The website is set up to \u201ccontribute to mutual understanding [between Palestinians and Israels] through the open exchange of ideas\u201d.\nFootnote or Reference text (if exists): 1 http://www.bitterlemons.org\nSection Titles (if exists):  ['3 Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://translate.google.com/\nCitation Context: Also, Moses (hierarchical) stands for the hi-erarchical phrase-based SMT system and Moses (phrase) stands for the flat phrase-based SMT sys-tem. For intuitive comparison (note that the result achieved by Google is only for reference and not a comparison, since it uses a different and unknown training data) and following (Goto et al., 2011), the scores achieved by using the Google online transla-tion system [URL_CITE] are also listed in this table.\nFootnote or Reference text (if exists): 4 http://translate.google.com/\nSection Titles (if exists):  ['2 Akamon Toolkit Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://blogs.bing.com/search/2013/03/21/understand-your-world-with-bing/\nCitation Context: To identify the replaceable entities, we apply named entity recognition (NER) and POS tag-ging using the Stanford CoreNLP toolkit (Man-ning et al., 2014). We allow for replacement of only those entities that are well-known, according to the Microsoft Knowledge Base [URL_CITE] . This improves the likelihood that the terms are familiar to both headline editors and humor judges.\nFootnote or Reference text (if exists): 1 http://blogs.bing.com/search/2013/03/21/understand-your-world-with-bing/\nSection Titles (if exists):  ['2 The Humor Dataset', '2.1 Task Description']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Knowledge\nTYPE:  DataSource\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Knowledge:** The Microsoft Knowledge Base is a source of factual information, which is a type of knowledge.\n* **TYPE: DataSource"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dcferreira/multilingual-joint-embeddings\nCitation Context: We report results on two experiments: one on cross-lingual classification on the Reuters RCV1/RCV2 dataset, and another on multi-label classification with multilingual embeddings on the TED Corpus. [URL_CITE]\nFootnote or Reference text (if exists): 5 Our code is available at https: //github.com/dcferreira/ multilingual-joint-embeddings.\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://sourceforge.net/projects/sserver/\nCitation Context: R OBO C UP ( www.robocup.org ) is an AI research initiative using robotic soccer as its primary domain. In the R OBO C UP Coach Competi-tion, teams of agents compete on a simulated soccer field and receive coach advice written in a formal language called CL ANG (Chen et al., 2003) [URL_CITE] . Fig-ure 1 shows a sample MR in CL ANG .\nFootnote or Reference text (if exists): M. Chen et al. 2003. Users manual: RoboCup soc-cer server manual for soccer server version 7.07 and later. Available at http://sourceforge.net/projects/sserver/.\nSection Titles (if exists):  ['2 Application Domains']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ilk.uvt.nl/sabine/chunklink/\nCitation Context: 1 Software available at [URL_CITE] http://ilk.uvt.nl/sabine/chunklink/\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['2 Unsupervised Relation Extraction Problem', '2.1 Context Vector and Feature Design']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The citation refers to software used in the research process, making it a methodological tool.\n* **TYPE: Tool"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://languagetool.org/\nCitation Context: We use (1) attack success rate \u2013 the ratio of the suc-cessful attacks to total number of attacks, (2) query count \u2013 the number of queries, (3) perturbation rate \u2013 the percentage of words substituted in an in-put and (4) grammatical correctness \u2013 the average grammatical error increase rate (calculated using Language-Tool [URL_CITE] ) to verify the quality of generated adversarial examples. For all the metrics except attack success rate, lower the value better the re-sult.\nFootnote or Reference text (if exists): 2 https://languagetool.org/\nSection Titles (if exists):  ['4 Experiments', '4.4 Evaluation Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/artetxem/monoses\nCitation Context: Our experiments show the effective-ness of our approach, as we improve the previous state-of-the-art in unsupervised machine transla-tion by 5-7 BLEU points in French-English and German-English WMT 2014 and 2016. Our code is available as an open source project at [URL_CITE] https: //github.com/artetxem/monoses.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['6 Conclusions and future work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://youtu.be/bcEysXmR09c\nCitation Context: Ecco is available at https: //www.eccox.io/ . [URL_CITE]\nFootnote or Reference text (if exists): 2 Video demo available at https://youtu.be/ bcEysXmR09c\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The video is supplementary material that provides a demonstration of the Ecco system. It's not directly used in the research"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf\nCitation Context: However, it cannot fully take advantage the training data if it comes from multiple source domains. MS,ST adaptation (Mansour et al., 2009 [URL_CITE] ; Zhao et al., 2017) can deal with multiple source domains but only transfers to a single target domain. Therefore, when multiple target domains exist, they need to treat them as independent prob-lems, which is more expensive and cannot utilize the additional unlabeled data in these domains.\nFootnote or Reference text (if exists): Yishay Mansour, Mehryar Mohri, and Afshin Ros-tamizadeh. 2009. Domain adaptation with multiple sources. In Advances in Neural Information Processing Systems 21, Curran Associates, Inc., pages 1041\u20131048. http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/fairseq-py\nCitation Context: For C ONV S2S [URL_CITE] and T-C ONV S2S, we used 512 dimensional hidden states and 512 dimensional word and position embeddings. We trained our convolutional models with Nesterov\u2019s accelerated gradient method (Sutskever et al., 2013) using a momentum value of 0.99 and renormalized gra-dients if their norm exceeded 0.1 (Pascanu et al., 2013).\nFootnote or Reference text (if exists): 3 We used the code available at https://github.com/facebookresearch/fairseq-py.\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://web.stanford.edu/~jurafsky/ws97/manual.august1.html\nCitation Context: The SwDA cor-pus conforms to the damsl tag schema. [URL_CITE] We as-sembled the tag sets referring to easy damsl (Iso-mura et al., 2009) into 9 tags (Table 2) in order to consolidate tags with a significantly low fre-quency. The SwDA corpus provides transcriptions of 1, 155 conversations with 219, 297 utterances.\nFootnote or Reference text (if exists): 1 https://web.stanford.edu/\u02dcjurafsky/ws97/manual.august1.html\nSection Titles (if exists):  ['4 Experiment', '4.1 Switch Board Dialogue Act Corpus (SwDA)']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Document\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The resource is a manual describing the DAMSL tag schema, which is a foundational element for understanding and working with the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: http://nlp.stanford.edu/projects/chinese-nlp.shtml\\\\#cws\nCitation Context: We compare our method with three baseline methods. The first two are both famous Chinese word segmentation tools: ICTCLAS and Stan-ford Chinese word segmenter [URL_CITE] , which are widely used in NLP related to word segmentation. Stan-ford Chinese word segmenter is a CRF-based seg-mentation tool and its segmentation standard is chosen as the PKU standard, which is the same to ours.\nFootnote or Reference text (if exists): 4 http://nlp.stanford.edu/projects/chinese-nlp.shtml\\\\#cws\nSection Titles (if exists): ['3 Experiment', '3.1 Data set']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pku-wuwei/QCN\nCitation Context: \u2022 Our proposed Question Condensing Net-works (QCN) achieves the state-of-the-art performance on two SemEval CQA datasets, outperforming all exisiting SOTA models by a large margin, which demonstrates the effec-tiveness of our model. [URL_CITE]\nFootnote or Reference text (if exists): 3 An implementation of our model is available at https: //github.com/pku-wuwei/QCN.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aspell.net/\nCitation Context: (2010)). We use the Aspell dictionary (v6.06) [URL_CITE] to determine whether a word is IV, and only include in our normalisation dictionary OOV tokens with at least 64 occurrences in the corpus and character length \u2265 4, both of which were determined through empirical observation. For each OOV word type in the corpus, we select the most similar IV type to form (OOV, IV) pairs.\nFootnote or Reference text (if exists): 2 http://aspell.net/\nSection Titles (if exists):  ['4 Contextually-similar Pair Generation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The Aspell dictionary provides a source of knowledge about words (whether they are considered \"in-vocabulary\" or"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.opensubtitles.org/\nCitation Context: Our English-Portuguese training corpus consists of 28.5 Million segments from the Europarl, JRC-Aquis (Steinberger et al., 2006) and OpenSubti-tles [URL_CITE] corpora.\nFootnote or Reference text (if exists): 5 http://www.opensubtitles.org/\nSection Titles (if exists):  ['A.3 English-Portuguese']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dl.dropbox.com/u/513347/resources/data-emnlp2012.zip\nCitation Context: We built two datasets of adjective-noun phrases for the present research, one with color terms and one with intensional adjectives. [URL_CITE] Color terms. This dataset is populated with a ran-domly selected set of adjective-noun pairs from the space presented above.\nFootnote or Reference text (if exists): 6 Available at http://dl.dropbox.com/u/513347/resources/data-emnlp2012.zip. See Bruni et al. (to appear) for an analysis of the color term dataset from a multi-modal perspective.\nSection Titles (if exists):  ['p = Bv (5)', '3.3 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hohocode.github.io/textSimilarityConvNet/\nCitation Context: Everything necessary to replicate our experimen-tal results can be found in our open-source code repository. [URL_CITE]\nFootnote or Reference text (if exists): 4 http://hohocode.github.io/textSimilarityConvNet/\nSection Titles (if exists):  ['6 Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** -  The code repository is directly used in the research to produce the experimental results.\n* **TYPE: Code** - The"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wndomains.itc.it\nCitation Context: To form a lexicon required for the identification of this feature, we extract from W ORD N ET D OMAINS [URL_CITE] all the synsets labeled with the domain S EXUALITY . The list is further processed by removing all words with high polysemy (\u2265 4).\nFootnote or Reference text (if exists): 3 W ORD N ET D OMAINS assigns each synset in W ORD N ET with one or more \u201cdomain\u201d labels, such as S PORT , M EDICINE , E CONOMY . See http://wndomains.itc.it.\nSection Titles (if exists):  ['3 Automatic Humor Recognition', '3.1 Humor-Specific Stylistic Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/long-range-arena\nCitation Context: The open-source Long-Range Arena (LRA) benchmark [URL_CITE] has been proposed as a standard way to probe and quantify the capabilities of var-ious xformer (long-range Transformer) architec-tures (Tay et al., 2020c). In our case, it also serves to highlight the effectiveness of the inductive bias inspired by the H-Matrix method, as well as the capability of our hierarchical attention to handle long sequences.\nFootnote or Reference text (if exists): 7 https://github.com/google-research/long-range-arena\nSection Titles (if exists):  ['8 Experiments And Results', '8.1 Long-Range Arena']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://nlp.stanford.edu/projects/glove/\nCitation Context: In addition, if the vocabulary for BoW is available, e.g. IMDb and Wiki10, the Word Embedding component is initialized by Glove [URL_CITE] , a pre-trained word embed-dings of 100 dimensions; if it is not, e.g. Medi-amill, Delicious and RCV, a random initialization is employed.\nFootnote or Reference text (if exists): 4 https://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['3 Experiments & Analysis', '3.1 Dataset & Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.mturk.com/\nCitation Context: We randomly select 100 candidates and compare the outputs of different systems. We use Ama-zon Turk [URL_CITE] for human evaluation. Each candidate is rated by three annotators and we report the av-erage scores here.\nFootnote or Reference text (if exists): 8 https://www.mturk.com/ tent preservation. Mean denotes the average of the met-\nSection Titles (if exists):  ['3 Experiments', '3.5 Human Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/neulab/NL2code\nCitation Context: Experiments (\u00a7 5) on two Python code gener-ation tasks show 11.7% and 9.3% absolute im-provements in accuracy against the state-of-the-art system (Ling et al., 2016). Our model also gives competitive performance on a standard semantic parsing benchmark [URL_CITE] .\nFootnote or Reference text (if exists): 1 Implementation available at https://github.com/neulab/NL2code\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/hanxiao/bert-as-service\nCitation Context: For experiments with the con-textualized representation, we adopt the pre-trained language model BERT (Devlin et al., 2019) for the four datasets. Specifically, we use bert-as-service (Xiao, 2018) [URL_CITE] to generate the contextualized word representation without fine-tuning. Following Luo et al.\nFootnote or Reference text (if exists): Han Xiao. 2018. bert-as-service. https://github.com/hanxiao/bert-as-service.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://phontron.com/lader\nCitation Context: For translation, we use Moses (Koehn et al., 2007) with lexicalized reordering (Koehn et al., 2005) in all experiments. We test three types of pre-ordering: original order with F 0 \u2190 F (orig), pre-orderings learned using the 3-step process of DeNero and Uszkoreit (2011) (3-step), and the proposed model with latent derivations (lader). [URL_CITE] Except when stated oth-erwise, lader was trained to minimize chunk fragmentation loss with a cube pruning stack pop limit of 50, and the regularization constant of 10 \u22123 (chosen through cross-validation).\nFootnote or Reference text (if exists): 7 Available open-source: http://phontron.com/lader\nSection Titles (if exists):  ['6 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/fxsjy/jieba\nCitation Context: We use the third-party tool jieba [URL_CITE] for word seg-mentation and POS tagging; both steps are cus-tomized in order to achieve a better performance on domain- and task-specific data. Specifically, the dictionary provided by the tool is inter-sected with a user-specified dictionary.\nFootnote or Reference text (if exists): 3 https://github.com/fxsjy/jieba\nSection Titles (if exists):  ['5 Processing steps', '5.1 Preprocessing']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.statmt.org/wmt14/translation-task\nCitation Context: We evaluate our method on five widely used benchmark tasks: IWSLT14 German\u2192English translation (IWSLT14 De-En) , WMT16 English\u2194Romanian translation (WMT16 En-Ro/Ro-En) , and WMT14 English\u2194German translation (WMT14 En-De/De-En) [URL_CITE] . We strictly follow the dataset configurations of previous works.\nFootnote or Reference text (if exists): 3 https://www.statmt.org/wmt14/ translation-task\nSection Titles (if exists):  ['5 Experiments', '5.1 Experimental Setup 5.1.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/seatgeek/fuzzywuzzy\nCitation Context: Figure 7: Average number of citations per paper that are 15 years or older, by venue of publication. tance ratio [URL_CITE] is \u2264 95%.\nFootnote or Reference text (if exists): 12 As implemented by https://github.com/seatgeek/fuzzywuzzy.\nSection Titles (if exists):  ['A Fuzzy paper matching']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/archive/p/word2vec/\nCitation Context: We use the 300-dimensional embeddings pretrained on the Google News corpus, which is released as part of the word2vec package. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://code.google.com/archive/p/word2vec/ ranging between 1.0 and 5.0, of 300 random words from the word-complexity lexicon vectorized into 10-dimensional rep-resentations by applying Gaussian radial basis functions.\nSection Titles (if exists):  ['3 Neural Readability Ranking Model for Words and Phrases', '3.2 Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/SussexCompSem/learninghypernyms\nCitation Context: For our evaluation on hyponymy detection, we replicate the experimental setup of Weeds et al. (2014), using their selection of word pairs [URL_CITE] from the BLESS dataset (Baroni and Lenci, 2011). These noun-noun word pairs include positive hy-ponymy pairs, plus negative pairs consisting of some other hyponymy pairs reversed, some pairs in other semantic relations, and some random pairs.\nFootnote or Reference text (if exists): 2 https://github.com/SussexCompSem/ learninghypernyms\nSection Titles (if exists):  ['5 Evaluation', '5.1 Hyponymy with Word2Vec Vectors']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt{11,12}/results.html\nCitation Context: In our experiments, we used the data available for the WMT12 and the WMT11 metrics shared tasks for translations into English. [URL_CITE] This included the output from the systems that participated in the WMT12 and the WMT11 MT evaluation cam-paigns, both consisting of 3,003 sentences, for four different language pairs: Czech-English ( CS - EN ), French-English ( FR - EN ), German-English ( DE - EN ), and Spanish-English ( ES - EN ); as well as a dataset with the English references.\nFootnote or Reference text (if exists): 3 http://www.statmt.org/wmt{11,12}/results.html\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/UKPLab/emnlp2017-cmapsum-corpus\nCitation Context: We release the corpus along with a baseline system and proposed evaluation protocol to enable further research on this variant of summarization. [URL_CITE]\nFootnote or Reference text (if exists): 1 Available at https://github.com/UKPLab/ emnlp2017-cmapsum-corpus\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.18653/v1/K17-3014\nCitation Context: Nguyen et al. (2017) [URL_CITE] incorporated a graph-based dependency parser (Kiperwasser and Goldberg, 2016) with POS tagging. Our work followed these lines of effort and improved TAG parsing perfor-mance.\nFootnote or Reference text (if exists): Dat Quoc Nguyen, Mark Dras, and Mark John-son. 2017. A novel neural network model for joint pos tagging and graph-based dependency pars-ing. In CoNLL 2017 Shared Task: Multilin-gual Parsing from Raw Text to Universal Depen-dencies. Association for Computational Linguis-tics, pages 134\u2013142. https://doi.org/10.18653/v1/K17-3014.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare \n\n\nLet me break down why:\n\n* **ROLE: Supplement** - The citation refers to a scholarly paper, which is a type of supplementary material providing background information and context for the current"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlm.nih.gov/research/umls/\nCitation Context: Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be ex-ploited systematically to improve the accuracy of the prediction task. Knowledge in this domain can be thought of as belonging to two categories: (1) Background Knowledge captured in medical ontolo-gies like UMLS (Url1, 2013) [URL_CITE] , MeSH and SNOMED CT and (2) Discourse Knowledge driven by the fact that the narratives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the lat-ter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not.\nFootnote or Reference text (if exists): Url1. 2013. Umls: Unified medical language system (http://www.nlm.nih.gov/research/umls/) (ac-cessed july 1, 2013).\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tuetschek/\nCitation Context: A Replication Instructions Dataset The E2E dataset contains a training set of 42,061 pairs of meaning representations and hu-man authored utterances, 4,672 pairs in the devel-opment set, and 4,693 in the test set. Download the dataset from [URL_CITE] https://github.com/tuetschek/ e2e-dataset .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.ownthink.com\nCitation Context: There are four types of personal information in a Chinese loan application form: \u201cSchool\u201d, \u201cCom-pany\u201d, \u201cResidence\u201d and \u201cBirthPlace\u201d. To generate derived questions, we link all personal information entities to nodes in an existing Chinese KG [URL_CITE] and crawl triplets that are directly related to them. How-ever, owing to the fact that the KG is largely sparse, nearly a half of entities cannot be linked.\nFootnote or Reference text (if exists): 3 https://www.ownthink.com\nSection Titles (if exists):  ['2 Knowledge Graph Constructor']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a Knowledge Graph (KG), which is a type of knowledge representation.  It's being"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ml4nlp.de/code-and-data/treex2conll\nCitation Context: Their annotation in the CoNLL-ST is not identi-cal, but the guidelines for \u201ccore\u201d semantic roles are similar (Kingsbury et al., 2004), so we eval-uate only on core roles here. The data for the second language pair is drawn from the Prague Czech-English Dependency Treebank 2.0 (Hajic\u030c et al., 2012), which we converted to a format simi-lar to that of CoNLL-ST [URL_CITE] . The original annotation uses the tectogrammatical representation (Hajic\u030c, 2002) and an inventory of semantic roles (or func-tors), most of which are interpretable across vari-ous predicates.\nFootnote or Reference text (if exists): 1 see http://www.ml4nlp.de/code-and-data/treex2conll\nSection Titles (if exists):  ['4 Evaluation', '4.1 Datasets and Preprocessing']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/N16-1142\nCitation Context: More closely related is our prior work (Vyas and Carpuat, 2016) [URL_CITE] where we used lexical context based embeddings to detect cross-lingual lexical entailment. In contrast, the focus of this work is on hypernymy, a more well-defined relation than entailment. Also, we improve upon our previ-ous approach by using dependency based embed-dings (\u00a76.1), and show that the improvements hold even when exposed to data scarce settings (\u00a76.3).\nFootnote or Reference text (if exists): Yogarshi Vyas and Marine Carpuat. 2016. Sparse Bilingual Word Representations for Cross-lingual Lexical Entailment. Association for Computational Linguistics, San Diego, California, pages 1187\u2013 1197. http://www.aclweb.org/anthology/N16-1142.\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dblp.uni-trier.de/db/journals/corr/corr1805.html#abs-1805-06826\nCitation Context: Propensity score based matching aims to control for most confounding variables by using an ex-ternal method for estimating and controlling for the likelihood of outcomes (Olteanu et al., 2017). More recently, (Wang and Blei, 2018) [URL_CITE] showed that with multiple causal factors, it is possible to lever-age the correlation of those multiple causal fac-tors and deconfound using a latent variable model. This setting is similar to the one we consider, and is guaranteed to be truly causal if there is no con-founder which links a single cause and the out-come.\nFootnote or Reference text (if exists): Yixin Wang and David M. Blei. 2018. The Blessings of Multiple Causes. CoRR abs/1805.06826. http: //dblp.uni-trier.de/db/journals/ corr/corr1805.html#abs-1805-06826\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/trangvu/alil-dream\nCitation Context: Our contribution are as follows: (i) we propose a sample-efficient AL policy learning method to make the best use of the annotation budget to im-prove both the student learner and the AL policy directly on the target task of interest; (ii) we pro-vide comprehensive experimental results compar-ing our method to strong heuristic-based and data-driven AL query strategy learning-based methods on cross-lingual and cross-domain text classifica-tion, and cross annotation scheme named entity recognition tasks [URL_CITE] . The experiment results demon-strate the ability of our method to quickly learn a good policy directly on the task of interest. Com-pared to the previous work (Fang et al., 2017; Liu et al., 2018a) which transfers a policy learned on a source task to target task, our dream-based AL query policies are consistently more effective even when the data domain and annotation scheme of target task are different from the source task.\nFootnote or Reference text (if exists): 1 Source code is available at https://github.com/trangvu/alil-dream\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ruotianluo/iep-ref\nCitation Context: IEP-Ref, a NMN solution based on IEP (Johnson et al., 2017b), is the current state-of-the-art model on CLEVR-Ref+ dataset. [URL_CITE] As shown Figure 2(a), the neural modules in IEP-Ref are represented using a stan-dard Residual Convolution Block (RCB). Formally, each RCB module (f n ) of arity n receives n feature maps (F i ) of shape 128 \u00d7 20 \u00d7 20 and outputs a same-sized tensor f o = f n (F 1 , F 2 , ..., F n ).\nFootnote or Reference text (if exists): 1 We used the IEP-Ref implementation provided at the link https://github.com/ruotianluo/iep-ref\nSection Titles (if exists):  ['3 Module Parameterization in NMN']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/nlpyang/PreSumm\nCitation Context: Parameters: We employ pre-trained \u2018albert-xxlarge-v2\u2019 2 and reuse the implementation of PreSumm [URL_CITE] . We train our model (with about 400M parameters) one day for 100,000 steps on GPUs(Nvidia Tesla V100, 32G) with gradient accumulation every two steps.\nFootnote or Reference text (if exists): 3 https://github.com/nlpyang/PreSumm\nSection Titles (if exists):  ['4 Experiments Setting', '4.2 Evaluation Metric & Parameter Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://fasttext.cc/docs/en/language-identification.html\nCitation Context: It is surpris-ing that almost 6% of the data seems to have the wrong source or target language. [URL_CITE]\nFootnote or Reference text (if exists): 5 LID itself may also commit errors, we used https://fasttext.cc/docs/en/language-identification.html\nSection Titles (if exists):  ['5 Experimental evaluation: improving WMT\u201914 En-De NMT systems', '5.2 Filtering Common Crawl']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.eccox.io/\nCitation Context: More curiously, we find that the model builds up syntactic information in its hidden states even when intermediate FFNNs indicate diminished levels of syntac-tic information. Ecco is available at [URL_CITE] https: //www.eccox.io/ . 2\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://creativecommons.org/licenses/by-nc-sa/4.0/\nCitation Context: Copyright Act and ensured that our collection action fell under fair use category. We release our dataset under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License [URL_CITE] .\nFootnote or Reference text (if exists): 10 https://creativecommons.org/licenses/by-nc-sa/4.0/\nSection Titles (if exists):  ['8 Ethical Considerations', '8.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION:  Use \n\n\nLet's break down why:\n\n* **ROLE: Supplement** - The citation refers to a license agreement, which provides guidelines and terms for using the dataset. It's"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.biu.ac.il/~nlp/downloads/\nCitation Context: To our knowledge, this is the first such in-depth study. [URL_CITE]\nFootnote or Reference text (if exists): 4 The guidelines and the dataset are available at http://www.cs.biu.ac.il/\u02dcnlp/downloads/\nSection Titles (if exists):  ['3 Motivation and Goals']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/software/srparser.shtml\nCitation Context: In this paper, we contribute a perceptron-based shift-reduce parsing architecture with beam search (following Zhu et al. (2013) and Bauer (2014) [URL_CITE] ) and extend it such that it can create trees with crossing branches (following Versley (2014)). We present strategies to improve performance on dis-continuous structures, such as a new feature set.\nFootnote or Reference text (if exists): John Bauer. 2014. Stanford shift-reduce parser. http://nlp.stanford.edu/software/srparser.shtml.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://pc-erato2.iei.pi.cnr.it/echo\nCitation Context: In particular the project addresses the development of generic speech recognition technology and methods to rapidly port technology to new domains and languages with limited supervision, and to produce en-riched symbolic speech transcriptions. The E CHO project ( [URL_CITE] http://pc-erato2.iei.pi.cnr.it/echo) aims to develop an infrastructure for access to histori-cal films belonging to large national audiovisual archives. The project will integrate state-of-the-art language technologies for indexing, searching and retrieval, cross-language retrieval capabilities and automatic film summary creation.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['8 Recent Research Projects']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wing.comp.nus.edu.sg/~linzihen/parser/\nCitation Context: We use the data from AESOP 2009 and 2010 as the training data, and test our metrics on AESOP 2011 data. To obtain the discourse relations of a summary, we use the discourse parser [URL_CITE] developed in Lin et al. (2010).\nFootnote or Reference text (if exists): 2 http://wing.comp.nus.edu.sg/\u02dclinzihen/parser/\nSection Titles (if exists):  ['4 DICOMER: Evaluating Summary Readability', '4.3 Predicting Readability Scores']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use two sets of 300-dimensional pre-trained embeddings, word2vec 1 and GloVe [URL_CITE] , forming two channels for our network. For all datasets, we use 100 convolution filters each for window sizes of 3, 4, 5. Rectified Linear Units (ReLU) is chosen as the nonlinear function in the convolutional layer.\nFootnote or Reference text (if exists): 2 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['5 Experiments', '5.2 Training Details and Implementation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cs229.stanford.edu/proj2017/final-reports/5242471.pdf\nCitation Context: As an emerging research problem, text-based per-sonality detection has attracted the attention of both NLP and psychological researchers (Cui and Qi, 2017 [URL_CITE] ; Xue et al., 2018; Keh et al., 2019; Jiang et al., 2020; Tadesse et al., 2018; Lynn et al., 2020).\nFootnote or Reference text (if exists): Brandon Cui and Calvin Qi. 2017. Survey analysis of machine learning methods for natural language processing for mbti per-sonality type prediction. Available on-line: http://cs229.stanford.edu/proj2017/final-reports/5242471.pdf (accessed on 26 May 2021).\nSection Titles (if exists):  ['2 Related Work', '2.1 Personality Detection']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce \n\n\nLet me explain the reasoning:\n\n* **ROLE: Supplement** - The cited document is a survey analysis, providing background information and context on the research problem of text-based personality detection"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://sites.google.com/site/naistlang8corpora/\nCitation Context: Therefore, we relax the standards of matching nodes. We establish a para-phrase table based on the statistical machine trans-lation between a parallel learner corpus [URL_CITE] . As long as the labels of two aligned nodes have the same stem or they form a paraphrase pair in our ta-ble, then the two nodes can be considered \u201cmatch-ing\u201d.\nFootnote or Reference text (if exists): 3 https://sites.google.com/site/naistlang8corpora/\nSection Titles (if exists):  ['6 Parsing to Intended Meanings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/TimDettmers/ConvE\nCitation Context: We use OpenKE for re-implementing TransE, Com-plEx, and RotatE. For the rest models, we use the original codes for ConvE [URL_CITE] , TuckER 7 , Multi-types of KGC models including embedding-based, multi-hop reasoning (reinforcement learning), and rule-based models, these models largely have their own hyperparameters. To avoid exhaustive param-eter search in a large range, we conduct a series of preliminary experiments and find that the sug-gested parameters work well on Wikidata-based data.\nFootnote or Reference text (if exists): 6 https://github.com/TimDettmers/ConvE\nSection Titles (if exists):  ['F Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/Friends\nCitation Context: Data Collection For the dyadic Speaker-Addressee Model we used scripts from the American television comedies Friends [URL_CITE] and The Big Bang Theory, available from Internet Movie Script Database (IMSDb). We collected 13 main characters from the two series in a corpus of 69,565 turns. We split the corpus into train-ing/development/testing sets, with development and testing sets each of about 2,000 turns.\nFootnote or Reference text (if exists): 2 https://en.wikipedia.org/wiki/Friends\nSection Titles (if exists):  ['5 Datasets', '5.3 Television Series Transcripts']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/microsoft/unilm\nCitation Context: BART 3 (P:0.83, R: 1.0) [URL_CITE]\nFootnote or Reference text (if exists): 7 https://github.com/microsoft/unilm 8 https://github.com/microsoft/MASS\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.unicode.org/reports/tr44/tr44-4.html#General_Category_Values\nCitation Context: We introduce the following modifica-tions for fairer multilingual evaluation: Instead of stripping ASCII punctuation, we strip all unicode characters with a punctuation General Category. [URL_CITE] When a language has stand-alone articles (English, Spanish, German and Vietnamese) we strip them. We use whitespace tokenization for all MLQA lan-guages other than Chinese, where we use the mixed segmentation method from Cui et al.\nFootnote or Reference text (if exists): 6 http://www.unicode.org/reports/tr44/tr44-4.html#General_Category_Values\nSection Titles (if exists):  ['4 Cross-lingual QA Experiments', '4.1 Evaluation Metrics for Multilingual QA']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://azure.microsoft.com/en-us/services/cognitive-services/spell-check/\nCitation Context: We resolve spelling errors with a public spell checker [URL_CITE] as preprocessing, as Xie et al. (2016) and Sakaguchi et al. (2017) do.\nFootnote or Reference text (if exists): 4 https://azure.microsoft.com/en-us/services/cognitive-services/spell-check/\nSection Titles (if exists):  ['5 Experiments', '5.2 Experimental setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\nCitation Context: For all our experiments we use the RAT-SQL of-ficial implementation and the pre-trained BERT-Large from Google. [URL_CITE] We follow the original set-tings to get the pre-fine-tuned/pre-adapted models. 8.76 18.51 24.00 16.66 21.96 23.16 \u00b1 0.5% For adaptation and fine-tuning, we decrease the learning rate of BERT parameters by 50 times to 6e-8 to avoid overfitting.\nFootnote or Reference text (if exists): 6 We use the BERT-Large, Uncased (Whole Word Mask-ing) model from https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\nSection Titles (if exists):  ['A.3 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.wordgumbo.com/ie/cmp/iedata.txt\nCitation Context: (2005), model the expan-sion of the Indo-European language family and find support for the hypothesis which places its homeland in Anatolia; Atkinson and Gray (2006) analyze language divergence dates and argue for the usage of computational phylogenetic meth-ods in the question of Indo-European age and ori-gins. Using modified versions of Swadesh\u2019s lists [URL_CITE] , Dyen et al. (1992) investigate the classification of Indo-European languages by applying a lexicosta-tistical method.\nFootnote or Reference text (if exists): 1 http://www.wordgumbo.com/ie/cmp/iedata.txt\nSection Titles (if exists):  ['1 Introduction', '1.1 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dolphin-zs/Doc2EDAG\nCitation Context: Ex-tensive experiments with comprehensive anal-yses illustrate the superiority of Doc2EDAG over state-of-the-art methods. Data and codes can be found at [URL_CITE] https://github.com/dolphin-zs/Doc2EDAG.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool within the research to achieve the stated goal of analyzing and comparing document-to-EDAG"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://duc.nist.gov/\nCitation Context: Thus, human as-sessments are in a 2-10 scale. For AS, we have used the AS test suites developed in the DUC 2005 and DUC 2006 evaluation campaigns [URL_CITE] . This AS task was to generate a question focused summary of 250 words from a set of 25-50 documents to a complex question.\nFootnote or Reference text (if exists): 4 http://duc.nist.gov/\nSection Titles (if exists):  ['4 Data Sets and Measures', '4.1 Data sets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wiki.answers.com\nCitation Context: For experiments we used 2 publicly available CQA datasets: Yahoo! Answers Comprehensive Ques-tions and Answers and a crawl of WikiAnswers [URL_CITE] (Fader et al., 2014). The Yahoo!\nFootnote or Reference text (if exists): 5 http://wiki.answers.com\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ljain2/libsvm-openset\nCitation Context: All documents use tf-idf term weighting scheme with no feature selection. Source code for different baselines (1-vs-Set Machine , W-SVM and P I - SVM [URL_CITE] , and Exploratory learning ) was provided by the authors of their original papers.\nFootnote or Reference text (if exists): 3 https://github.com/ljain2/libsvm-openset\nSection Titles (if exists):  ['4 Experiments', '4.1 Baselines']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool to implement the baselines in the experiments.\n* **TYPE: Code** - The"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/thunlp/OpenKE/tree/OpenKE-PyTorch\nCitation Context: We perform 5-shot KG completion task for all the methods. Our implementation for KG embedding baselines is based on OpenKE [URL_CITE] (Han et al., 2018) with their best hyperparameters reported in the orig-inal literature. During training, all triples in back-ground KG G 0 and training set, as well as few-shot reference triples of validation and testing set are used to train models.\nFootnote or Reference text (if exists): 2 https://github.com/thunlp/OpenKE/tree/OpenKE-PyTorch\nSection Titles (if exists):  ['5 Experiments', '5.3 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mallet.cs.umass.edu\nCitation Context: Using all available features, we compare four MAL-LET (McCallum, 2002) [URL_CITE] classifiers: logistic regres-sion, na\u0131\u0308ve Bayes, decision tree, and Winnow2. Fig-ure 1 shows the learning curves for each classifier as the number of sampled words comprising each train-ing example is varied from 10 to 1000.\nFootnote or Reference text (if exists): Andrew McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.\nSection Titles (if exists):  ['4 Word-level Language Classification', '4.2 Classifiers']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.bingiton.com/\nCitation Context: Most notably is a continued study sponsored by Pepsi, known as the Pepsi Challenge , where Pepsi demonstrates how even though people preferred the taste of Pepsi, Coca-Cola\u2019s branding has made it more popular. Even now, Microsoft uses similar blind taste tests [URL_CITE] to compare search en-gines, Bing and Google, showing that although par-ticipants prefer Bing\u2019s results, Google\u2019s brand might have strengthened over the years. These studies all suggest that brand and its associations play impor-tant roles in the customers\u2019 perceptions and deci-sions.\nFootnote or Reference text (if exists): 2 http://www.bingiton.com/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION:  Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a website, likely providing more information about the Pepsi Challenge and/or Microsoft's blind"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/sameenmaruf/selective-attn\nCitation Context: For the Transformer, we use Transformer-DyNet implementation and extend it for our context-aware NMT model. [URL_CITE] The hidden dimensions and feed-forward layer size is set to 512 and 2048 respectively. We use 4 layers each in the encoder and decoder with 8 attention heads and employ label smoothing with a value of 0.1.\nFootnote or Reference text (if exists): 8 The code is available at https://github.com/sameenmaruf/selective-attn\nSection Titles (if exists):  ['4 Experiments', '4.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/Quaternion\nCitation Context: Then, pretraining with two language modeling tasks aims to minimize both loss functions L 1 and L 2 by: L LM = argmin \u03b8 L 1 + L 2 A.2 Quaternion In mathematics, Quaternions [URL_CITE] are a hypercomplex number system. A Quaternion number P in a Quaternion space H is formed by a real component (r) and three imaginary components as follows:\nFootnote or Reference text (if exists): 5 https://en.wikipedia.org/wiki/Quaternion\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/NP-NET-research/Recursive-Semi-Markov-Model\nCitation Context: Our code is released at [URL_CITE] https://github.com/NP-NET-research/Recursive-Semi-Markov-Model, which is developed on the base of the open-source Berkekey parser (Kitaev and Klein, 2018; Kitaev et al., 2019).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being presented as a tool used in the research, specifically for implementing the Recursive-Semi-Markov-Model."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/transformers/tree/master/examples/text-classification\nCitation Context: The example code to train the NLI-style models is also available. [URL_CITE] We use the roberta-base configuration for all the RoBERTa/SRoBERTa-based models in our experiments. All the model parameters including the RoBERTa parameters are updated during all the fine-tuning processes, where we use the AdamW (Loshchilov and Hutter, 2017) optimizer with a weight decay coefficient of 0.01 for all the non-bias parameters.\nFootnote or Reference text (if exists): 11 https://github.com/huggingface/transformers/tree/master/examples/text-classification.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aclweb.org/anthology/E99-1026\nCitation Context: H EAD F INAL Among SOV languages, Japanese is known as a strictly head final language, mean-ing that the head of every word always follows it. Japanese dependency parsing (Uchimoto et al., 1999 [URL_CITE] ; Kudo and Matsumoto, 2002) has exploited this property explicitly by only allowing left-to-right dependency arcs. Inspired by this tradition, we try a simple H EAD F INAL rule in Japanese CCG parsing, in which we always select the right argument as the head.\nFootnote or Reference text (if exists): Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara. 1999. Japanese Dependency Structure Analysis Based on Maximum Entropy Models. In Ninth Conference of the European Chapter of the Association for Computational Linguistics. http://aclweb.org/anthology/E99-1026.\nSection Titles (if exists):  ['4 CCG to Dependency Conversion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://joshua-decoder.com/language-packs/paraphrase/\nCitation Context: This tool can be used to demonstrate and test a model or to hand-tune the model in order to de-termine the parameters for a configuration file to paraphrase a large batch of sentences. Detailed instructions for using the tool and shell scripts, as well as a detailed description of the config-uration file, are available at the language pack home page: [URL_CITE] http://joshua-decoder.com/language-packs/paraphrase/\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Interactive tool']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.markwatson.com/opensource/\nCitation Context: are developed that retrieve answers from the Web and other tex-tual sources. Similarly, structured QA systems (Aqualog , NLBean [URL_CITE] etc.) obtain answers from the sub-networks.\nFootnote or Reference text (if exists): 9 http://www.markwatson.com/opensource/\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/senisioi/NeuralTextSimplification\nCitation Context: Furthermore, in accor-dance with prior work on TS, we report average BLEU (Papineni et al., 2002) and SARI (Xu et al., 2016) scores for the rephrasings of each system. [URL_CITE] Finally, we computed the SAMSA and SAMSA abl score of each system, which are the first met-rics that explicitly target syntactic aspects of TS (Sulem et al., 2018b).\nFootnote or Reference text (if exists): 6 For the computation of the BLEU and SARI scores we used the implementation of Nisioi et al. (2017) which is available under https://github.com/senisioi/NeuralTextSimplification.\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://mashable.com/article/snopes-stops-fact-checking-for-facebook/\nCitation Context: On the one hand, it is un-likely fact-checkers are able to check every social media post, due to limited resources and the sheer volume of data. [URL_CITE] On the other hand, a large num-ber of false claims, likely much more than those in traditional media, are being spread through so-cial media. This can be due to the compounded effect of several factors: social media platforms have become increasingly important to public fig-ures and organizations in engaging with voters and citizens; mobile devices have brought an age in which sharing and disseminating information is easy for anyone, including both malicious and un-intentional creators of falsehoods; the falsehoods are further replicated and amplified by social me-dia bots and clickbait articles.\nFootnote or Reference text (if exists): 1 https://mashable.com/article/snopes-stops-fact-checking-for-facebook/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION:  Other \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The article cited is not directly used in the research process (like a dataset or tool). It provides context and"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.usf.edu/Freeassociation\nCitation Context: (1999). [URL_CITE] These were established by presenting a large num-ber of participants with a cue word (e.g., rice) and asking them to name an associate word in response (e.g., Chinese, wedding, food, white). For each word, the norms provide a set of associates and the fre-quencies with which they were named.\nFootnote or Reference text (if exists): 3 http://www.usf.edu/Freeassociation.\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wiki-pedia.org/wiki/List\nCitation Context: Though the idea that abbreviations and keyphrases are linked fits within our understanding of scientific writing, we confirmed our intuition through a small exper-iment. Specifically, we looked at the 85 unique keyphrases (in this case, article titles) listed in the Wikipedia entry for List of Machine Learning Concepts (Wikipedia, 2014) [URL_CITE] . These ranged from well known terms (e.g., Support Vector Machines and Autoencoders) to less known (e.g., Informa-tion fuzzy networks).\nFootnote or Reference text (if exists): Wikipedia. 2014. Wikipedia: List of ma-chine learning concepts. http://en.wiki-pedia.org/wiki/List of machine learning concepts. Accessed: 2015-2-26.\nSection Titles (if exists):  ['3 Keyphrases and Hierarchies']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6214\nCitation Context: For example, syntactic knowledge alone tells us that the sentence John, who loves Mary, saw a squirrel entails John saw a squirrel and John loves Mary but not, for in-stance, that John knows Mary or John saw an animal. Prior work found the best performance was achieved with parsers using grammatical frameworks that provided rich linguistic descrip-tions, including CCG (Rimell and Clark, 2010; Ng et al., 2010), Minimal Recursion Semantics (MRS) (Lien, 2014), and TAG (Xu et al., 2017) [URL_CITE] . Xu et al.\nFootnote or Reference text (if exists): Pauli Xu, Robert Frank, Jungo Kasai, and Owen Rambow. 2017. TAG parser evaluation us-ing textual entailments. In TAG+. Association for Computational Linguistics, Umea\u030a, Sweden, pages 132\u2013141. http://www.aclweb.org/anthology/W17-6214.\nSection Titles (if exists):  ['5 Downstream Tasks', '5.1 PETE']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The cited paper is not a tool or method used in the research, nor is it the primary source of data."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google/sentencepiece\nCitation Context: All experiments are performed with the Trans-former architecture (Vaswani et al., 2017) using the open-source Tensorflow-Lingvo implementa-tion (Shen et al., 2019). Specifically, we use the Transformer Big model containing 375M parame-ters (6 layers, 16 heads, 8192 hidden dimension) (Chen et al., 2018) and a shared source-target Sen-tencePiece model (SPM) [URL_CITE] (Kudo and Richardson, 2018). We use a vocabulary size of 32k for the bilingual models and 64k for the multilingual mod-els.\nFootnote or Reference text (if exists): 3 https://github.com/google/sentencepiece\nSection Titles (if exists):  ['3 Experimental Setup', '3.3 Architecture and Optimization']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://multiwordnet.itc.it\nCitation Context: MultiWordNet [URL_CITE] . It is a multilingual computa-tional lexicon, conceived to be strictly aligned with the Princeton WordNet.\nFootnote or Reference text (if exists): 4 Available at http://multiwordnet.itc.it.\nSection Titles (if exists):  ['4 Exploiting Bilingual Dictionaries']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://yjernite.github.io/lfqa.html\nCitation Context: This objective is based on contrastive learning, a method that has been used effectively for semi-supervised learning (Chen et al., 2020) and dense retriever training (Karpukhin et al., 2020). Scaling up from Jernite (2020) [URL_CITE] , who used a mini-batch size of 512 and initialized their retriever with BERT, we use much large mini-batches of size 12,288 (and hence, many more negative examples) and initial-ize our retriever with a strong pretrained retriever, the REALM model (Guu et al., 2020) trained on the Common Crawl News (CC-News) corpus. These design decisions greatly improve retriever qual-ity, as we observe in an ablation study (see Ap-pendix A.2).\nFootnote or Reference text (if exists): Yacine Jernite. 2020. Explain anything like i\u2019m five: A model for open domain long form question answer-ing. https://yjernite.github.io/lfqa.html.\nSection Titles (if exists):  ['2 A state-of-the-art LFQA system', '2.1 Retriever']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Compare \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The cited resource is a codebase (a model for open domain long form question answering) that serves as a basis"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.wikidata.org/\nCitation Context: For the choice of the Knowledge Base, we use a subset of Freebase [URL_CITE] that includes 3 million entities with the most connections, similar to Xu and Barbosa (2019). For all pairs appearing in the test set of NYT 10 (both positive and negative), we remove all links in the subset of Freebase to ensure that we will not memorise any relations between them (Weston et al., 2013). The resulting KB contains approximately 24 million triples.\nFootnote or Reference text (if exists): 2 https://developers.google.com/freebase 3 https://www.wikidata.org/\nSection Titles (if exists):  ['3 Experimental Settings', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jcyk/AMR-parser\nCitation Context: During testing, we use a beam size of 8 for generating graphs. [URL_CITE]\nFootnote or Reference text (if exists): 5 Our code can be found at https://github.com/jcyk/AMR-parser.\nSection Titles (if exists):  ['5 Experiments', '5.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/nyu-dl/dl4mt-tutorial\nCitation Context: \u2022 RNNSearchtentional NMT: a re-implementationsystem (Bahdanauof theet alat-., 2015) with slight changes taken from dl4mt tutorial. [URL_CITE] For the activation function f of an RNN, RNNSearch uses the gated recurrent unit (GRU) recently proposed by (Cho et al., 2014b). It incorporates dropout (Hinton et al., 2012) on the output layer and improves the attention model by feeding the lastly gen-erated word.\nFootnote or Reference text (if exists): 8 https://github.com/nyu-dl/ dl4mt-tutorial\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method:** The citation refers to a code repository, which is a tool used in the research process. \n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://tanbih.qcri.org\nCitation Context: At QCRI, he leads the Tanbih project, [URL_CITE] devel-oped in collaboration with MIT, which aims to limit the effect of \u201cfake news\u201d, propaganda and media bias by making users aware of what they are reading. The project was featured by over 100 news outlets, including Forbes, Boston Globe, Al-jazeera, MIT Technology Review, Science Daily, Popular Science, Fast Company, The Register, WIRED, and Engadget, among others.\nFootnote or Reference text (if exists): 2 Tanbih project: http://tanbih.qcri.org\nSection Titles (if exists):  ['6 Lecturers', '6.1 Preslav Nakov']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.aclweb.org/anthology/D17-1180\nCitation Context: (2016), Kasai et al. (2017) [URL_CITE] , and Fried-man et al. (2017); we use the grammar and the TAG-annotated WSJ Penn Tree Bank extracted by Chen et al.\nFootnote or Reference text (if exists): Jungo Kasai, Robert Frank, Tom McCoy, Owen Rambow, and Alexis Nasr. 2017. TAG pars-ing with neural networks and vector representa-tions of supertags. In EMNLP. Association for Computational Linguistics, Copenhagen, Denmark, pages 1713\u20131723. https://www.aclweb.org/anthology/D17-1180.\nSection Titles (if exists):  ['3 Results and Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aka.ms/WikiQA\nCitation Context: We select WikiQA [URL_CITE] as the evaluation data, as it is precisely constructed based on natural language questions and Wikipedia documents, which con-tains 2,118 \u2018question-document\u2019 pairs in the train-ing set, 296 \u2018question-document\u2019 pairs in devel-opment set, and 633 \u2018question-document\u2019 pairs in testing set. Each sentence in the document of a given question is labeled as 1 or 0, where 1 de-notes the current sentence is a correct answer sen-tence, and 0 denotes the opposite meaning.\nFootnote or Reference text (if exists): 6 http://aka.ms/WikiQA\nSection Titles (if exists):  ['7 Experiments', '7.1 Evaluation on QA (English)', '7.1.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Material** - WikiQA is a dataset specifically designed for question answering tasks. It provides labeled data (question-document pairs with answer"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ldc.upenn.edu/Projects/TIDES/Translation/TranAssessSpec.pdf\nCitation Context: There were 118 sentences, out of which 94 had at least one modification after the rewrite pro-cess. We selected 50 of these 94 sentences at ran-dom and asked 2 human judges to rate each sen-tence and its rewritten form on a scale of 1\u20135 for accuracy and fluency [URL_CITE] . We used 4 human judges, each judging 25 sentence pairs.\nFootnote or Reference text (if exists): 3 We followed the DARPA/LDC guidelines from http://ldc.upenn.edu/Projects/TIDES/Translation/TranAssessSpec.pdf. For fluency, the scale was 5:Flawless, 4:Good, 3:Non-native, 2:Disfluent, 1:Incomprehensible. The accuracy scale for information covered (comparing with human translation) was 5:All, 4:Most, 3:Much, 2:Little, 1:None.\nSection Titles (if exists):  ['3 Arbitrary noun phrases', '3.5 Manual Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://snips.ai/\nCitation Context: We also compare our proposed model C APSULE -NLU with existing commercial natural language understanding services, includ-ing api.ai (Now called DialogFlow) , Waston Assistant , Luis , wit.ai , snips.ai [URL_CITE] , recast.ai , and Amazon Lex .\nFootnote or Reference text (if exists): 6 https://snips.ai/\nSection Titles (if exists):  ['3 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://pypi.python.org/pypi/newspaper\nCitation Context: We deduplicated the 16,000 extracted URLs into 6,003 unique addressed, then extracted and preprocessed their contents. The newspaper package [URL_CITE] was used to extract article text and the title from the web page. Since we are interested in text articles that can serve as the source text for summarization algorithms, we needed to re-move photos and video links such as those from Instagram and YouTube.\nFootnote or Reference text (if exists): 2 https://pypi.python.org/pypi/newspaper\nSection Titles (if exists):  ['3 Data Extraction and Preprocessing', '3.2 Extracting Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ilk.uvt.nl/conll/software.html\nCitation Context: The labeled F 1 score [F1] 9 , de-fined by the standard protocol called PARSEVAL (Black et al., 1991), takes into account the brack-eting and labeling of nodes. The unlabeled attache-ment score [UAS] evaluates the quality of unlabeled dependencies between words of the sentence [URL_CITE] . And finally, the Leaf-Ancestor score [LA] (Sampson, 2003) computes the similarity between all paths (se-quence of nodes) from each terminal node to the root node of the tree.\nFootnote or Reference text (if exists): 10 This score is computed by using the tool available at http://ilk.uvt.nl/conll/software.html. The constituent trees are automatically converted into dependency trees with the tool Bonsai.\nSection Titles (if exists):  ['6 Evaluation', '6.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://allennlp.org/elmo\nCitation Context: We explore if contextual word embeddings obvi-ate the need for adapting source embeddings, in the ELMo (Peters et al., 2018) setting, a contex-tualized word representation model, pre-trained on a 5.5B token corpus [URL_CITE] . We compare ELMo\u2019s contextual embeddings as-is, and also after con-catenating them with each of Tgt, SrcTune, and SrcSel embeddings in Table 8.\nFootnote or Reference text (if exists): 11 https://allennlp.org/elmo\nSection Titles (if exists):  ['Topics and tasks', '4.4 Contextual embeddings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6213\nCitation Context: (2017) and Friedman et al. (2017) [URL_CITE] . For the transition-based parser, it is beneficial to share statistics among the input supertags that differ only by a certain operation or property (Kasai et al., 2017) during the training phase, yielding the success in the analogy task.\nFootnote or Reference text (if exists): Dan Friedman, Jungo Kasai, R. Thomas McCoy, Robert Frank, Forrest Davis, and Owen Rambow. 2017. Linguistically rich vector representations of supertags for TAG parsing. In TAG+. Associa-tion for Computational Linguistics, Umea\u030a, Sweden, pages 122\u2013131. http://www.aclweb.org/anthology/W17-6213.\nSection Titles (if exists):  ['4 Joint Modeling and Network Representations', '4.2 Syntactic Analogies']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION:  Use \n\n\nLet me explain:\n\n* **ROLE: Supplement** - The citation refers to a full research paper, which provides more detailed information about a specific technique or finding. It's"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use the 100-dimensional GloVe vectors [URL_CITE] (Pen-nington et al., 2014) to initialize our word embed-dings, and those words that do not appear in Glove vectors are treated as unknown. The dimension of all hidden states is set to 100 as well.\nFootnote or Reference text (if exists): 3 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['4 Experiments', '4.1 Answer Selection', '4.1.2 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cmu.edu/~ark/TweetNLP/\nCitation Context: We preprocessed Twitter dataset with Twitter NLP tool [URL_CITE] (Gimpel et al., 2011; Owoputi et al., 2013) for tokenization. For Weibo dataset, we used NLPIR tool 10 (Zhang et al., 2003) for Chi-nese word segmentation.\nFootnote or Reference text (if exists): 9 http://www.cs.cmu.edu/\u02dcark/TweetNLP/\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.lsi.upc.edu/~nlp/IQMT\nCitation Context: This approach has proven very effective in recent eval-uation campaigns. Metric computation has been carried out using the IQ MT Framework for Auto-matic MT Evaluation (Gime\u0301nez, 2007) [URL_CITE] . The sim-plicity of this approach (with no training of the metric weighting scheme) ensures that the poten-tial advantages detected in our experiments are not due to overfitting effects.\nFootnote or Reference text (if exists): 1 http://www.lsi.upc.edu/\u02dcnlp/IQMT\nSection Titles (if exists):  ['3 Metrics and Test Beds', '3.1 Metric Set']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact:\n\n* **ROLE:** Method \n* **TYPE:** Tool\n* **FUNCTION:** Use \n\n\n**Explanation:**\n\n* **ROLE: Method** - The IQMT framework is used as a tool"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/JasperGuo/Unimer\nCitation Context: Also, pro-gram alias and grammar rules heavily impact the performance of different meaning repre-sentations. Our benchmark, execution engines and implementation can be found on: [URL_CITE] https: //github.com/JasperGuo/Unimer .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/YatinChaudhary/\nCitation Context: We have shown state-of-the-art re-sults with significant gains quantified by gener-alization (perplexity), interpretability (topic co-herence) and text retrieval. The code is avail-able at [URL_CITE] https://github.com/YatinChaudhary/ Multi-view-Multi-source-Topic-Modeling . pretrained word embeddings from a WordPool at each autoregressive step i.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PhilipMay/stsb-multi-mt\nCitation Context: Training Data Table 3 presents statistics on the training data used for supervised and unsuper-vised models across the ST evaluation aspects. For datasets that are only available for EN , we use the already available machine translated re-sources for STS [URL_CITE] and formality datasets (Briakou et al., 2021b). The former employs the DeepL service (no information of translation quality is available) while the latter uses the AWS translation service (with reported BLEU scores of 37.16 ( BR -\nFootnote or Reference text (if exists): 10 https://github.com/PhilipMay/ stsb-multi-mt\nSection Titles (if exists):  ['4 Experiment Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a collection of machine translated resources used for training. This aligns with the \"Material\" role as"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.acronymsearch.com/\nCitation Context: We downloaded a list of acronyms in capital let-ters only from Wikipedia and filtered them by eliminating acronyms shorter than three letters. Then we obtained definitions for each acronym from [URL_CITE] http://www.acronymsearch.com/ and dis-carded acronyms that have less than five defini-tions. Finally, we randomly selected 20 acronyms.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Experiment', '3.1 Acronym and definition preparation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/\nCitation Context: This experiment uses the 2006\u20132008 cor-pora of the Workshop on Statistical Machine Translation (WMT). [URL_CITE] It consists of data from EU-ROPARL (Koehn, 2005) and various news com-mentaries, with five source languages (French, Ger-man, Spanish, Czech, and Hungarian). As training set, we use the portions of WMT 2006 and 2007 that are annotated with absolute scores on a five-point scale (around 14,000 sentences produced by 40 systems).\nFootnote or Reference text (if exists): 7 Available from http://www.statmt.org/.\nSection Titles (if exists):  ['6 Expt. 2: Predicting Pairwise Preferences']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/marian-nmt/marian-examples/blob/master/transformer\nCitation Context: Transformer We used the same training, dev and test sets as in the big RNN model, and the exam-ple configuration for a transformer model from Marian [URL_CITE] adapted to our needs as shown in Table 1. This configuration utilises a six-layer deep encoder and decoder, learning rate warm-up and tied em-beddings for source, target and output layer.\nFootnote or Reference text (if exists): 2 https://github.com/marian-nmt/marian-examples/blob/master/transformer\nSection Titles (if exists):  ['4 Experiment setup', '4.3 Training setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The code is used as a tool within the research process. The authors adapt an existing transformer model configuration for their experiments"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cninfo.com.cn/new/index\nCitation Context: Data Collection with Event Labeling. We uti-lize ten years (2008-2018) ChFinAnn [URL_CITE] documents and human-summarized event knowledge bases to conduct the DS-based event labeling. We focus on five event types: Equity Freeze (EF), Equity Re-purchase (ER), Equity Underweight (EU), Equity Overweight (EO) and Equity Pledge (EP), which belong to major events required to be disclosed by the regulator and may have a huge impact on the company value.\nFootnote or Reference text (if exists): 4 Crawling from http://www.cninfo.com.cn/new/index\nSection Titles (if exists):  ['6 Experiments', '6.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/donnyslin/KCAT\nCitation Context: Whereas, it\u2019s hard for human be-ings to differentiate and memorize thousands of types, thus making large-scale human la-beling hardly possible. In this paper, we in-troduce a Knowledge-Constraint Typing An-notation Tool (KCAT [URL_CITE] ), which is efficient for fine-grained entity typing annotation. KCAT reduces the size of candidate types to an ac-ceptable range for human beings through en-tity linking and provides a Multi-step Typ-ing scheme to revise the entity linking result.\nFootnote or Reference text (if exists): 1 Code is available at https://github.com/donnyslin/KCAT\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.3115/1118905.1118906\nCitation Context: Computational Linguistics, Stroudsburg, PA, USA, HLT-NAACL-PARALLEL \u201903, pages 1\u201310. [URL_CITE] https://doi.org/10.3115/1118905.1118906.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Supplement** - This citation refers to a scholarly paper, which is a type of supplementary material used to support the research presented in the current work"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mit-nlp/MITIE\nCitation Context: Class-based language models are often used alongside lexical language models to form gener-alizations. We tested a 5\u2013gram language model over CoNLL part-of-speech tags from MITIE (King, 2014) [URL_CITE] . There are fewer than 256 unique tags, fitting into a byte per word.\nFootnote or Reference text (if exists): Davis E. King. 2014. MITIE: MIT information extraction, January. https://github.com/mit-nlp/MITIE.\nSection Titles (if exists):  ['6 Experiments', '6.2 Language Modeling', '6.2.2 Vocabulary Indices']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html\nCitation Context: Finally, we automatically an-notated all utterances with part-of-speech tags, us-ing TreeTagger (Schmid, 1994), which we\u2019ve trained on the switchboard corpus of spoken lan-guage (Godfrey et al., 1992), because it contains, just like our corpus, speech disfluencies. [URL_CITE]\nFootnote or Reference text (if exists): 6 The tagger is available free for academic research from http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html.\nSection Titles (if exists):  ['3 Corpus, Features, and Data Creation', '3.1 Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://crisislex.org/data-collections.html\nCitation Context: To prepare our large multilingual dataset, we ag-gregated several resources from CrisisNLP, to-gether with two resources from CrisisLex. [URL_CITE] Specif-ically, we used Resource #1 (Imran et al., 2016a), Resource #4 (Nguyen et al., 2017), Resource #5 (Alam et al., 2018c), and Resource #7 (Alam et al., 2018a) from CrisisNLP, and CrisisLexT6 (Olteanu et al., 2014) and CrisisLexT26 (Olteanu et al., 2015) from CrisisLex. The original classes in each resource, together with the mapping to the new classes included in our data set, can be seen in Table 1.\nFootnote or Reference text (if exists): 3 https://crisislex.org/data-collections.html\nSection Titles (if exists):  ['3 Aggregated Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PyTorchLightning/pytorch-lightning,3\nCitation Context: Training details All of our experiments were done on a single Nvidia GeForceRTX 2080 Ti. We base our implementation on PyTorch (Paszke et al., 2017) and also use PyTorch Lightning (Fal-con, 2019) [URL_CITE] and Huggingface (Wolf et al., 2019). The gates and the experts in our MoE model were a single layer MLP.\nFootnote or Reference text (if exists): et al. Falcon, WA. 2019. Pytorch lightning. GitHub. Note: https://github.com/PyTorchLightning/pytorch-lightning,3.\nSection Titles (if exists):  ['C Hyperparameters']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nsdl.org\nCitation Context: Our research is motivated by the challenges we encountered in working with the National Science Digital Library (NSDL) collection. [URL_CITE] Each item in the collection is a scientific resource, such as a re-search paper, an educational video, or perhaps an entire website. In addition to its main content, each resource is annotated with metadata, which provides information such as the author or creator of the re-source, its subject area, format (text/image/video) and intended audience \u2013 in all over 90 distinct fields (though some are very related).\nFootnote or Reference text (if exists): 1 http://www.nsdl.org\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/TemporalKGTeam/TANGO\nCitation Context: We evaluate our model by performing future link prediction on five tKG datasets [URL_CITE] . We compare TANGO\u2019s performance with several existing meth-ods and evaluate its potential with inductive link prediction and long horizontal link forecasting.\nFootnote or Reference text (if exists): 1 Code and datasets are available at https://github.com/TemporalKGTeam/TANGO. filtered MRR (%) on ICEWS05-15 with regard to dif-ferent \u2206t. preprint arXiv:2012.08492.\nSection Titles (if exists):  ['4 Experiments', '4.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material:** The cited resource provides the datasets used in the experiments. Datasets fall under the \"Material\" category.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/SimonDeDeyne/SWOWEN-2018\nCitation Context: Pre-Processing Our pre-processing steps are mostly based on De Deyne et al. (2018) [URL_CITE] . These procedures consist of spell-check, unifying cue forms, removing untrustworthy participants, and Americanize all non-American spellings.\nFootnote or Reference text (if exists): 3 Raw word association test results and pre-process scripts are available in https://github.com/SimonDeDeyne/SWOWEN-2018. We re-implement their R codes with Python.\nSection Titles (if exists):  ['3 Word Association Graph']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/fred2008/TCMSA\nCitation Context: To our knowledge, we are the first to investigate graph NNs for tree senti-ment classification, and the first to discuss phrase level sentiment consistency over a constituent tree for SST. We release our code and models at [URL_CITE] https://github.com/fred2008/TCMSA.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://spacy.io/\nCitation Context: To tackle this challenge, we propose to use a label projection method based on word alignment. Specifically, we first leverage an exist-ing English POS tagger in the spaCy [URL_CITE] library to annotate the English source sentences. We then use the fast_align tool (Dyer et al., 2013) to train a word alignment model on the training data for the En-XX language pair, and use the alignment model to obtain the word-level alignment for the test data.\nFootnote or Reference text (if exists): 14 https://spacy.io/\nSection Titles (if exists):  ['5 Results and Discussion', '5.3 Fine-grained Language Analysis']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/Irina_Dunn\nCitation Context: However, this simplifi-cation (of representing sarcasm merely as positive verbs followed by negative situation) may not capture difficult forms of context incongruity. Consider the sarcastic sen-tence \u2018A woman needs a man like a fish needs bicycle\u2019 [URL_CITE] . The sarcasm in this sentence is understood from the fact that a fish does not need bicycle - and hence, the sentence ridicules the target \u2018a man\u2019.\nFootnote or Reference text (if exists): 2 This quote is attributed to Irina Dunn, an Australian writer (https://en.wikipedia.org/wiki/Irina_Dunn\nSection Titles (if exists):  ['2 Motivation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://openreview.net/pdf?id=rke2P1BFwS\nCitation Context: A tKG represents a temporal fact as a quadruple (s, r, o, t) by extending a static triple with time t, describing that this fact is valid at time t. In recent years, several sizable temporal knowledge graphs, such as ICEWS (Boschee et al., 2015), have been developed that provide widespread availability of such data and enable reasoning on temporal KGs. While lots of work (Garc\u00eda-Dur\u00e1n et al., 2018; Goel et al., 2020; Lacroix et al., 2020 [URL_CITE] ) focus on the tem-poral KG completion task and predict missing links at observed timestamps, recent work (Jin et al., 2019; Trivedi et al., 2017) paid attention to forecast future links of temporal KGs. In this work, we focus on the temporal KG forecasting task, which is more challenging than the completion task.\nFootnote or Reference text (if exists): Timothee Lacroix, Guillaume Obozinski, and Nico-las Usunier. 2020. Tensor decompositions for tem-poral knowledge base completion. ICLR preprint https://openreview.net/pdf?id=rke2P1BFwS.\nSection Titles (if exists):  ['\u2020 Corresponding author.']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jiachenwestlake/Entity_BERT\nCitation Context: Results on the three datasets show that our method outperforms these methods and achieves the best results, which demonstrates the effec-tiveness of the proposed Char-Entity-Transformer structure for integrating entity information in LM pre-training for Chinese NER. To our knowl-edge, we are the first to investigate how to make use of the scale of the input document text for enhancing NER. Our code and NER datasets are released at [URL_CITE] https://github.com/jiachenwestlake/Entity_BERT.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Produce\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Produce** - The citation states that the code and datasets are being *released* by the authors of the paper. This indicates the code"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mortezaro/tr-disfluency\nCitation Context: Table 1. [URL_CITE] We found our best model was the add-M\nFootnote or Reference text (if exists): 1 Experiments are reproducible from https://github.com/mortezaro/tr-disfluency\nSection Titles (if exists):  ['7 Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.is.cs.cmu.edu/mie\nCitation Context: In the past few years, there has been an increasing interest in research on developing systems for effi-cient recording of and access to multimedia meet-ing data [URL_CITE] . This work often results in videos of meetings, transcripts, electronic copies of docu-ments referenced, as well as annotations of various kinds on this data. In order to exploit this work, a user needs to have an interface that allows them to retrieve and browse the multimedia meeting data easily and efficiently.\nFootnote or Reference text (if exists): 1 The IM2 project http://www.im2.ch, the AMI project www.amiproject.org, The Meeting Room Project at Carnegie Mellon University, http://www.is.cs.cmu.edu/mie, and rich transcription of natural and impromptu meetings at ICSI, Berkeley, http://www.icsi.berkeley.edu/Speech/EARS/rt.html\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.d.umn.edu/~tpederse/WSDTutorial.html\nCitation Context: Our proposal is a kind of word-sense disam-biguation (Pedersen and Mihalcea, 2005) [URL_CITE] . The hit pages can provide us with training data for disam-biguating the acronym in question, and the snip-pets in the pages are fed into the learner of a classifier. Features used in classification will be explained in the latter half of this subsection.\nFootnote or Reference text (if exists): Ted Pedersen and Rada. F. Mihalcea, \u201cAdvances in Word Sense Disambiguation,\u201d tutorial at ACL 2005. http://www.d.umn.edu/~tpederse/WSDTutorial.html.\nSection Titles (if exists):  ['2 The proposal']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a tutorial on Word Sense Disambiguation (WSD). This tutorial is supplementary material that provides further"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/Pzoom522/L1-Refinement\nCitation Context: 1). Our code is avail-able at [URL_CITE] https://github.com/Pzoom522/L1-Refinement.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/cl-tohoku/bert-japanese\nCitation Context: We used pretrained BERT (Devlin et al., 2019) as the em-bedding layer of the model. [URL_CITE] We adopted the same optimization algorithm, learning rate, batch size, and output dimension of the recurrent layer as in Taghipour and Ng (2016). We trained the SAS models for 50 epochs and selected the parameters in the epoch in which the best QWK was achieved for the development set.\nFootnote or Reference text (if exists): 3 We adopted pretrained character-based BERT which is known to be suitable for processing Japanese texts. This is available at https://github.com/cl-tohoku/bert-japanese. for Low-Resource NLP, pages 175\u2013182.\nSection Titles (if exists):  ['5 Experiments', '5.2 Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/complementizer/news-tls\nCitation Context: For a more robust evaluation, we also present a new TLS dataset, which is larger and spans longer time periods than previous datasets. The dataset will be made available at [URL_CITE] https://github.com/complementizer/news-tls.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://ai.google.com/research/atNaturalQuestions/visualization\nCitation Context: Recently, a new benchmark MRC dataset called Natural Questions [URL_CITE] (NQ) (Kwiatkowski et al., 2019) has presented a substantially greater chal-lenge for the existing MRC models. Specifically, there are two main challenges in NQ compared to the previous MRC datasets like SQuAD 2.0.\nFootnote or Reference text (if exists): 2 NQ provides some visual examples of the data https://ai.google.com/research/atNaturalQuestions/visualization.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.purl.com/net/lexicons\nCitation Context: The sentiment lex-icon features are derived from existing, general-purpose, manual lexicons, namely NRC Emotion Lexicon (Mohammad and Turney, 2010; Moham-mad and Turney, 2013), Bing Liu\u2019s Lexicon (Hu and Liu, 2004), and MPQA Subjectivity Lexicon (Wilson et al., 2005), as well as automatically gen-erated, tweet-specific lexicons, Hashtag Sentiment Lexicon and Sentiment140 Lexicon (Kiritchenko et al., 2014). [URL_CITE]\nFootnote or Reference text (if exists): 4 http://www.purl.com/net/lexicons\nSection Titles (if exists):  ['6 English Sentiment Analysis']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cogcomp.cs.illinois.edu\nCitation Context: We evaluate the models using a corpus of ESL es-says, annotated [URL_CITE] by native English speakers (Ro-zovskaya and Roth, 2010a). For each preposition (article) used incorrectly, the annotator indicated the correct choice.\nFootnote or Reference text (if exists): 7 The annotation of the ESL corpus can be downloaded from http://cogcomp.cs.illinois.edu.\nSection Titles (if exists):  ['3 Comparison of Algorithms', '3.1 Evaluation Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The resource is a dataset (annotated ESL essays) used in the research.\n* **TYPE: Dataset** - The"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.delph-in.net/\nCitation Context: Head-driven Phrase Structure Grammar (HPSG) is a deep-syntax phrase structure gram-mar which produces rich, non-context-free syntactic analyses of input sentences based on a collection of carefully constructed rules and lexical item structures (Pollard and Sag, 1994; Wahlster, 2000). Each utterance is parsed using the PET deep parser produced by the inter-institutional DELPH-IN group [URL_CITE] . The manually compiled English Resource Grammar (ERG) (Flickinger, 2002) rules have previously been extended for the Verbmobil (Wahlster, 2000) project to allow for the parsing of basic conversa-tional elements such as SUs with no verb or basic backchannel acknowledgements like \u201clast thursday\u201d or \u201csure\u201d , but still produce strict HPSG parses based on these rules.\nFootnote or Reference text (if exists): 2 The DEep Linguistic Processing with HPSG INitiative (see http://www.delph-in.net/)\nSection Titles (if exists):  ['3 Identifying poor constructions', '3.1 SU-level error features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/abhijith-athreya/ASDUS\nCitation Context: These results exhibit a robust level of accuracy suitable for enhancing question answering, in-formation extraction, and summarization. [URL_CITE]\nFootnote or Reference text (if exists): 1 The source code and corpora generated by this research are available at https://github.com/abhijith-athreya/ASDUS.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.natcorp.ox.ac.uk/\nCitation Context: Our source corpus is the concatenation of the ukWaC corpus , a mid-2009 dump of the English Wikipedia and the British National Corpus [URL_CITE] . The corpus is tokenized, POS-tagged and lemmatized with TreeTagger (Schmid, 1995) and contains about 2.8 billion tokens. We extracted all statistics at the lemma level, ignoring inflectional information.\nFootnote or Reference text (if exists): 4 http://www.natcorp.ox.ac.uk/\nSection Titles (if exists):  ['3 Method', '3.1 Semantic space', '3.1.1 Source corpus']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact:\n\n* **ROLE:** Material \n* **TYPE:** Dataset\n* **FUNCTION:** Use \n\n\n**Explanation:**\n\n* **ROLE: Material** - The artifact is a corpus, which is a"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ai-systems/premise\nCitation Context: For the experiments using BERT and the pro-posed approach, we split the dataset using a 50/20/30 (train/dev/test) split. We run all exper-iments ten times, evaluating on the test set, and report the average Precision, Recall and F1-score. All evaluation data, as well as the experimental pipeline, can be found online [URL_CITE] for reproducibility purposes.\nFootnote or Reference text (if exists): 2 https://github.com/ai-systems/premise selection graph\nSection Titles (if exists):  ['6 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/parsing/preprocessing.html\nCitation Context: As to the Chinese Weibo dataset, we use FudanNLP toolkit (Qiu et al., 2013) for word segmentation. In addition, for each dataset, we maintain a vocab-ulary built based on the training set with removal of stop words [URL_CITE] and words occurring less than 3 times. The inputs of topic models x BoW are con-structed based on this vocabulary following com-mon topic model settings (Blei et al., 2003; Miao et al., 2016).\nFootnote or Reference text (if exists): 10 https://radimrehurek.com/gensim/parsing/preprocessing.html\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/datasets\nCitation Context: Sim-ilarly, the Rotten Tomatoes (RT) (Pang and Lee, 2005) dataset has 5331 positive and 5331 negative review sentences. We use the processed dataset made available by HuggingFace Dataset library 3 (Wolf et al., 2020b) [URL_CITE] .\nFootnote or Reference text (if exists): Thomas Wolf, Quentin Lhoest, Patrick von Platen, Yacine Jernite, Mariama Drame, Julien Plu, Julien Chaumond, Clement Delangue, Clara Ma, Abhishek Thakur, Suraj Patil, Joe Davison, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angie McMillan-Major, Simon Brandeis, Sylvain Gugger, Fran\u00e7ois Lagunas, Lysandre Debut, Morgan Funtow-icz, Anthony Moi, Sasha Rush, Philipp Schmidd, Pierric Cistac, Victor Mu\u0161tar, Jeff Boudier, and Anna Tordjmann. 2020b. Datasets. GitHub. Note: https://github.com/huggingface/datasets.\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource provides a pre-processed dataset for use in the research. Datasets are a core material used in machine"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/lijuncen/Sentiment-and-Style-Transfer\nCitation Context: Our best neural system in turn outperformed our baseline, achieving an average success rate of 34%. Our code and data, including newly collected human reference outputs for the Yelp and Amazon domains, can be found at [URL_CITE] https://github.com/lijuncen/Sentiment-and-Style-Transfer.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://ai.google.com/research/NaturalQuestions/leaderboard\nCitation Context: To our best knowledge, it is the first single model that out-performs the single human performance. Fur-thermore, an ensemble RikiNet obtains 76.1 F1 and 61.3 F1 on long-answer and short-answer tasks, achieving the best performance on the official NQ leaderboard [URL_CITE] .\nFootnote or Reference text (if exists): 1 Till our submission time, 29 Nov. 2019. We re-fer readers to https://ai.google.com/research/NaturalQuestions/leaderboard for the latest re-sults.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mpqa.cs.pitt.edu/lexicons/effectlexicon/\nCitation Context: +E FFECT (x) and -E FFECT (x): We use the +/-effect sense-level lexicon (Choi and Wiebe, 2014) [URL_CITE] to extract the +/-effect events in each sen-tence. The score of +E FFECT (x) is the fraction of that word\u2019s senses that are +effect senses accord-ing to the lexicon, and the score of -E FFECT (x) is the fraction of that word\u2019s senses that are -effect senses according to the lexicon. If a word does not appear in the lexicon, we do not treat it as a +/-effect event, and thus assign 0 to both +E FFECT (x) and -E FFECT (x).\nFootnote or Reference text (if exists): 7 Available at: http://mpqa.cs.pitt.edu/lexicons/effectlexicon/\nSection Titles (if exists):  ['4 PSL for Sentiment Analysis', '4.4 PSL Augmented with +/-Effect Events (PSL3)']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The artifact is a lexicon, which is a type of knowledge resource. It provides information about the sentiment-related"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/martiansideofthemoon/hurdles-longform-qa\nCitation Context: We offer suggestions to mitigate each of these issues, which we hope will lead to more rigorous LFQA research and meaningful progress in the future. [URL_CITE]\nFootnote or Reference text (if exists): 1 Resources accompanying our paper can be found in https://github.com/martiansideofthemoon/ hurdles-longform-qa\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/wtimkey/rogue-dimensions\nCitation Context: Taken together, we argue that accounting for rogue dimensions is essential when evaluating representa-tional similarity in transformer language models. [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code is publically released at: http://github.com/wtimkey/rogue-dimensions\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://towcenter.org/research/lies-damn-lies-and-viral-content/\nCitation Context: It consists of 50K labelled claim-article pairs, com-bining 300 claims with 2,582 articles. The claims and the articles were curated and labeled by jour-nalists in the context of the Emergent Project (Sil-verman, 2015) [URL_CITE] , and the dataset was first proposed by Ferreira and Vlachos (2016), who only classi-fied the claim w.r.t. the article headline instead of the whole article.\nFootnote or Reference text (if exists): Craig Silverman. 2015. Lies, Damn Lies and Viral Content. http: //towcenter.org/research/ lies-damn-lies-and-viral-content/.\nSection Titles (if exists):  ['2 Related Works']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The resource is a dataset used in the research. \n* **TYPE: Dataset** - The URL points"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.philippe-fournier-viger.com/spmf\nCitation Context: Calculations have been carried out within the open-source SPMF Java data mining plat-form. [URL_CITE]\nFootnote or Reference text (if exists): 8 http://www.philippe-fournier-viger.com/spmf\nSection Titles (if exists):  ['5 A closer look at edit sequences: Mining collaboration patterns']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.csie.ntu.edu.tw/~cjlin/libsvm/\nCitation Context: The algorithm first creates a smaller pool U \u2032 containing unlabeled data from U. It uses L i (i = 1, 2) to train two distinct classifiers: the acoustic classifier h [URL_CITE] , and the lexical classifier h 2 . We use function V i (i = 1, 2) to represent that only a single view is used for training h 1 or h 2 .\nFootnote or Reference text (if exists): 1 LIBSVM \u2013 A Library for Support Vector Machines, loca-tion: http://www.csie.ntu.edu.tw/\u02dccjlin/libsvm/\nSection Titles (if exists):  ['3 Prosodic Model', '3.3 Prosodic Model Training']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/pytorch-pretrained-BERT\nCitation Context: We implement our models using the jiant toolkit, which is in turn built on AllenNLP (Gard-ner et al., 2017) and on a public PyTorch imple-mentation of BERT. [URL_CITE] Appendix A presents addi-tional details.\nFootnote or Reference text (if exists): 4 https://github.com/huggingface/ pytorch-pretrained-BERT\nSection Titles (if exists):  ['5 Models and Experimental Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The cited resource is a codebase (pytorch-pretrained-BERT) used as a building block in the research. \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pytorch/fairseq/tree/master/examples/scaling_nmt\nCitation Context: B.1 Neural Machine Translation For the rich-resource WMT\u201916 En-De dataset, we use the pre-processed data from Ott et al. (2018) [URL_CITE] . For the low-resource datasets, we use byte-pair encoding (Sennrich et al., 2016) with 10,000 merge operations to build the vocabulary for the IWSLT (\u201914, \u201915, \u201916) datasets.\nFootnote or Reference text (if exists): 7 https://github.com/pytorch/fairseq/tree/master/examples/scaling_nmt\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mdtux89/amr-evaluation\nCitation Context: We evaluate AMR and cross-lingual AMR parsing by using the Smatch score 13 (Cai and Knight, 2013), a metric that computes the overlap between two graphs. Furthermore, in order to have a better picture of the systems\u2019 performances, we also re-port the fine-grained scores as computed by the evaluation toolkit [URL_CITE] of Damonte et al. (2017).\nFootnote or Reference text (if exists): 14 https://github.com/mdtux89/ amr-evaluation\nSection Titles (if exists):  ['4 Experimental Setup', '4.3 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/bert\nCitation Context: As a text encoder, we employed BERT and a Hi-erarchical Attention Network (HAN) (Yang et al., 2016) for generating sentence and document rep-resentation, respectively. For BERT, we used the pre-trained BERT-base [URL_CITE] (d = 768). We imple-mented the HAN following Yang et al.\nFootnote or Reference text (if exists): 7 https://github.com/google-research/bert\nSection Titles (if exists):  ['3 Experiments', '3.3 Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/raylin1000/drop-bert\nCitation Context: Appendix for \u201cA Simple and Effective Model for Answering Multi-span Questions\u201d A Experimental Setup We experiment with model variations that use either SSE, TASE, or their combination as a multi-head model. For DROP, we additionally use arithmetic and count heads based on (Dua et al., 2019; Kin-ley and Lin, 2019 [URL_CITE] ). Our model is implemented with PyTorch (Paszke et al., 2019) and AllenNLP (Gardner et al., 2017).\nFootnote or Reference text (if exists): Jambay Kinley and Raymond Lin. 2019. NABERT+: Improving numerical reason-ing in reading comprehension. URL https: //github.com/raylin1000/drop-bert .\nSection Titles (if exists):  ['Acknowledgements']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/p/universal-tagger/\nCitation Context: We made our code are available for download. [URL_CITE]\nFootnote or Reference text (if exists): 4 https://code.google.com/p/universal-tagger/\nSection Titles (if exists):  ['6 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hltfbk.github.io/Excitement-Open-Platform/\nCitation Context: For this base-line, MCTest is again re-casted as an RTE task by converting each question-answer pair into a statement (using Cucerzan and Agichtein (2005)) and then selecting the answer whose statement has the highest likelihood of being entailed by the story. [URL_CITE] (4) The fourth baseline (called LSTM) is taken from Weston et al. (2015).\nFootnote or Reference text (if exists): 5 The BIUTEE system (Stern and Dagan, 2012) available under the Excitement Open Platform http://hltfbk.github.io/Excitement-Open-Platform/ was used for recognizing textual entailment.\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The cited resource (Excitement Open Platform) is a tool used in the research process. It's not a dataset,"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cornell.edu/~jhessel/cats/cats.html\nCitation Context: Many non-content factors can influence commu-nity reception of posts, e.g., Hessel et al. (2017) [URL_CITE] find that when a post is made on Reddit can signif-icantly influence its eventual popularity.\nFootnote or Reference text (if exists): Jack Hessel, Lillian Lee, and David Mimno. 2017. Cats and captions vs. creators and the clock: Comparing multimodal content to context in pre-dicting relative popularity. In WWW. Project homepage at http://www.cs.cornell.edu/\u02dcjhessel/cats/cats.html.\nSection Titles (if exists):  ['4 Early Prediction of Controversy', '4.2 Post-time Metadata']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://competitions.codalab.org/competitions/18814\nCitation Context: But, the ground truth evidence and labels of the test set are not publicly available. Instead, once extracted evidence sets/sentences and predicted labels of the test set by a model are sub-mitted to the online evaluation system [URL_CITE] , its perfor-mance is measured and displayed at the system. In this work, we train and tune our hyper-parameters on training and development sets, respectively.\nFootnote or Reference text (if exists): 1 https://competitions.codalab.org/competitions/18814\nSection Titles (if exists):  ['5 Experiments', '5.1 Experiment Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://research.facebook.com/research/-babi/\nCitation Context: Bordes et al. (2015) released the SimpleQuestions data set [URL_CITE] , which consists of 108,442 English questions. Each ques-tion (e.g., What does Jimmy Neutron do?)\nFootnote or Reference text (if exists): 11 https://research.facebook.com/research/-babi/\nSection Titles (if exists):  ['7 Experiments', '7.1 Evaluation on QA (English)', '7.1.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce \n\n\nLet me explain:\n\n* **ROLE: Material** - The cited resource is a dataset (SimpleQuestions) which is a core component used in the research.\n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://rxhui.com\nCitation Context: We thank Zhiyang Teng and Linfeng Song for their work and discussion. This work is supported by a grant from Rxhui Inc [URL_CITE] .\nFootnote or Reference text (if exists): 1 https://rxhui.com\nSection Titles (if exists):  ['8 Acknowledgments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.clsp.jhu.edu/workshops/archive/ws-12/groups/dasmt\nCitation Context: The 2012 JHU workshop on Domain Adapta-tion for MT [URL_CITE] proposed phrase sense disambiguation (PSD) for translation model adaptation. In this ap-proach, the context of a phrase helps the system to find the appropriate translation.\nFootnote or Reference text (if exists): 4 http://www.clsp.jhu.edu/workshops/archive/ws-12/groups/dasmt\nSection Titles (if exists):  ['6 Related work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.tau-nlp.org/commonsenseqa\nCitation Context: Resource Copyright This work presents three new resources: MickeyCorpus, X-CODAH, and X-CSQA, which are multilingual extension of the OMCS (Singh et al., 2002) , CSQA (Talmor et al., 2019) [URL_CITE] , and CODAH (Chen et al., 2019) 5 re-spectively. All these three original sources of the data are publicly available for free, and we do not add any additional requirement for accessing our resources.\nFootnote or Reference text (if exists): 4 https://www.tau-nlp.org/commonsenseqa 5 https://github.com/Websail-NU/CODAH\nSection Titles (if exists):  ['* Ethical Considerations']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact:\n\n* **ROLE:**  Supplement \n* **TYPE:** Website\n* **FUNCTION:** Introduce \n\n\n**Explanation:**\n\n* **ROLE:** The citation introduces a resource (CSQA) that is"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/Lambda-3/DiscourseSimplification/tree/master/supplemental_material\nCitation Context: These analyses were carried out on a dataset which we compiled. [URL_CITE] It consists of 100 Wikipedia sentences per syntactic phenomenon tackled by our TS approach. In the construction of this corpus we ensured that the collected sen-tences exhibit a great syntactic variability to allow for a reliable predication about the coverage and accuracy of the specified simplification rules.\nFootnote or Reference text (if exists): 10 The dataset is available under https://github.com/Lambda-3/DiscourseSimplification/tree/master/supplemental_material.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://news.google.com/\nCitation Context: One important step in the cre-ation process of this corpus consists in finding sets of related documents that describe the same semi-nal event such that the annotation of coreferential event mentions across documents is possible. For this purpose, we selected from the GoogleNews archive [URL_CITE] various topics whose description contains keywords such as commercial transaction, attack, death, sports, terrorist act, election, arrest, natu-ral disaster, etc. The entire annotation process for creating the ECB resource is described in (Bejan and Harabagiu, 2008).\nFootnote or Reference text (if exists): 7 http://news.google.com/\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://answers.yahoo.com/\nCitation Context: Yahoo! An-swers, [URL_CITE] Answers.com, etc. ), which became very popular resources for question answering.\nFootnote or Reference text (if exists): 1 http://answers.yahoo.com/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use two sets of 300-dimensional pre-trained embeddings, word2vec 1 and GloVe [URL_CITE] , forming two channels for our network. For all datasets, we use 100 convolution filters each for window sizes of 3, 4, 5. Rectified Linear Units (ReLU) is chosen as the nonlinear function in the convolutional layer.\nFootnote or Reference text (if exists): 2 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['5 Experiments', '5.2 Training Details and Implementation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.bing.com/translator/api/Dictionary/Lookup?from=en&to=zh-CHS&text=\nCitation Context: Bilingual Lexicon Our bilingual lexicon is collected from Microsoft Translator [URL_CITE] , which trans-lates English words to multiple Chinese words with confidence scores. Note that all named en-tities and slang terms used in the following exper-iments are excluded from this bilingual lexicon.\nFootnote or Reference text (if exists): 6 http://www.bing.com/translator/api/Dictionary/ Lookup?from=en&to=zh-CHS&text=\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/Wikipedia:Translation\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles [URL_CITE] (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks.\nFootnote or Reference text (if exists): 4 http://en.wikipedia.org/wiki/Wikipedia:Translation\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The Wikipedia page is not directly used as a tool or dataset in the research. It provides background information and examples related"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/\nCitation Context: Thus our method some-times acts as an efficient mechanism of sourcing existing human translations, rather than sourcing independently-written content on the same topic. The use of machine translation is strongly discour-aged by the Wikipedia community, [URL_CITE] but from exam-ining edit histories of articles in MLQA, machine translation is occasionally used as an article seed, before being edited and added to by human authors.\nFootnote or Reference text (if exists): 8 https://en.wikipedia.org/wiki/ Wikipedia:Translation#Avoid_machine_ translations\nSection Titles (if exists):  ['6 Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html\nCitation Context: The maximum sequence length is truncated to 512 tokens. We enable mixed preci-sion and pad all sequence lengths to the multiples of 8 for the effective usage of TensorCores [URL_CITE] .\nFootnote or Reference text (if exists): 8 https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.htmlels. [MASK] means the prompts are intialized with the word embedding of same token, and MNLI means the prompt is initialized with the prompts of out best MNLI run.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/OnlpLab/morphodetection\nCitation Context: We conclude that bootstrapping datasets for in-flectional morphology in low-resourced languages, is a viable strategy to be adopted and explored. [URL_CITE]\nFootnote or Reference text (if exists): 3 Our code is available on https://github.com/OnlpLab/morphodetection.\nSection Titles (if exists):  ['table, given a few forms of the same lexeme. 2']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method:** The code is presented as a tool used in the research, making it a method.\n* **TYPE: Code:** The URL"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN\nCitation Context: We used JUMAN (Kurohashi and Kawahara, 2009a) [URL_CITE] for word segmentation and part-of-speech tagging, and we calculated idf over Mainichi newspaper articles from 1991 to 2005. For the de-pendency parsing, we used KNP (Kurohashi and Kawahara, 2009b).\nFootnote or Reference text (if exists): Sadao Kurohashi and Daisuke Kawahara, 2009a. Japanese Morphological Analysis System JUMAN 6.0 Users Manual. http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN.\nSection Titles (if exists):  ['5 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://t.co/zrRIBxMUYJ\nCitation Context: Tweet Officer Wilson will be returned to active duty if no indictment, says #Ferguson Police Chief [URL_CITE] http://t.co/zrRIBxMUYJ\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Data Extraction and Preprocessing', '3.2 Extracting Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/stanfordnlp/treelstm\nCitation Context: Our experiments show that Tree-LSTMs outper-form existing systems and sequential LSTM base-lines on both tasks. Implementations of our mod-els and experiments are available at [URL_CITE] https://github.com/stanfordnlp/treelstm.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The cited resource is a code repository containing implementations of Tree-LSTMs, a method used in the research.\n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/viking-sudo-rm/\nCitation Context: We used default hyperpa-rameters provided by the open-source AllenNLP framework (Gardner et al., 2018). The code is avail-able at [URL_CITE] https://github.com/viking-sudo-rm/ rr-experiments .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['0 < [h t ] 4 \u2228 [h t ] 1 + [h t ] 2 + [h t ] 3 \u2264 0 . (76) E Experimental Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/allenai/allennlp/blob/master/tutorials/howto/elmo.md\nCitation Context: For the experiments with external resources in the open setting, we utilize 1) word embed-dings pre-trained with GloVe (Pennington et al., 2014) on the Gigaword corpus for Chinese and the published embeddings with 100 dimensions pre-trained on Wikipedia and Gigaword for English; and 2) ELMo [URL_CITE] (Peters et al., 2018) and BERT (Devlin et al., 2018), two recently proposed effec-tive deep contextualized word representations .\nFootnote or Reference text (if exists): 3 We use the released model on their website: https://github.com/allenai/allennlp/blob/master/tutorials/howto/elmo.md\nSection Titles (if exists):  ['4 Experiment', '4.1 Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://L2R.cs.uiuc.edu/~cogcomp/software.php\nCitation Context: We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. For word deletion, we use only the POS tags of the corresponding tokens (generated by the LBJ POS tagger [URL_CITE] ) to generate features. For edge the entailment and paraphrase identification tasks.\nFootnote or Reference text (if exists): 3 http://L2R.cs.uiuc.edu/\u02dccogcomp/software.php\nSection Titles (if exists):  ['5 Experiments', '5.2 Textual Entailment']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact:\n\n* **ROLE:** Method \n* **TYPE:** Tool\n* **FUNCTION:** Use \n\n\n**Explanation:**\n\n* **ROLE: Method** - The citation refers to a tool used in the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/Babylonpartners/fastText_multilingual\nCitation Context: We enriched the basic similarity model by inte-grating affective information from human-created lexicons. Since affective datasets are typically small-scale and mostly exist for English, we ap-plied a cross-lingual approach (Smith et al., 2017) to learn a linear transformation that aligns mono-lingual vectors from two languages in a single vec-tor space. We took off-the-shelf word represen-tations [URL_CITE] for German and English that live in the same semantic space, learned a regression model based on the English data, and applied it to the German data by relying on findings from Ko\u0308per and Schulte im Walde (2017), who showed that a feed-forward neural network obtained a high cor-relation with human-annotated ratings.\nFootnote or Reference text (if exists): 4 https://github.com/Babylonpartners/ fastText_multilingual\nSection Titles (if exists):  ['3 Representations of BV\u2013PV Analogies', '3.3 Affect Models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mallet.cs.umass.edu\nCitation Context: We used the machine learning package MALLET (McCallum, 2002) [URL_CITE] to conduct the CRF model training and labeling.\nFootnote or Reference text (if exists): McCallum, A.K. 2002. MALLET: A Machine Learning for Language Toolkit. http://mallet.cs.umass.edu.\nSection Titles (if exists):  ['4 Empirical Evaluation', '4.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.ldc.upenn.edu/collaborations/past-projects/ace\nCitation Context: Besides employing active learning to create spe-cific data set with nested, overlapping, discontinu-ous entity mentions, we notice that there are some off-the-shelf corpora in biomedical domain that we can use to evaluate our proposed methods, al-though, to our knowledge, none of these data sets contains all three kinds of complex mentions, e.g., GENIA (Kim et al., 2003) only contains nested en-tity mentions, and CADEC (Karimi et al., 2015) and SemEval2014 (Pradhan et al., 2014) contain overlapping and discontinuous mentions. In ad-dition, ACE [URL_CITE] and NNE (Ringland, 2016) are newswire corpora with nested entity mentions.\nFootnote or Reference text (if exists): 1 https://www.ldc.upenn.edu/collaborations/past-projects/ace\nSection Titles (if exists):  ['4 Research Plan']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Dataset\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.phontron.com/kytea/\nCitation Context: The corpora were processed using a standard procedure for machine translation. The English texts were tokenized with the tokenization script released with Europarl corpus (Koehn, 2005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002) 7 ; the Japanese texts were segmented into words using the Kyoto Text Analysis Toolkit (KyTea [URL_CITE] ). Sentences longer than 100 words or those with foreign/English word length ratios between larger than 9 were filtered out.\nFootnote or Reference text (if exists): 8 http://www.phontron.com/kytea/\nSection Titles (if exists):  ['4 Experiments', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://about.twitter.com/company\nCitation Context: With the rise in popularity of social media, mes-sage broadcasting sites such as Twitter and other microblogging services have become an important means of communication, with an estimated 500 million tweets being written every day [URL_CITE] . In addi-tion to individual users, various organizations and public figures such as newspapers, government officials and entertainers have established them-selves on social media in order to disseminate in-formation or promote their products.\nFootnote or Reference text (if exists): 1 https://about.twitter.com/company\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://crowdflower.com\nCitation Context: To answer these questions, we also conduct a human judges study on Crowdflower [URL_CITE] . We se-lect 200 items at random (100 real reviews and 100 from the conditional model, half of each with meta-information), and ask annotators to rate them as real or fake.\nFootnote or Reference text (if exists): 6 https://crowdflower.com\nSection Titles (if exists):  ['4 Experiments', '4.2 Human Judges']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - Crowdflower is a platform used to source human labor for tasks, including the annotation task described in the citation. This aligns"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wordnet.princeton.edu/wordnet/man/wninput.5WN.html\nCitation Context: There are 35 different frames in to-tal. [URL_CITE] We manually assigned a set of clause types to each frame (e.g., SVO to frame \u201csomebody verb something\u201d). Table 1 shows an example frame for each of the seven clause types.\nFootnote or Reference text (if exists): 3 See http://wordnet.princeton.edu/wordnet/man/wninput.5WN.html.\nSection Titles (if exists):  ['4 Syntactic Pruning']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/fairseq-py\nCitation Context: For C ONV S2S [URL_CITE] and T-C ONV S2S, we used 512 dimensional hidden states and 512 dimensional word and position embeddings. We trained our convolutional models with Nesterov\u2019s accelerated gradient method (Sutskever et al., 2013) using a momentum value of 0.99 and renormalized gra-dients if their norm exceeded 0.1 (Pascanu et al., 2013).\nFootnote or Reference text (if exists): 3 We used the code available at https://github.com/facebookresearch/fairseq-py.\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lair.cse.msu.edu/lair/projects/actioneffect.html\nCitation Context: This opens up the possibility for humans to teach robots new tasks through language communication with a small number of examples. Third, we have cre-ated a dataset for this task, which is available to the community [URL_CITE] . Our bootstrapping approach can serve as a baseline for future work on this topic.\nFootnote or Reference text (if exists): 1 This dataset is available at http://lair.cse.msu.edu/lair/projects/actioneffect.html\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://youtu.be/x6cOpVSZcdo\nCitation Context: An NLP toolkit for DNN models with both generality and flexibility can greatly improve the productivity of engineers by sav-ing their learning cost and guiding them to find optimal solutions to their tasks. In this pa-per, we introduce NeuronBlocks [URL_CITE] , a toolkit encapsulating a suite of neural network mod-ules as building blocks to construct various DNN models with complex architecture. This toolkit empowers engineers to build, train, and test various NLP models through simple con-figuration of JSON files.\nFootnote or Reference text (if exists): 2 Demo: https://youtu.be/x6cOpVSZcdo\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://bit.ly/15StNc\u201d\nCitation Context: (11) \u201cTodd and Sarah Palin to divorce [URL_CITE] http://bit.ly/15StNc\u201d\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Data', '4.1 Annotation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://u.cs.biu.ac.il/~nlp/resources/downloads/\nCitation Context: We ob-serve similar trends to previously published results, and make the dataset splits available for replication. [URL_CITE]\nFootnote or Reference text (if exists): 1 http://u.cs.biu.ac.il/~nlp/resources/downloads/\nSection Titles (if exists):  ['2 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The URL points to a location where datasets are hosted, making it a source of data.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/allenai/document-qa\nCitation Context: For the synthetic dataset training method, we con-sider two QA models: finetuning BERT (Devlin et al., 2018) and BiDAF + Self Attention (Clark and Gardner, 2017). [URL_CITE] For the posterior maximisa-tion method, we extract cloze questions from both sentences and sub-clauses, and use the NMT mod-els to estimate p(q|c,a). We evaluate using the standard Exact Match (EM) and F1 metrics.\nFootnote or Reference text (if exists): 5 We use the HuggingFace implementation of BERT, available at https://github.com/huggingface/ pytorch-pretrained-BERT, and the documentQA implementation of BiDAF+SA, available at https://github.com/allenai/document-qa\nSection Titles (if exists):  ['3 Experiments', '3.1 Unsupervised QA Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://timan.cs.uiuc.edu/downloads.html\nCitation Context: The first one is a benchmark dataset in Wang et al. (2011), which contains English review sets on two do-mains (MP3 and Hotel) [URL_CITE] . The second dataset is proposed by Chinese Opinion Analysis Evalua-tion 2008 (COAE 2008) , where two review sets (Camera and Car) are selected.\nFootnote or Reference text (if exists): 5 http://timan.cs.uiuc.edu/downloads.html\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets and Evaluation Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/clab/dynet\nCitation Context: NMT Models. We implemented our continuous-optimisation based decoding method on top of the Mantidae toolkit (Cohn et al., 2016), and using the dynet deep learning library [URL_CITE] (Neubig et al., 2017). All neural network models were configured with 512 input embedding and hidden layer dimensions, and 256 alignment dimension, with 1 and 2 hidden layers in the source and target, respectively.\nFootnote or Reference text (if exists): 5 https://github.com/clab/dynet\nSection Titles (if exists):  ['5 Experiments', '5.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "Here's the classification:\n\n* **ROLE:** Method\n* **TYPE:** Code\n* **FUNCTION:** Use \n\n\n**Explanation:**\n\n* **ROLE: Method** - The citation refers to a tool used in the research process (the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ZurichNLP/understanding-mbr\nCitation Context: We find that MBR still exhibits a length and token frequency bias, owing to the MT metrics used as utility functions, but that MBR also increases robustness against copy noise in the training data and domain shift. [URL_CITE]\nFootnote or Reference text (if exists): 1 Code and documentation available at https://github.com/ZurichNLP/understanding-mbr\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/p/word2vec/\nCitation Context: We use the gensim implementation of the DBOW and DM paragraph vector models. The word em-beddings for the SkipAvg model are obtained with word2vec. [URL_CITE] The data was tokenized with the Stan-ford tokenizer and then lowercased.\nFootnote or Reference text (if exists): 8 https://code.google.com/p/word2vec/\nSection Titles (if exists):  ['3 Experiments', '3.2 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google/flax\nCitation Context: We have used Flax, an open-source library [URL_CITE] to train neural networks, as the code base for the model training. Our H-Transformer-1D model uses the standard Transformer decoder implemen-tation in Flax as the backbone.\nFootnote or Reference text (if exists): 8 https://github.com/google/flax\nSection Titles (if exists):  ['8 Experiments And Results', '8.2 Language Models Trained on One-Billion Words']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.riedelcastro.org/uschema\nCitation Context: We compare the proposed T RESCAL model to RI13 (Riedel et al., 2013), YA11 (Yao et al., 2011), MI09 (Mintz et al., 2009) and SU12 (Surdeanu et al., 2012) [URL_CITE] . We follow the protocol used in (Riedel et al., 2013) to evaluate the results.\nFootnote or Reference text (if exists): 8 The corpus and the system outputs are from http://www.riedelcastro.org/uschema\nSection Titles (if exists):  ['5 Experiments', '5.2 Relation Extraction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2011T13\nCitation Context: We also compare a gazetteer based method L ATTICE (Zhang and Yang, 2018) and L ATTICE (R E E NT ), which replaces the word gazetteer of L ATTICE with our entity dictionary for fair comparison. We use the same embeddings as (Zhang and Yang, 2018), which are pre-trained on Giga-Word [URL_CITE] us-ing Word2vec (Mikolov et al., 2013). The entity embeddings are randomly initialized and fine-tuned during training.\nFootnote or Reference text (if exists): 6 https://catalog.ldc.upenn.edu/ LDC2011T13\nSection Titles (if exists):  ['4 Experiments', '4.2 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/moses/giza/GIZA++.html\nCitation Context: As seen from Table 2, the translation based methods outperforms the baseline signifi-cantly. The models are trained using GIZA++ [URL_CITE] tool with the question and best answer pair as the parallel corpus. For the topic based Q-A topic model and Q-A topic model(s), we implemented the models QATM -PR (Question-Answer Topic Model) Ji et al.\nFootnote or Reference text (if exists): 12 http://www.statmt.org/moses/giza/GIZA++.html\nSection Titles (if exists):  ['8 Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://openreview.net/pdf?id=BJJsrmfCZ\nCitation Context: More details of us-ing CNN for text classification can be found in the original paper (Kim, 2014). MAN is implemented using PyTorch (Paszke et al., 2017) [URL_CITE] .\nFootnote or Reference text (if exists): Adam Paszke, Sam Gross, Soumith Chintala, Gre-gory Chanan, Edward Yang, Zachary DeVito, Zem-ing Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in py-torch. NIPS 2017 Autodiff Workshop https://openreview.net/pdf?id=BJJsrmfCZ.\nSection Titles (if exists):  ['5 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ChunchuanLv/Iterative_Inference\nCitation Context: Furthermore, we provide analysis on con-straint violations and errors on the English test set. [URL_CITE]\nFootnote or Reference text (if exists): 2 The code and experiment settings can be ac-cessed at https://github.com/ChunchuanLv/ Iterative_Inference\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dianping.com\nCitation Context: Besides, experts\u2019 prior knowledge or de-velopers\u2019 ingenuity is not always reliable with the variations of domains and languages. For exam-ple, based on the datasets from Dianping site [URL_CITE] , Li et al. (2015) find that the real users tend to review the restaurants nearby, but the spammers are not re-stricted to the geographical location, they may come from anywhere.\nFootnote or Reference text (if exists): 4 http://www.dianping.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The Dianping website is a source of data (user reviews) used in the cited research. \n*"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://christophm.github.io/interpretable-ml-book/\nCitation Context: Interpretable NLP aims to better understand pre-dictive models\u2019 internals for purposes such as de-bugging, validating safety before deployment, or revealing unintended biases and behavior (Molnar, 2019) [URL_CITE] . These objectives require faithful rationales\u2014 explanations of the model\u2019s behavior that are accu-rate representations of its decision process (Melis and Jaakkola, 2018).\nFootnote or Reference text (if exists): Christoph Molnar. 2019. Interpretable Machine Learning. https://christophm.github.io/interpretable-ml-book/.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nikkei.co.jp\nCitation Context: We created a corpus of sentence summaries based on email news bulletins we had received over five to six months from an on-line news provider called Nikkei Net, which mostly deals with finance and politics. [URL_CITE] Each bulletin consists of six to seven news briefs, each with a few sentences. Since a news brief contains nothing to indicate what its longer version might look like, we manually searched the news site for a full-length article that might reasonably be con-sidered a long version of that brief.\nFootnote or Reference text (if exists): 9 http://www.nikkei.co.jp\nSection Titles (if exists):  ['5 Evaluation Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mstparser.sourceforge.net\nCitation Context: The parser is basically based on the MSTParser [URL_CITE] using all the features presented by (McDonald et al., 2006) with projective parsing. Moreover, we exploit three types of additional features to im-prove the parser.\nFootnote or Reference text (if exists): 8 It\u2019s freely available at http://mstparser.sourceforge.net.\nSection Titles (if exists):  ['5 Evaluation Results', '5.1 Syntactic Dependency Parsers']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Tool:** The MSTParser is described as a \"parser,\" which is a software tool used for analyzing and understanding language structure."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/F1score\nCitation Context: We are interested in finding a sub-set C 0 of C such that most of the pairs in C 0 are problem-solution pairs, and most of those in C\u2212C 0 are not so. In short, we would like to find problem-solution pairs from C such that the F-measure [URL_CITE] for solution identification is maximized.\nFootnote or Reference text (if exists): 8 http://en.wikipedia.org/wiki/F1 score\nSection Titles (if exists):  ['3 Problem Definition']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://bit.ly/2Qbr0w1\nCitation Context: Whereas a decade ago most mon NLP models, compared to familiar consumption. [URL_CITE] NLP models could be trained and developed on a commodity laptop or server, many now require multiple instances of specialized hardware such as GPUs or TPUs, therefore limiting access to these highly accurate models on the basis of finances.\nFootnote or Reference text (if exists): 1 Sources: (1) Air travel and per-capita consumption: https://bit.ly/2Hw0xWc; (2) car lifetime: https: //bit.ly/2Qbr0w1.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tuzhaopeng/NMT-Coverage\nCitation Context: Experiments show that the proposed approach significantly im-proves both translation quality and align-ment quality over standard attention-based NMT. [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code is publicly available at https://github.com/tuzhaopeng/NMT-Coverage.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact:\n\n* **ROLE:**  Method \n* **TYPE:** Code\n* **FUNCTION:** Use \n\n\n**Explanation:**\n\n* **ROLE: Method** - The code is presented as a tool used"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/attardi/wikiextractor\nCitation Context: The original BookCorpus (Zhu et al., 2015) is no longer avail-able, so we collect similar data from Smashwords, the original source of BookCorpus. [URL_CITE]\nFootnote or Reference text (if exists): 5 We collect our data using the Wikipedia XML dump https://dumps.wikimedia.org/mirrors.html and data-processing code https://github.com/attardi/wikiextractor, and a Smashwords crawler https://github.com/soskek/bookcorpus.\nSection Titles (if exists):  ['4 Models, Pretraining, & Fine-Tuning', '4.1 Pretraining']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/georgwiese/biomedical-qa\nCitation Context: We also test on the BioASQ 5b dataset, which consists of question-answer pairs from PubMed abstracts. We use the publicly available system [URL_CITE] from Wiese et al. (2017), and follow the exact same setup as theirs, focusing only on factoid and list questions.\nFootnote or Reference text (if exists): 5 https://github.com/georgwiese/ biomedical-qa\nSection Titles (if exists):  ['4 Experiments & Results', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://academicworks.cuny.edu/gc\nCitation Context: A survey of recent work of several researchers on producing animations of sign language with fa-cial expressions appears in (Kacorri, 2015) [URL_CITE] . There is recent interest in data-driven approaches using facial motion-capture of human performances to generate sign language animations: For example, (Schmidt et al., 2013) used clustering techniques to select facial expressions that co-occur with indi-vidual lexical items, and (Gibet et al., 2011) stud-ied how to map facial motion-capture data to ani-mation controls.\nFootnote or Reference text (if exists): Hernisa Kacorri. 2015. Tr-2015001: A sur-vey and critique of facial expression syn-thesis in sign language animation. Tech-nical report, The Graduate Center, CUNY. http://academicworks.cuny.edu/gc cs tr/403.\nSection Titles (if exists):  ['1 Introduction and Motivation', '1.2 Prior Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/unlu\nCitation Context: We drop examples from test sets where we are unable to compute all unique randomizations, typi-cally these are examples with sentences of length of less than 6 tokens. [URL_CITE] Models accept many permuted examples. We find \u2126 max is very high for models trained and evalu-ated on MNLI (in-domain generalization), reaching 98.7% on MNLI dev.\nFootnote or Reference text (if exists): 2 Code, data, and model checkpoints will be available at https://github.com/facebookresearch/unlu. models are trained on OCNLI corpus (Hu et al., 2020a). Bold marks the highest value per metric (red shows the model is insensitive to permutation).\nSection Titles (if exists):  ['5 Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.politicalforum.com\nCitation Context: We use three different datasets. The first dataset (politicalforum, henceforth) consists of 5,743 posts collected from a political forum [URL_CITE] . All the posts are in English.\nFootnote or Reference text (if exists): 2 http://www.politicalforum.com\nSection Titles (if exists):  ['2 Related Work', '2.4 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.mat.unical.it/OlexSuite/Datasets/SampleDataSets-about.htm\nCitation Context: : Computer, Recreation, Science, Pol-itics, Religion. The corresponding five down-stream tasks are text classification over the 3\u2013 [URL_CITE] fine-grained classes under each top-level class. Train, test, dev splits were 50%, 40%, 10%.\nFootnote or Reference text (if exists): 5 https://www.mat.unical.it/OlexSuite/Datasets/SampleDataSets-about.htm\nSection Titles (if exists):  ['Topics and tasks']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource provides a dataset used in the research. Datasets are a core material used in training and evaluating models."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/rtmaww/SENT\nCitation Context: We further design an iterative training algorithm to take full advantage of these data-refining processes, which significantly boost performance. Our codes are publicly available at Github [URL_CITE] .\nFootnote or Reference text (if exists): 1 https://github.com/rtmaww/SENT\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://paracrawl.eu/download.html\nCitation Context: There are many directions to extend this re-search, in particular to scale-up to larger corpora. We will apply it to the data mined by the European ParaCrawl project. [URL_CITE] The proposed multilingual sentence distance could be also used in MT con-fidence estimation, or to filter back-translations of monolingual data (Sennrich et al., 2016a).\nFootnote or Reference text (if exists): 6 http://paracrawl.eu/download.html\nSection Titles (if exists):  ['6 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt17/\nCitation Context: Following recent unconditional long text genera-tion work (Caccia et al., 2018), we perform exper-iments on EMNLP2017 WMT News dataset [URL_CITE] . All sentences are longer than 20, making the dataset appropriate for testing the exposure bias problem.\nFootnote or Reference text (if exists): 3 http://www.statmt.org/wmt17/\nSection Titles (if exists):  ['4 Experiments', '4.3 Neural Language Generation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/sshaar/That-is-a-Known-Lie\nCitation Context: \u2022 We create a specialized dataset, which we release to the research community. [URL_CITE] Un-like previous work in fact-checking, which used normalized claims from fact-checking datasets, we work with naturally occurring claims, e.g., in debates or in social media.\nFootnote or Reference text (if exists): 8 Data and code are available at the following URL: https://github.com/sshaar/ That-is-a-Known-Lie\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.uni-weimar.de/medien/webis/corpora\nCitation Context: It will be made freely avail-able to other researchers. [URL_CITE] Second, we obtain a ro-bust classifier for argumentativeness, providing ev-idence that distant supervision does not only save money and time, but also benefits the effectiveness of cross-domain and cross-register argumentation mining. Third, we evaluate\u2014for the first time\u2014 the robustness of several features in classifying ar-gumentativeness across domains and registers.\nFootnote or Reference text (if exists): 1 http://www.uni-weimar.de/medien/webis/corpora\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/English_grammar#Semantic_gradability\nCitation Context: \u2022 Notgood,quantifiablebetter, best etcgradable. usually [URL_CITE] wordsmake sucha claimas bald, as there is no qualified definition of being good or better.\nFootnote or Reference text (if exists): 3 http://en.wikipedia.org/wiki/English_ grammar#Semantic_gradability\nSection Titles (if exists):  ['3 Annotation Scheme']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The Wikipedia article is providing background information and context about semantic gradability, which is relevant to the annotation scheme being described"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.askoxford.com\nCitation Context: Since we are interested in improving the performance of NLP ap-plications such as MT, we take a pragmatic approach and classify usages as \u2019figurative\u2019 if they are not lex-icalized, i.e., if the specific sense is not listed in a dictionary. [URL_CITE] For example, we would classify summit in the \u2019meeting\u2019 sense as \u2019literal\u2019 (l). In our data set, 7.3% of the instances were annotated as \u2019nsa\u2019, 1.9% as \u2019nsu\u2019, 9.2% as \u2019nw\u2019 and 81.5% as \u2019l\u2019.\nFootnote or Reference text (if exists): 2 We used http://www.askoxford.com.\nSection Titles (if exists):  ['4 Evaluating the GMM Approach', '4.1 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://developer.twitter.com/en/docs/tweets/search/api-reference/get-saved_searches-show-id\nCitation Context: The Twitter dataset is constructed based on TREC2011 microblog track . To recover conver-sations, we used Tweet Search API [URL_CITE] to retrieve full information of a tweet with its \u201cin reply to status id\u201d included. Recursively, we searched the \u201cin re-ply to\u201d tweet till the entire conversation is recov-ered.\nFootnote or Reference text (if exists): 5 http://developer.twitter.com/en/docs/tweets/search/api-reference/get-saved_ searches-show-id\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/YerevaNN/WARP\nCitation Context: In this paper, we introduce a novel technique to find optimal prompts. We call our method WARP: Word-level Adversarial RePrograming [URL_CITE] . The method is inspired by adversarial reprogramming (Elsayed et al., 2019) \u2014 a method of adding ad-versarial perturbations to an input image that re-programs a pretrained neural network to perform classification on a task other than the one it was originally trained for.\nFootnote or Reference text (if exists): 1 Our implementation is publicly available at: https: //github.com/YerevaNN/WARP\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://kaldi.sf.net\nCitation Context: First, we build an HMM-GMM system using the Kaldi open-source toolkit [URL_CITE] (Povey et al., 2011). The baseline recognizer has 8,986 sub-phone states and 200K Gaussians trained using maximum likelihood.\nFootnote or Reference text (if exists): 2 http://kaldi.sf.net\nSection Titles (if exists):  ['4 Experiments', '4.1 Baseline Systems']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.everyzing.com/\nCitation Context: We\u2019ve taken the rather nar-row view that systems might only expose the list of scores they assigned to retrieved documents, a plau-sible scenario considering the many systems now emerging which are effectively doing this already. Some examples include EveryZing, [URL_CITE] the MIT Lec-ture Browser, 2 and Comcast\u2019s video search. 3 This trend is likely to continue as the underlying repre-sentations of the content are themselves becoming increasingly complex (e.g., word and subword level lattices or confusion networks).\nFootnote or Reference text (if exists): 1 http://www.everyzing.com/\nSection Titles (if exists):  ['6 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/swift-coreml-transformers\nCitation Context: Models can use adapters to convert models to CoreML weights that are suit-able to be embedded inside a iOS application, to enable on-the-edge machine learning. Code is also made available [URL_CITE] . Similar methods can be used for Android devices.\nFootnote or Reference text (if exists): 3 https://github.com/huggingface/ swift-coreml-transformers\nSection Titles (if exists):  ['5 Deployment']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Method** - The cited resource provides a way to achieve a specific task (converting models to CoreML for iOS deployment). This"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mpqa.cs.pitt.edu/lexicons/subjlexicon/\nCitation Context: In this paper, both Chinese and English [URL_CITE] sen-timental lexicons are employed to identify can-didate opinion expressions by searching the oc-currences of negative and positive expressions in text, and predict the polarity of both Chinese and English texts through the word-counting approach (Turney, 2002).\nFootnote or Reference text (if exists): 6 English sentiment lexicon is uti-lized from MPQA Subjectivity Lexicon: http://mpqa.cs.pitt.edu/lexicons/subjlexicon/\nSection Titles (if exists):  ['4 Emotion Detection via Bilingual and Sentiment Information', '4.2 Sentimental Information']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/p/word2vec\nCitation Context: Next we consider the context-predicting vectors (DS Mikolov ) available as part of the word2vec [URL_CITE] project (Mikolov et al., 2013a). We use the publicly avail-able vectors which were trained on a Google News dataset of circa 100 billion tokens.\nFootnote or Reference text (if exists): 6 https://code.google.com/p/word2vec\nSection Titles (if exists):  ['4 Semantic spaces', '4.1 The distributional semantic space']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.lsi.upc.edu/asiya/\nCitation Context: While standard algorithms can be used to build prediction models, key to this task is work of feature engineering. Two open source feature extraction toolkits are available for that: A SIYA [URL_CITE] and Q U E ST (Specia et al., 2013). The latter has been used as the official baseline for the WMT shared tasks and extended by a number of partic-ipants, leading to improved results over the years (Callison-Burch et al., 2012; Bojar et al., 2013; Bojar et al., 2014).\nFootnote or Reference text (if exists): 1 http://nlp.lsi.upc.edu/asiya/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://xjtu-intsoft.github.io/chase\nCitation Context: To understand the characteristics of C HASE , we conduct a detailed data analysis and experi-ment with three state-of-the-art (SOTA) XDTS approaches, namely, EditSQL (Zhang et al., 2019), IGSQL (Cai and Wan, 2020), and our extension of RAT-SQL (Wang et al., 2020a). The best approach only achieves an exact match accuracy of 40% over all questions and 16% over all question sequences, indicating that C HASE presents significant chal-lenges for future research. The dataset, benchmark approaches, and our annotation tools are available at [URL_CITE] https://xjtu-intsoft.github.io/chase.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/datasets\nCitation Context: We obtain closed-book QA datasets from https://github.com/facebookresearch/DPR/blob/master/data/downloaddata.py, knowledge-intensive language tasks from https://github.com/facebookresearch/KILT/blob/master/scripts/donwload all kilt data.py. We obtain ROPES, WIQA and QuaRTz from hug-gingface datasets ( [URL_CITE] https://huggingface.co/datasets). For more details, see Table 6.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['D Reproducibility', 'D.1 Dataset Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.waikato.ac.nz/ml/weka/\nCitation Context: Given these features, as well as actual F-scores computed for the development data, we use supervised learning to set the feature weights. To this end, we use SVM-Regression [URL_CITE] (Smola and Schoelkopf, 1998) with an RBF kernel, to learn the feature weights and build our predictor system. We validate the accuracy of the predictor trained in this fashion on both WSJ (Section 4) and the Brown cor-pus (Section 5).\nFootnote or Reference text (if exists): 2 Weka software (http://www.cs.waikato.ac.nz/ml/weka/)\nSection Titles (if exists):  ['2 Related Work and Experimental Framework']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool:**  The citation refers to Weka as a software tool used for machine learning tasks.\n* **TYPE: Tool:** Weka"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/HuthLab/IGF\nCitation Context: Standard fine-tuning on Books achieves a median perplexity of 57.3, compared to 56.9 for IGF with a constant threshold and 54.0 for IGF with the shifting threshold schedule. [URL_CITE] All 50 runs of IGF with a shifting schedule outperformed all 50 stan-dard fine-tuning runs. This means that the over-all improvements to data order that IGF achieves through selective sampling of informative contexts are far in excess of what might be reasonably achieved through random sampling of contexts.\nFootnote or Reference text (if exists): 2 Demo code and data can be found at https://github.com/HuthLab/IGF. dit comments (25% of contexts) and a corpus of books (75% of contexts) were mixed into a single training dataset. Using the predicted q-value generated from our convolutional secondary learner, we can achieve good separation of the corpora using the information gain metric despite computing the true q-value using a small objective set. The percentage of examples from the Books corpus that are higher than several frequently the WikiText-103 dataset. We plot the model perplexity over many batches as in Figure 4 of the paper. This fig-ure can be replicated by following the Jupyter tutorial provided along with the supplementary material. ity of standard at each step. This serves as a barome-ter for comparing the relative efficiency of fine-tuning. In the early stages of fine-tuning, we can see that IGF requires 30%-40% fewer backpropagation steps over standard fine-tuning. This suggests that IGF could be used as a more energy efficient alternative to standard language model fine-tuning. Note that since IGF con-verges to a lower final value than standard fine-tuning, these values asymptote to a fixed value.\nSection Titles (if exists):  ['5 Results', '5.1 Language Model Fine-tuning']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://disi.unitn.it/moschitti/Tree-Kernel.htm\nCitation Context: Reranking models based on SVM and PTK have been trained with \u201cSVM-Light-TK\u201d [URL_CITE] . Kernel param-eters M and SVM parameter C have been optimized on the development set, as well as thresholds for the WRR (see section 4.2).\nFootnote or Reference text (if exists): 3 available at http://disi.unitn.it/moschitti/Tree-Kernel.htm\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/saffsd/langid.py\nCitation Context: We extract texts written by learners who learn only English from Lang-8. A language identification tool langid.py [URL_CITE] (Lui and Baldwin, 2011) is then used to obtain purely English sentences. In addition, we remove noisy source-target sentence pairs in Lang8 where the ratio of the lengths of the source and target sentences is outside [0.5, 2.0], or their word overlap ratio is less than 0.2.\nFootnote or Reference text (if exists): 1 https://github.com/saffsd/langid.py\nSection Titles (if exists):  ['6 Data and Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://bit.ly/2QHE5O3\nCitation Context: Table 2: Percent energy sourced from: Renewable (e.g. hydro, solar, wind), natural gas, coal and nuclear for the top 3 cloud compute providers (Cook et al., 2017), compared to the United States, 4 China [URL_CITE] and Germany (Burger, 2019).\nFootnote or Reference text (if exists): 5 China Electricity Council; trans. China Energy Portal: https://bit.ly/2QHE5O3\nSection Titles (if exists):  ['2 Methods']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://taku910.github.io/cabocha/\nCitation Context: For this reason, we evaluate the parser outputs by converting them to bunsetsu dependencies, the syntactic representation ordi-nary used in Japanese NLP (Kudo and Matsumoto, 2002). Given a CCG tree, we obtain this by first segment a sentence into bunsetsu (chunks) using CaboCha [URL_CITE] and extract dependencies that cross a bunsetsu boundary after obtaining the word-level, head final dependencies as in Figure 4b. For ex-ample, the sentence in Figure 4e is segmented as \u201cBoku wa | eigo wo | hanashi tai\u201d, from which we extract two dependencies (Boku wa) \u2190 (hanashi tai) and (eigo wo) \u2190 (hanashi tai).\nFootnote or Reference text (if exists): 11 http://taku910.github.io/cabocha/\nSection Titles (if exists):  ['6 Experiments', '6.2 Japanese Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.macmillandictionary.com/dictionary/american/\nCitation Context: In con-trast, the meaning to experience something bad of to go through [a situation] (ibid., (7)), or the sense to do/conduct of to get [something] done (ibid., (5)), are strongly conventionalized, as indicated by their inclusion in dictionaries. [URL_CITE]\nFootnote or Reference text (if exists): 4 e.g., https://www.macmillandictionary.com/dictionary/american/go-through#go-through 7, https://www.macmillandictionary.com/dictionary/american/ get#get 60\nSection Titles (if exists):  ['3 Corpus', '3.3 Analysis']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE:  DataSource\nFUNCTION:  Compare \n\n\nLet's break down why:\n\n* **ROLE: Material** - The cited resource is a dictionary, which serves as a source of information about word meanings and usage."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aclweb.org/anthology/N10-1090\nCitation Context: Zhang et al. (2010) [URL_CITE] use the syntactic dependencies in a different way, and show that dependency-based features are useful for predicting HPSG supertags.\nFootnote or Reference text (if exists): Yao-zhong Zhang, Takuya Matsuzaki, and Jun\u2019ichi Tsujii. 2010. A Simple Approach for HPSG Su-pertagging Using Dependency Information. In Hu-man Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Associ-ation for Computational Linguistics, pages 645\u2013648. http://aclweb.org/anthology/N10-1090.\nSection Titles (if exists):  ['7 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dbamman/NAACL2019-literary-entities\nCitation Context: All data is freely available for public use under a Creative Commons Sharealike license and is avail-able at: https://github.com/dbamman/ litbank; code to support this work can be found at: [URL_CITE] https://github.com/dbamman/NAACL2019-literary-entities.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt15/\nCitation Context: (2016) demonstrated that bpe boosts NMT, so sim-ilar to CDNMT we also preprocess the source side of our corpora using bpe. We use WMT-15 corpora [URL_CITE] to train the models, newstest-2013 for tuning and newstest-2015 as the test sets. For English\u2013Turkish (En\u2013Tr) we use the OpenSubtitle2016 collection (Lison and Tiedemann, 2016).\nFootnote or Reference text (if exists): 1 http://www.statmt.org/wmt15/\nSection Titles (if exists):  ['4 Experimental Study', '4.1 Experimental Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf\nCitation Context: However, it cannot fully take advantage the training data if it comes from multiple source domains. MS,ST adaptation (Mansour et al., 2009 [URL_CITE] ; Zhao et al., 2017) can deal with multiple source domains but only transfers to a single target domain. Therefore, when multiple target domains exist, they need to treat them as independent prob-lems, which is more expensive and cannot utilize the additional unlabeled data in these domains.\nFootnote or Reference text (if exists): Yishay Mansour, Mehryar Mohri, and Afshin Ros-tamizadeh. 2009. Domain adaptation with multiple sources. In Advances in Neural Information Processing Systems 21, Curran Associates, Inc., pages 1041\u20131048. http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://time2002.org/\nCitation Context: For the evaluation a corpus of questions containing as many simple as complex questions is required. Due to the fact that question corpora used in TREC (TREC, ) and CLEF (CLEF, ) do not contain com-plex questions, the TERQAS question corpus has been chosen (Radev and Sundheim, 2002; Puste-jovsky, 2002 [URL_CITE] ). It consists of 123 temporal questions.\nFootnote or Reference text (if exists): J. Pustejovsky. 2002. Terqas:time and event recognition for question answering systems. http://time2002.org/.\nSection Titles (if exists):  ['4 Question Decomposition Unit', '4.3.3 Example']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://verbs.colorado.edu/semlink/\nCitation Context: The wide coverage of VN in SimVerb-3500 assures the wide coverage of distinct verb groups/classes and their related linguistic phenom-ena. Finally, VerbNet enables further connections of SimVerb-3500 to other important lexical resources such as FrameNet (Baker et al., 1998), WordNet (Miller, 1995), and PropBank (Palmer et al., 2005) through the sets of mappings created by the SemLink project initiative (Loper et al., 2007). [URL_CITE]\nFootnote or Reference text (if exists): 7 https://verbs.colorado.edu/semlink/\nSection Titles (if exists):  ['3 The SimVerb-3500 Data Set', '3.2 Choice of Verb Pairs and Coverage']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a project website (SemLink) that provides mappings between different lexical resources. This website is being"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://wapo.st/2rucTq8\nCitation Context: While politicians may refrain themselves from making outright false claims to avoid being fact-checked, oftentimes they even double down after their false claims are debunked. [URL_CITE]\nFootnote or Reference text (if exists): 9 https://wapo.st/2rucTq8\nSection Titles (if exists):  ['2 System Architecture and Components', '2.5 Claim Matcher']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2017T01\nCitation Context: We construct our corpus by extending Kato et al. (2016)\u2019s corpus [URL_CITE] , which is itself built on a corpus by Shigeto et al. (2013).\nFootnote or Reference text (if exists): 5 https://catalog.ldc.upenn.edu/LDC2017T01\nSection Titles (if exists):  ['2 MWE-aware Dependency Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2012T21\nCitation Context: To unsupervisedly pre-train our document model H IBERT (see Section 3.2 for details), we created the GIGA-CM dataset (totally 6,626,842 documents and 2,854 million words), which in-cludes 6,339,616 documents sampled from the En-glish Gigaword [URL_CITE] dataset and the training split of the CNNDM dataset. We used the validation set of CNNDM as the validation set of GIGA-CM as well.\nFootnote or Reference text (if exists): 4 https://catalog.ldc.upenn.edu/LDC2012T21\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/xuuuluuu/SynLSTM-for-NER\nCitation Context: Our fur-ther analysis demonstrates that our model can capture longer dependencies compared with strong baselines. [URL_CITE]\nFootnote or Reference text (if exists): 1 We make our code publicly available at https://github.com/xuuuluuu/SynLSTM-for-NER.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://hotpotqa.github.io\nCitation Context: Results on our brand new NQ test set are 3/4 points lower for EM and F1-score than dev results. We don\u2019t evaluate multi-hop specific baselines on KILT but the current best F1-score for HotpotQA is 75.43 according to the official lead-earboard [URL_CITE] , that is quite far from what achieved by our general solutions. BLINK results are in line with what reported in the GitHub repository for all three entity linking datasets.\nFootnote or Reference text (if exists): 19 https://hotpotqa.github.io\nSection Titles (if exists):  ['7:453\u2013466.']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://casmacat.eu/corpus/\nCitation Context: Our data comes primarily from WikiMatrix (Schwenk et al., 2019), Global Voices, [URL_CITE] EuroParl\nFootnote or Reference text (if exists): 5 http://casmacat.eu/corpus/ Bootstrap resampling (Koehn, 2004; Graham et al., global-voices.html 2014) is used to estimate confidence intervals for\nSection Titles (if exists):  ['1 Introduction', '4.2 Model Training']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The URL points to a corpus, which is a collection of data used for training and evaluating machine learning models. This aligns with"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://aclweb.org/anthology/D16-1264\nCitation Context: It has been hypothesized that difficult MRC problems re-quire some form of multi-step synthesis and rea-soning. For instance, the following example from the MRC dataset SQuAD (Rajpurkar et al., 2016) [URL_CITE] illustrates the need for synthesis of information across sentences and multiple steps of reasoning:\nFootnote or Reference text (if exists): Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text pages 2383\u20132392. https://aclweb.org/anthology/D16-1264.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/csong27/collision-bert\nCitation Context: We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at [URL_CITE] https://github.com/csong27/collision-bert.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://readium.org\nCitation Context: Mobile versions of MTTR are built using Apache Cordova \u2013 a cross-platform toolkit \u2013 with platform-specific modifications where nec-essary. The reading and listening components in all versions are built on top of Readium [URL_CITE] , a robust, standards-compliant, and open-source e-reader. Figure 1 shows a screenshot of the iOS version of MTTR.\nFootnote or Reference text (if exists): 4 https://readium.org\nSection Titles (if exists):  ['3 My Turn To Read App']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/SinaWeibo\nCitation Context: Weibo, in particular Sina Weibo [URL_CITE] , has attracted more than 30% of Internet users (Yang et al., 2012), making it one of the most popular social media services in the world. While Weibo posts are abundantly available, NLP techniques for ana-lyzing Weibo posts have not been well-studied in the past.\nFootnote or Reference text (if exists): 1 http://en.wikipedia.org/wiki/Sina Weibo\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.mturk.com/\nCitation Context: To verify whether human evaluators are in agree-ment with our characterization model, we con-ducted a user study using MTurk (Amazon, 2005) [URL_CITE] .\nFootnote or Reference text (if exists): Amazon. 2005. MTurk. (https://www.mturk.com/).\nSection Titles (if exists):  ['5 User study']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://visionandlanguage.net/VIST/dataset.html\nCitation Context: SIND, ROCStory: SIND is a visual storytelling dataset [URL_CITE] (Huang et al., 2016), which is re-leased as training/validation/testing following the 8:1:1 split. ROCStory is a commonsense story dataset (Wang and Wan, 2019; Mostafazadeh et al., 2016).\nFootnote or Reference text (if exists): 3 http://visionandlanguage.net/VIST/dataset.html\nSection Titles (if exists):  ['3 Experiments', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://kbqademo.gstore.cn\nCitation Context: Moreover, we develop a novel data annotation strategy that facilitates the node-to-mention alignment, a dataset with such strat-egy is also published to promote further re-search. An online demo of NAMER [URL_CITE] is pro-vided to visualize our framework and supply extra information for users, a video illustra-tion of NAMER is also available.\nFootnote or Reference text (if exists): 2 http://kbqademo.gstore.cn\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://pypi.python.org/pypi/jieba\nCitation Context: We apply the Adam algorithm (Kingma and Ba, 2015) for optimization, where the parameters of Adam are set as in (Kingma and Ba, 2015). The variance \u03c3 [URL_CITE] of the Gaussian Kernel layer is set as 1, and all other trainable parameters are randomly initialized by uniform distribution within [-0.08,0.08]. The mini-batch size for the update is set as 128.\nFootnote or Reference text (if exists): 2 https://pypi.python.org/pypi/jieba\nSection Titles (if exists):  ['4 Experiment', '4.3 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.aclweb.org/anthology/D17-1180\nCitation Context: Indeed, Kasai et al. (2017) [URL_CITE] and Friedman et al. (2017) demonstrated that their unlexicalized neural network TAG parsers that only get as in-put predicted supertags can achieve state-of-the-art performance, with lexical inputs providing no improvement in performance.\nFootnote or Reference text (if exists): Jungo Kasai, Robert Frank, Tom McCoy, Owen Rambow, and Alexis Nasr. 2017. TAG pars-ing with neural networks and vector representa-tions of supertags. In EMNLP. Association for Computational Linguistics, Copenhagen, Denmark, pages 1713\u20131723. https://www.aclweb.org/anthology/D17-1180.\nSection Titles (if exists):  ['2 Our Models', '2.2 Parsing Model', '2.2.1 Input Representations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare \n\n\nLet me break down why:\n\n* **ROLE: Supplement** - The citation refers to a specific research paper that provides context and comparison points for the authors' own work. It'"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/parsing/preprocessing.html\nCitation Context: As to the Chinese Weibo dataset, we use FudanNLP toolkit (Qiu et al., 2013) for word segmentation. In addition, for each dataset, we maintain a vocab-ulary built based on the training set with removal of stop words [URL_CITE] and words occurring less than 3 times. The inputs of topic models x BoW are con-structed based on this vocabulary following com-mon topic model settings (Blei et al., 2003; Miao et al., 2016).\nFootnote or Reference text (if exists): 10 https://radimrehurek.com/gensim/parsing/preprocessing.html\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mallet.cs.umass.edu\nCitation Context: Since SCR, SC, SR and CR model have loopy examples, TRP approximate inference is nec-essary. To perform training and testing with CRFs, we use GRMM (Sutton, 2006) [URL_CITE] with TRP. We set the Gaussian Prior variances for weights as \u03c3 2 = 10 in all models.\nFootnote or Reference text (if exists): Charles Sutton. 2006. GRMM: A graphical models toolkit. http://mallet.cs.umass.edu.\nSection Titles (if exists):  ['3 Graph-based CRFs for NE Categorization in Wikipedia']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://kkma.snu.ac.kr/\nCitation Context: The Domain of this corpus cov-ers typical news articles such as health, entertain-ment, technology, politics, world and others. We ran Kokoma Korean morpheme analyzer [URL_CITE] on each sentence of the Donga corpus to divide words into morphemes to build latent morpheme representa-tions.\nFootnote or Reference text (if exists): 4 http://kkma.snu.ac.kr/\nSection Titles (if exists):  ['6 Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/DeepLearnXMU/CG-RL\nCitation Context: Experimental results and in-depth analy-sis on several commonly-used datasets demon-strate the effectiveness and generality of our ap-proach. We have released our code at [URL_CITE] https: //github.com/DeepLearnXMU/CG-RL .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/N16-1142\nCitation Context: Given a dependency based co-occurrence matrix described in the previous section(s), we generate B I S PARSE -D EP embeddings using the framework from our prior work (Vyas and Carpuat, 2016) [URL_CITE] , which we henceforth call B I S PARSE . B I S PARSE generates sparse, bilingual word embeddings us-ing a dictionary learning objective with a spar-sity inducing l 1 penalty. We give a brief overview of this approach, the full details of which can be found in our prior work.\nFootnote or Reference text (if exists): Yogarshi Vyas and Marine Carpuat. 2016. Sparse Bilingual Word Representations for Cross-lingual Lexical Entailment. Association for Computational Linguistics, San Diego, California, pages 1187\u2013 1197. http://www.aclweb.org/anthology/N16-1142.\nSection Titles (if exists):  ['3 Our Approach \u2013 B I S PARSE -D EP', '3.3 Bilingual Sparse Coding']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://gun-violence.org/\nCitation Context: We also thank the students of the University of Pennsylvania\u2019s crowdsourcing class (NETS 213) for their involvement in building and testing a useful crowdsourcing pipeline for in-formation extraction. Finally, we thank the devel-opers at 10clouds for the excellent engineering and design of [URL_CITE] http://gun-violence.org/. Amit Singhal.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6213\nCitation Context: We hypothesize that our multi-task learning yields feature representations in the LSTM layers that are more linguistically relevant and that gener-alize better (Caruana, 1997). We provide support for this hypothesis by analyzing syntactic analo-gies across induced vector representations of su-pertags (Kasai et al., 2017; Friedman et al., 2017 [URL_CITE] ). The end-to-end TAG parser substantially outper-forms the previously reported best results.\nFootnote or Reference text (if exists): Dan Friedman, Jungo Kasai, R. Thomas McCoy, Robert Frank, Forrest Davis, and Owen Rambow. 2017. Linguistically rich vector representations of supertags for TAG parsing. In TAG+. Associa-tion for Computational Linguistics, Umea\u030a, Sweden, pages 122\u2013131. http://www.aclweb.org/anthology/W17-6213.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.mturk.com/\nCitation Context: We randomly select 100 candidates and compare the outputs of different systems. We use Ama-zon Turk [URL_CITE] for human evaluation. Each candidate is rated by three annotators and we report the av-erage scores here.\nFootnote or Reference text (if exists): 8 https://www.mturk.com/ tent preservation. Mean denotes the average of the met-\nSection Titles (if exists):  ['3 Experiments', '3.5 Human Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/andy194673/nlg-sclstm-multiwoz\nCitation Context: The best model for both datasets was found through a grid search over a set of hyper-parameters such as the size of embeddings, learn-ing rate, and number of LSTM layers. [URL_CITE]\nFootnote or Reference text (if exists): 6 The model is publicly available at https://github.com/andy194673/ nlg-sclstm-multiwoz\nSection Titles (if exists):  ['5 MultiWOZ as a New Benchmark', '5.3 Dialogue-Act-to-Text Generation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool within the research process to generate dialogue acts. \n* **TYPE: Code** -"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/uwnlp/taggerflow\nCitation Context: (2016) obtain their sil-ver data annotated with the high quality supertags. Since they make this data publicly available [URL_CITE] , we obtain our silver data by assigning dependency\nFootnote or Reference text (if exists): 5 https://github.com/uwnlp/taggerflow\nSection Titles (if exists):  ['5 Tri-training']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/chakki-works/seqeval\nCitation Context: The metrics were calculated using seqeval (Nakayama, 2018) [URL_CITE] . \u2191 (\u2193) indicate whether the higher (or lower) the better from the attack perspective.\nFootnote or Reference text (if exists): Hiroki Nakayama. 2018. seqeval: A python framework for sequence labeling evaluation. Software available from https://github.com/chakki-works/seqeval.\nSection Titles (if exists):  ['4 Experiments', '4.2 Adversarial training']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.psychpark.org\nCitation Context: Then, the CIP randomly selects one seed pattern per run without replacement from the seed set, and iteratively induces relevant patterns from the psychiatry web corpora. The psychiatry web corpora used here include some professional mental health web sites, such as PsychPark ( [URL_CITE] http://www.psychpark.org) (Bai, 2001) and John Tung Foundation (http://www.jtf.org.tw).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Experimental Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.princeton.edu/~blei/lda-c/index.html\nCitation Context: We trained an LDA model with 20 top-ics on our document collection using David Blei\u2019s implementation. [URL_CITE] We used this model to re-rank the output of our annotation model according to the three most likely topics in each document.\nFootnote or Reference text (if exists): 3 Available from http://www.cs.princeton.edu/\u02dcblei/lda-c/index.html.\nSection Titles (if exists):  ['5 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/transformers/blob/694e2117f33d752ae89542e70b84533c52cb9142/README.md#optimizers\nCitation Context: We discard 3.87% of the training examples of DROP and 5.05% of the training example of Q UOREF , which are cases when the answer cannot be outputted by the model (due to a dataset error, or trunca-tion of the correct answer span). For training, the BertAdam [URL_CITE] optimizer is used with default parame-ters and learning rates of either 5 \u00d7 10 \u22126 or 10 \u22125 . Hyperparameter search was not performed.\nFootnote or Reference text (if exists): 4 https://github.com/huggingface/transformers/blob/694e2117f33d752ae89542e70b84533c52cb9142/README.md#optimizers\nSection Titles (if exists):  ['7:453\u2013466.']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.sogou.com/labs/dl/c.html\nCitation Context: Data preparation The data is composed of two parts: source documents and background knowl-edge. For source documents, we use a publicly available Chinese corpus which consists of 17,199 documents and 13,719,428 tokens extracted from Internet news [URL_CITE] including 9 topics: Finance, IT, Health, Sports, Travel, Education, Jobs, Art, Mil-itary. We then randomly but equally select 600 articles as the set of source documents from 9 top-ics without data bias.\nFootnote or Reference text (if exists): 2 http://www.sogou.com/labs/dl/c.html\nSection Titles (if exists):  ['5 Experiments', '5.1 Evaluation as a ranking problem']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/zhaozj89/TensorEmbeddingNLP\nCitation Context: The contributions of this paper are: 1) we pro-pose a tensor embedding method to model the lexical features of documents, which can cap-ture lexical similarity effectively regardless of the size of the corpus, 2) we show that the lex-ical features can be used effectively for fine-grained humor ranking and small sample humor recognition. Our implementation is open-sourced, and can be found at [URL_CITE] https://github.com/zhaozj89/TensorEmbeddingNLP.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.aclweb.org/anthology/D17-1180\nCitation Context: We also extend the models in Kasai et al. (2017) [URL_CITE] and Lewis et al. (2016) by allowing highway con-nections between LSTM layers.\nFootnote or Reference text (if exists): Jungo Kasai, Robert Frank, Tom McCoy, Owen Rambow, and Alexis Nasr. 2017. TAG pars-ing with neural networks and vector representa-tions of supertags. In EMNLP. Association for Computational Linguistics, Copenhagen, Denmark, pages 1713\u20131723. https://www.aclweb.org/anthology/D17-1180.\nSection Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model', '2.1.2 Deep Highway BiLSTM']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.aclweb.org/anthology/D17-1180\nCitation Context: This concatenation af-ter each layer differs from Kasai et al. (2017) [URL_CITE] and Lewis et al. (2016), where concatenation happens only after the final BiLSTM layer.\nFootnote or Reference text (if exists): Jungo Kasai, Robert Frank, Tom McCoy, Owen Rambow, and Alexis Nasr. 2017. TAG pars-ing with neural networks and vector representa-tions of supertags. In EMNLP. Association for Computational Linguistics, Copenhagen, Denmark, pages 1713\u20131723. https://www.aclweb.org/anthology/D17-1180.\nSection Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model', '2.1.2 Deep Highway BiLSTM']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/taka-yamakoshi/neural_constructions\nCitation Context: We collected judgments from 1011 participants on Amazon Mechanical Turk. Each participant was shown 50 dative alternation pairs (DO vs. PO) using unique verbs, balanced across the possible recipient and theme conditions. On each trial, par-ticipants used a continuous slider to indicate the strength of their preference for the DO or the PO, with the midpoint used to indicate they were \u201cabout the same\u201d (see Appendix A for details) [URL_CITE] .\nFootnote or Reference text (if exists): 1 Our procedure and behavioral analysis plan were pre-registered at https://osf.io/rtzv4 and we have re-leased all data and analysis code at https://github.com/taka-yamakoshi/neural_constructions.\nSection Titles (if exists):  ['3 The DAIS dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://textessence.github.io\nCitation Context: A screencast of TextEssence in action is available at https://youtu.be/1xEEfsMwL0k. All associated resources for TextEssence may be found at [URL_CITE] https://textessence.github.io.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/andreasvc/disco-dop\nCitation Context: We evaluate our parser on the test sets of the three treebanks. We report F-measure and discontinuous F-measure as computed using the disco-dop tool [URL_CITE] with standard parameters in Table 2. ants of our parsers produced exactly the same re-sults in all settings. This may be expected as their cover of the original treebanks are almost similar.\nFootnote or Reference text (if exists): 11 https://github.com/andreasvc/ disco-dop\nSection Titles (if exists):  ['4 Experiments', '4.3 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Method** - The tool is used as part of the research process (evaluating the parser).\n* **TYPE: Tool"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.whlib.ac.cn/sjk/bkqs.htm\nCitation Context: We used the labeled sentences as test data and the remaining sentences as unclassified data in English. We also used the sentences in the Great Encyclopedia [URL_CITE] Chinese corpus as unclassified data in Chinese. We defined, for each translation, a seed word in English as a classified example (cf., Table 5).\nFootnote or Reference text (if exists): 5 http://www.whlib.ac.cn/sjk/bkqs.htm\nSection Titles (if exists):  ['5 Word Translation Disambiguation', '6.2 Experiment 2: Yarowsky\u2019s Words']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/askerlee/topicvec\nCitation Context: \u2022 TopicVec (Li et al., 2016). A model incorpo-rates generative word embedding model with LDA [URL_CITE] . We also use default values for the pa-rameters.\nFootnote or Reference text (if exists): 8 https://github.com/askerlee/topicvec\nSection Titles (if exists):  ['4 Experiments', '4.1 Data and Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: http://www.cs.jhu.edu/~mdredze/datasets/sentiment/\nCitation Context: Sentiment analysis. The sentiment analysis datasets we examined include movie reviews (Pang and Lee, 2004; Zaidan and Eisner, 2008) , floor speeches by U.S. Congressmen deciding \u201cyea\"/\u201cnay\" votes on the bill under discussion (Thomas et al., 2006) 3 and product reviews from Amazon (Blitzer et al., 2007) [URL_CITE] .\nFootnote or Reference text (if exists): 4 http://www.cs.jhu.edu/~mdredze/datasets/sentiment/\nSection Titles (if exists): [\\'4 Experiments\\', \\'4.1 Datasets\\']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/kevinduh/sockeye-recipes/tree/master/egs/curriculum\nCitation Context: We evaluate on four domain adaptation tasks. The code base is provided to ensure reproducibility. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/kevinduh/sockeye-recipes/tree/master/egs/ curriculum\nSection Titles (if exists):  ['3 Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://yjernite.github.io/lfqa.html\nCitation Context: ELI5 (Fan et al., 2019b) [URL_CITE] is a collection of question-answer-evidence triples where the ques-tions are complex, and the answers are long, ex-planatory, and free-form. For dev and test, we col-lect annotations using Amazon Mechanical Turk, asking evaluators to select which supporting docu-ments from Wikipedia can be used to answer the question. We treat these as gold provenance anno-tations for evaluation (details in section 4).\nFootnote or Reference text (if exists): 8 https://yjernite.github.io/lfqa.html\nSection Titles (if exists):  ['3 Tasks', '3.4 Open Domain Question Answering']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1016/j.knosys.2019.105210\nCitation Context: CheckList enabled generating new (perturbed) test samples through abstracting different test types aimed at testing linguistic capabilities. Other studies focused on evaluating robustness to perturbed inputs for machine translation (Belinkov and Bisk, 2018; Niu et al., 2020), perturbation sensitivity analysis for detecting unintended model biases (Prabhakaran et al., 2019), or robustness to adversarial perturbations (Alshemali and Kalita, 2020 [URL_CITE] ; Ebrahimi et al., 2018; Liang et al., 2018). However, a comprehensive methodology for evaluating the performance of NLP models under real-world conditions is still missing.\nFootnote or Reference text (if exists): Basemah Alshemali, and Jugal Kalita. 2020. Improving the Reliability of Deep Neural Networks in NLP: A Review. Knowledge-Based Systems, 191: 105210. https://doi.org/10.1016/j.knosys.2019.105210.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://protege.stanford.edu/\nCitation Context: OWL allows us to define concept hierarchies, re-lations between concepts, domains and ranges of these relations, as well as specific relation in-stances between instances of a concept. Our on-tologies are defined by the freely available ontol-ogy editor Prote\u0301ge\u0301 4.0 [URL_CITE] . The advantage of using an ontology for structuring the domain knowledge is the modular non-redundant encoding.\nFootnote or Reference text (if exists): 2 http://protege.stanford.edu/, as accessed 27 Oct 2009\nSection Titles (if exists):  ['3 Knowledge Representation and Semantic Inference']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.reddit.com\nCitation Context: Online conversations are increasingly significant for communication, e.g., Slack for work com-munication and Reddit [URL_CITE] for general discussion. To organize overwhelming information from these conversations, researchers have been working on summarizing online conversations (Bhatia et al., 2014; Carenini et al., 2007; Mehdad et al., 2013, 2014; Oya et al., 2014).\nFootnote or Reference text (if exists): 2 https://www.reddit.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/domluna/memn2n\nCitation Context: For MemN2N, we use the publicly available im-plementation [URL_CITE] and train it exactly as all other mod-els (same optimizer, total epochs, and early stop-ping criteria) for fairness. While the reported best result for MemN2N is on the version with posi-tion encoding, linear start training, and random-injection of time index noise (Sukhbaatar et al., 2015), the version we use has only position encod-ing. Note that the comparison is still meaningful because linear start training and time index noise are not used in DMN+ (and as a result, neither in our proposed DSMN).\nFootnote or Reference text (if exists): 2 https://github.com/domluna/memn2n\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool to implement and experiment with the MemN2N model. \n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://git.io/JfV6J\nCitation Context: (2019) and parse test captions with Benepar (Kitaev and Klein, 2018). We use the same data preprocess-ing [URL_CITE] as in Shen et al. (2019) and Kim et al.\nFootnote or Reference text (if exists): 4 https://git.io/JfV6J.\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets and evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jzhou316/Unsupervised-Sentence-Summarization\nCitation Context: We explicitly manage the ELMo hid-den states to allow our model to generate con-textual embeddings sequentially for efficient beam search. [URL_CITE] The fluency language model component lm is task specific, and pretrained on a corpus of summarizations. We use an LSTM model with 2 layers, both embedding size and hidden size set to 1024.\nFootnote or Reference text (if exists): 1 Code available at https://github.com/jzhou316/Unsupervised-Sentence-Summarization.\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/clab/lstm-parser/tree/easy-to-use\nCitation Context: DeepCx is implemented using a refactored version of the LSTM parser codebase that performs iden-tically to the original. [URL_CITE] The neural network frame-work, which also underlies the LSTM parser, is an early version of DyNet (Neubig et al., 2017). The LSTM parser model is pretrained on the usual Penn Treebank (Marcus et al., 1994) sections (training: 02\u201321; development: 22).\nFootnote or Reference text (if exists): 2 https://github.com/clab/lstm-parser/tree/easy-to-use.\nSection Titles (if exists):  ['5 DeepCx neural network architecture', '5.3 Implementation details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being used as a foundational component in the development of DeepCx. \n* **TYPE: Code** -"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/P16-1101\nCitation Context: Input, layer-to-layer, and recurrent (Gal and Ghahramani, 2016) dropout rates are all 0.5. For the CNN character-level representation, we used the hyperparameters from Ma and Hovy (2016) [URL_CITE] .\nFootnote or Reference text (if exists): Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. In ACL. Association for Computational Linguistics, Berlin, Germany, pages 1064\u20131074. http://www.aclweb.org/anthology/P16-1101.\nSection Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model', '2.1.2 Deep Highway BiLSTM']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.copyright.gov/title17/92chap1.html#107\nCitation Context: How-ever, you could claim the concept of fair use which allows the use of copyrighted material without per-mission from the copyright holder when it is used for research, scholarship, and teaching\u201d. We also consulted Section 107 [URL_CITE] of U.S. Copyright Act and ensured that our collection action fell under fair use category.\nFootnote or Reference text (if exists): 9 https://www.copyright.gov/title17/92chap1.html#107\nSection Titles (if exists):  ['8 Ethical Considerations', '8.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/anjalief/unsupervised_gender_bias\nCitation Context: Ulti-mately, our work offers a way to capture subtle biases in various domains without relying on subjective human judgements. [URL_CITE]\nFootnote or Reference text (if exists): 1 Code and pre-trained models are available at https: //github.com/anjalief/unsupervised_ gender_bias\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being presented as a tool used in the research. It's not just a dataset or a reference point,"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1109/ICDM.2015.68\nCitation Context: Multi-Domain Text Classification The MDTC task was first examined by Li and Zong (2008), who proposed to fuse the training data from multi-ple domains either at the feature level or the classi-fier level. The prior art of MDTC (Wu and Huang, 2015) [URL_CITE] decomposes the text classifier into a gen-eral one and a set of domain-specific ones. How-ever, the general classifier is learned by param-eter sharing and domain-specific knowledge may sneak into it.\nFootnote or Reference text (if exists): Fangzhao Wu and Yongfeng Huang. 2015. Collabora-tive multi-domain sentiment classification. In 2015 IEEE International Conference on Data Mining. pages 459\u2013468. https://doi.org/10.1109/ICDM.2015.68.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://knowitall.github.io/ollie/\nCitation Context: We extract relational triples from each sentence in a large corpus using the OLLIE Open IE system (Mausam et al., 2012). [URL_CITE] This provides relational tu-ples in the format (Arg1, Relation, Arg2) where each tuple element is a phrase from the sentence. The sentence \u201cHe cited a new study that was released by UCLA in 2008.\u201d produces three tuples:\nFootnote or Reference text (if exists): 4 Available at: http://knowitall.github.io/ollie/\nSection Titles (if exists):  ['3 Modeling Relational Co-occurrence', '3.1 Relations Extraction and Representation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/quankiquanki/\nCitation Context: Product Review Domains (Websis-CLS-10,(Prettenhofer and Stein, 2010)), CLCD English-German S-T D-B M-B B-D M-D B-M D-M English-French All D-B M-B B-D M-D B-M D-M All PBLM Models P+BE 78.7 78.6 80.6 79.2 81.7 78.5 PBLM 70.9 62.9 74.5 66.5 75.0 75.5 Lazy 74.8 74.0 75.1 72.8 73.3 73.7 79.5 81.1 74.7 76.3 75.0 75.1 76.8 76.5 71.0 76.0 67.9 70.3 69.9 67.3 70.4 70.3 73.9 74.2 73.1 75.3 74.4 74.1 72.4 73.9 Autoencoder+pivot Models A-S-SR 68.3 62.5 69.4 69.9 70.2 69 A-SCL 67.9 63.7 68.7 63.8 69.0 70.1 67.4 69.3 68.9 70.9 70.7 67 71.4 69.7 67.2 68.6 66.1 69.2 69.4 66.7 68.1 68.0 Pivot-based (no DNN) Models C-SCL 65.9 62.5 65.1 65.2 71.2 69.8 DCI 67.1 60.6 66.9 66.7 68.9 68.2 66.7 70.3 63.8 68.8 66.8 66.0 70.1 67.6 66.4 71.2 65.4 69.1 67.5 66.7 71.4 68.6 CLCD without CD Learning CNN 62.8 63.8 65.3 68.7 71.6 72.0 67.3 69.5 59.7 63.7 65.7 65.9 67.0 65.2 Airline (English, (Nguyen, 2015) [URL_CITE] ) to Product Review Domains (German or French), CLCD English-German English-French Source-Target A-B A-D A-M All A-B A-D A-M All PBLM Models P+BE 64 6. 65.167.9 62.5 63.6 63.5 66.9 64.8 PBLM 60.9 59.6 60.1 .60 2 60.9 61.9 58.9 60.5 Lazy 66.3 65.0 66.6 66 0.\nFootnote or Reference text (if exists): Quang Nguyen. 2015. The airline review dataset. https://github.com/quankiquanki/skytrax-reviews-dataset. Scraped from www.airlinequality.com.\nSection Titles (if exists):  ['6 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/sheffieldnlp/fever-scorer\nCitation Context: This task has three evaluations: (i) N O S CORE E V \u2013 accuracy of claim verifica-tion, neglecting the validity of evidence; (ii) S CORE E V \u2013 accuracy of claim verification with a requirement that the predicted evidence fully covers the gold evidence for S UPPORTED and R E - FUTED ; (iii) F 1 \u2013 between the predicted evidence sentences and the ones chosen by annotators. We use the officially released evaluation scorer [URL_CITE] .\nFootnote or Reference text (if exists): 3 https://github.com/sheffieldnlp/fever-scorer\nSection Titles (if exists):  ['4 Experiments', '4.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://cloud.google.com/tpu\nCitation Context: Using the proposed T IME D IAL challenge set, we next conduct extensive experiments and analyses on the different model variants and context settings. We use either 4x4 or 8x8 Cloud TPUs V3 pod slices [URL_CITE] for fine-tuning and one V100 GPU for infer-ence. We provide more details of the experiment configurations in the appendix.\nFootnote or Reference text (if exists): 5 https://cloud.google.com/tpu\nSection Titles (if exists):  ['5 Experiments and Analyses']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/SapienzaNLP/sgl\nCitation Context: Furthermore, we find that mod-els trained under this configuration scale re-markably well to tasks such as cross-lingual AMR parsing: SGL outperforms all its com-petitors by a large margin without even explic-itly seeing non-English to AMR examples at training time and, once these examples are in-cluded as well, sets an unprecedented state of the art in this task. We release our code and our models for research purposes at [URL_CITE] https: //github.com/SapienzaNLP/sgl.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being used as a tool to conduct research (training models for cross-lingual AMR parsing).\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.wordgumbo.com/ie/cmp/iedata.txt\nCitation Context: (2005), model the expan-sion of the Indo-European language family and find support for the hypothesis which places its homeland in Anatolia; Atkinson and Gray (2006) analyze language divergence dates and argue for the usage of computational phylogenetic meth-ods in the question of Indo-European age and ori-gins. Using modified versions of Swadesh\u2019s lists [URL_CITE] , Dyen et al. (1992) investigate the classification of Indo-European languages by applying a lexicosta-tistical method.\nFootnote or Reference text (if exists): 1 http://www.wordgumbo.com/ie/cmp/iedata.txt\nSection Titles (if exists):  ['1 Introduction', '1.1 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://hackingsemantics.xyz/2019/leaderboards/\nCitation Context: Even today, practitioners can only use GPT-3 through an API, access to which is restricted. The cost-ignorance of leaderboards disproportionately affects practi-tioners with fewer resources (e.g., independent re-searchers) (Rogers, 2019) [URL_CITE] , since the resource de-mands would dwarf any utility from the model.\nFootnote or Reference text (if exists): Anna Rogers. 2019. How the transformers broke NLP leaderboards. https://hackingsemantics.xyz/2019/leaderboards/. Accessed: 2020-05- 20.\nSection Titles (if exists):  ['3 Utilitarian Critiques', '3.2 Prediction Cost']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We initialized our word representations using publicly available 300-dimensional Glove vec-tors [URL_CITE] (Pennington et al., 2014). For the sentiment classification task, word representations were up-dated during training with a learning rate of 0.1. For the semantic relatedness task, word represen-tations were held fixed as we did not observe any significant improvement when the representations were tuned.\nFootnote or Reference text (if exists): 5 Trained on 840 billion tokens of Common Crawl data, http://nlp.stanford.edu/projects/glove/.\nSection Titles (if exists):  ['5 Experiments', '5.3 Hyperparameters and Training Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The GloVe dataset provides pre-trained word embeddings, which are a fundamental material used in the cited research. "
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://textessence.github.io\nCitation Context: A case study on COVID-19 sci-entific literature illustrates the utility of the sys-tem. TextEssence can be found at [URL_CITE] https: //textessence.github.io.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0\nCitation Context: Named entity counts and concreteness ratio. For each turn, we calculate the number of named entities in five coarse-grained groups constructed from the fine-grained entity types of OntoNotes [URL_CITE] (Hovy et al., 2006): (1) events, (2) numbers, (3) organizations/locations, (4) persons, and (5) prod-ucts. We also calculate (6) a concreteness ratio: the number of named entities in the turn divided by the total number of tokens in the turn.\nFootnote or Reference text (if exists): 6 Version 5, https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0. pdf Section 2.6.\nSection Titles (if exists):  ['4 Pragmatic correlations with analysts\u2019 pre-call judgments', '4.1 Pragmatic lexical features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tuetschek/e2e-cleaning\nCitation Context: It uses modified regu-lar expressions from the e2e-cleaning repos-itory. [URL_CITE] https://github.com/tuetschek/ e2e-cleaning\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www-nlpir.nist.gov/MINDS/FINAL/MT.web.pdf\nCitation Context: Although the Markov chains are efficient at encoding local word interactions, the n-gram model clearly ignores the rich syntactic and semantic structures that constrain natural languages. As the machine translation (MT) working groups stated on page 3 of their final report (Lavie et al., 2006) [URL_CITE] , \u201cThese approaches have resulted in small im-provements in MT quality, but have not fundamen-tally solved the problem. There is a dire need for de-veloping novel approaches to language modeling.\u201d\nFootnote or Reference text (if exists): A. Lavie et al. 2006. MINDS Workshops Machine Translation Working Group Final Report. http://www-nlpir.nist.gov/MINDS/FINAL/MT.web.pdf\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/GeneZC/ASGCN\nCitation Context: Based on it, a novel aspect-specific sentiment classification framework is raised. Experiments on three benchmarking collections illustrate that our proposed model has comparable effectiveness to a range of state-of-the-art models [URL_CITE] , and further demon-strate that both syntactical information and long-range word dependencies are properly captured by the graph convolution structure.\nFootnote or Reference text (if exists): 1 Code and preprocessed datasets are available at https://github.com/GeneZC/ASGCN.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/JasperGuo/Unimer\nCitation Context: We plan to cover more domains and more MRs in U NIMER . We have made U NIMER along with the execution engines publicly available. [URL_CITE] We be-lieve that U NIMER can provide fertile soil for ex-ploring MRs and addressing challenges in semantic parsing.\nFootnote or Reference text (if exists): 3 Our benchmark, execution engines and and our im-plementation can be found on: https://github.com/JasperGuo/Unimer\nSection Titles (if exists):  ['3 Benchmark']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a tool (execution engines) and a dataset (benchmark) used in the research. \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/xinyadu/nqg\nCitation Context: The questions are written by crowd-workers and the answers are spans of tokens in the arti-cles. We employ two different data splits by fol-lowing (Zhou et al., 2017) and (Du et al., 2017) [URL_CITE] . In (Zhou et al., 2017), the original SQuAD de-velopment set is evenly divided into dev and test sets, while (Du et al., 2017) treats SQuAD devel-opment set as its test set and splits SQuAD training set into a training set (90%) and a development set (10%).\nFootnote or Reference text (if exists): 3 https://github.com/xinyadu/nqg\nSection Titles (if exists):  ['3 Experimental Setting', '3.1 Dataset & Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://registry.opendata.aws/amazon-reviews-ml/\nCitation Context: The Multilingual Amazon Reviews Corpus (MARC) can be found at [URL_CITE] https://registry.opendata.aws/amazon-reviews-ml/. The dataset description, code snippets, and li-cense agreement can be retrieved at https: //docs.opendata.aws/amazon-reviews-ml/ readme.html .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.sapere.it/sapere/dizionari\nCitation Context: We identify cognate pairs be-tween Romanian and six other languages: Ital-ian, French, Spanish, Portuguese, Turkish and En-glish. We use electronic dictionaries [URL_CITE] to extract etymology-related information and Google Trans-late to translate Romanian words. We are re-stricted in our investigation by the available re-sources, but we plan to extend our method to other related languages as well.\nFootnote or Reference text (if exists): 4 Italian: http://www.sapere.it/sapere/dizionari\nSection Titles (if exists):  ['2 Methodology and Algorithm', '2.2 Algorithm', '2.2.2 Relationships Identification']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE:  Knowledge \nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.informatics.sussex.ac.uk/research/groups/nlp/rasp\nCitation Context: For instance, the BioNLP shared task organizers have provided output from a num-ber of parsers , alleviating the need for participat-ing systems to download and run unfamiliar tools. On the other hand, many community members provide downloads of NLP tools [URL_CITE] to increase ac-cessibility and replicability of core components.\nFootnote or Reference text (if exists): 2 See, for example, http://nlp.stanford.edu/software; http://www.informatics.sussex.ac.uk/research/groups/nlp/rasp; http://incubator.apache.org/opennlp\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://translate.google.com\nCitation Context: In the experiment, the basic transfer learning algorithm is co-training. The Chinese word seg-mentation tool is ICTCLAS (Zhang et al, 2003) and Google Translator [URL_CITE] is the MT for the source language. The monolingual opinion classifier is SVM light4 , word unigram/bigram features are em-ployed.\nFootnote or Reference text (if exists): 3 https://translate.google.com\nSection Titles (if exists):  ['4 Experiment', '4.1 Experiment Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.bbc.com/news/technology-24299742\nCitation Context: However, the question remains: is every online review trustful? It has been reported that up to 25% of the reviews on Yelp.com could be fraudu-lent [URL_CITE] . Due to the great profit or reputation, impostors or spammers energetically post fake reviews on the web to promote or defame targeted products (Jindal and Liu, 2008).\nFootnote or Reference text (if exists): 1 http://www.bbc.com/news/technology-24299742\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION:  Introduce \n\n\nLet me explain:\n\n* **ROLE: Supplement** - The article cited is not directly used in the research (like a tool or dataset), but it provides background information and context"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.lycos.com/info/public-key-cryptography.html\nCitation Context: Figure 1 shows a sample Retriever page for the topic \u201cMario Lemieux\u201d. [URL_CITE] The topic is indicated at the upper left. Below it is a category assigned to the topic, in this case Sports > Hockey > Ice Hockey > National Hockey League > Lemieux, Mario.\nFootnote or Reference text (if exists): 4 For other categories, see e.g. King Kong (1933): http://www.lycos.com/info/king-kong-1933.html, Zoloft: http://www.lycos.com/info/zoloft.html, Public-Key Cryptography: http://www.lycos.com/info/public-key-cryptography.html , Lyme Disease: http://www.lycos.com/info/lyme-disease.html, Reggaeton: http://www.lycos.com/info/reggaeton.html\nSection Titles (if exists):  ['3 Lycos Retriever pages']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/data/glove.840B.300d.zip\nCitation Context: For training, our Our+FULL model is first ini-tialized by pre-training using Our+AVG model, and we set the iteration number over all the train-ing data as 10. For pre-trained word embeddings, we use the 300-dimensional GloVe [URL_CITE] (Pennington et al., 2014) word embeddings learned from 840B Web crawl data.\nFootnote or Reference text (if exists): 6 http://nlp.stanford.edu/data/glove.840B.300d.zip\nSection Titles (if exists):  ['4 Experiments', '4.3 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ai.mit.edu/people/jrennie/20_newsgroups/\nCitation Context: All methods are initialized by a ran-dom choice of 10 document labels and 10 word la-bels. For simplicity, we follow the widely used cost model (Raghavan and Allan, 2007; Druck et al., 2008; Sindhwani et al., 2009) where features are roughly 5 times cheaper to label than examples, so we assume the cost is [URL_CITE] for a word query and is 5 for a document query. We set \u03b1 = \u03b2 = 5, \u03b3 = 1 for all the following experiments 2 .\nFootnote or Reference text (if exists): 1 http://www.ai.mit.edu/people/jrennie/20_newsgroups/\nSection Titles (if exists):  ['6 Experiments', '6.1 Experiments Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The resource is a dataset (20 Newsgroups) used in the research.\n* **TYPE: Dataset** -"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://dialogflow.com/docs/getting-started/first-agent\nCitation Context: Conversational interfaces are a prominent fea-ture of many consumer technology products to-day. Popular voice assistants, such as Alexa, Siri, Google Assistant, and Cortana, have been built us-ing a methodical approach of domain-intent-entity classification and dialogue management that is be-coming an industry standard (Dialogflow, 2018 [URL_CITE] ; Wit.ai, 2018; Amazon, 2018; Microsoft, 2018).\nFootnote or Reference text (if exists): Dialogflow. 2018. Create and query your first agent. https://dialogflow.com/docs/getting-started/first-agent.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/salesforce/cove\nCitation Context: Both passage and question use a shared two-layers BiLSTM as the contextual encoding layer, which projects the lexicon embeddings to contextual embeddings. We concatenate a pre-trained 600-dimensional CoVe vectors [URL_CITE] (McCann et al., 2017) trained on German-English machine translation dataset, with the aforementioned lexicon embeddings as the fi-nal input of the contextual encoding layer, and also with the output of the first contextual encoding layer as the input of its second encoding layer. To reduce the parameter size, we use a maxout layer (Goodfellow et al., 2013) at each BiLSTM layer to shrink its dimension.\nFootnote or Reference text (if exists): 1 https://github.com/salesforce/cove\nSection Titles (if exists):  ['2 Proposed model: SAN']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/duyvuleo/Transformer-DyNet\nCitation Context: The dropout rate for the output layer is set to 0.2. For the Transformer, we use Transformer-DyNet [URL_CITE] implementation and extend it for our context-aware NMT model. The hidden dimensions and feed-forward layer size is set to 512 and 2048 respectively.\nFootnote or Reference text (if exists): 7 https://github.com/duyvuleo/Transformer-DyNet\nSection Titles (if exists):  ['4 Experiments', '4.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool:** The cited resource is a code implementation of the Transformer model, which is a tool used in the research.\n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/\nCitation Context: This experiment uses the 2006\u20132008 cor-pora of the Workshop on Statistical Machine Translation (WMT). [URL_CITE] It consists of data from EU-ROPARL (Koehn, 2005) and various news com-mentaries, with five source languages (French, Ger-man, Spanish, Czech, and Hungarian). As training set, we use the portions of WMT 2006 and 2007 that are annotated with absolute scores on a five-point scale (around 14,000 sentences produced by 40 systems).\nFootnote or Reference text (if exists): 7 Available from http://www.statmt.org/.\nSection Titles (if exists):  ['6 Expt. 2: Predicting Pairwise Preferences']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/software/lex-parser.shtml\nCitation Context: In all our experiments, both the constituency and dependency parse trees are produced by Stan-ford Parser [URL_CITE] . Specially, we train the parser on the GENIA Treebank 1.0 (Tateisi et al., 2005), which contains Penn Treebank-style syntactic (phrase structure) annotation for the GENIA corpus. The parser achieves the performance of 87.12% in F1-score in terms of 10-fold cross-validation on GENIA TreeBank 1.0.\nFootnote or Reference text (if exists): 2 http://nlp.stanford.edu/software/lex-parser.shtml\nSection Titles (if exists):  ['4 Experimentation', '4.2 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://spacy.io\nCitation Context: Implementation details: The spaCy tool [URL_CITE] is used to tokenize the both passages and questions, and generate lemma, part-of-speech and named entity tags. We use 2-layer BiLSTM with d = 128 hidden units for both passage and question encod-ing.\nFootnote or Reference text (if exists): 2 https://spacy.io\nSection Titles (if exists):  ['3 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/LayneIns/Unsupervised_dialo_disentanglement\nCitation Context: Moreover, we apply the disentangled conversations predicted by our method to the downstream task of multi-party response selection and get significant improvements compared to a baseline system. [URL_CITE] In summary, our main contributions are three-fold:\nFootnote or Reference text (if exists): 3 Code will be publicly available at https: //github.com/LayneIns/Unsupervised_ dialo_disentanglement\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/salesforce/cove\nCitation Context: Both passage and question use a shared two-layers BiLSTM as the contextual encoding layer, which projects the lexicon embeddings to contextual embeddings. We concatenate a pre-trained 600-dimensional CoVe vectors [URL_CITE] (McCann et al., 2017) trained on German-English machine translation dataset, with the aforementioned lexicon embeddings as the fi-nal input of the contextual encoding layer, and also with the output of the first contextual encoding layer as the input of its second encoding layer. To reduce the parameter size, we use a maxout layer (Goodfellow et al., 2013) at each BiLSTM layer to shrink its dimension.\nFootnote or Reference text (if exists): 1 https://github.com/salesforce/cove\nSection Titles (if exists):  ['2 Proposed model: SAN']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.delph-in.net/crawler/\nCitation Context: All numbers reported here reflect this frozen system. [URL_CITE]\nFootnote or Reference text (if exists): 10 The code and data are available from http://www.delph-in.net/crawler/ , for replicability (Fokkens et al., 2013).\nSection Titles (if exists):  ['4 Experiments', '4.1 Data Sets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The resource provides the source data used in the experiments.\n* **TYPE: DataSource** - It's a website hosting"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://L2R.cs.uiuc.edu/~cogcomp/data.php\nCitation Context: For our corpus, we selected 1,000 sentences con-taining at least one comma from the Penn Treebank (Marcus et al., 1993) WSJ section 00, and manu-ally annotated them with comma information [URL_CITE] . This annotated corpus served as both training and test datasets (using cross-validation).\nFootnote or Reference text (if exists): 3 The guidelines and annotations are available at http://L2R.cs.uiuc.edu/\u02dccogcomp/data.php. 19: Remove all examples from p that are covered by r 20: end for 21: end for\nSection Titles (if exists):  ['4 Corpus Annotation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://osf.io/z89vn/\nCitation Context: Results on reading and fMRI measures show substantial generalization im-provements from CDRNN over baselines, along with detailed insights about the underlying dynam-ics that cannot easily be obtained from existing methods. [URL_CITE]\nFootnote or Reference text (if exists): 1 Because of page constraints, additional replication details and synthetic results are provided in an external supplement, available here: https://osf.io/z89vn/.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/awslabs/fever\nCitation Context: We also conducted oracle experiments in which com-ponents of the pipeline were replaced by the gold standard annotations, and observed that the most challenging part of the task is selecting the sen-tences containing the evidence. In addition to pub-lishing the data via our website , we also publish the annotation interfaces [URL_CITE] and the baseline system to stimulate further research on verification.\nFootnote or Reference text (if exists): 2 https://github.com/awslabs/fever\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Tool** - The cited resource is a GitHub repository containing code for a baseline system. This suggests it's a tool used in"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ntcirstc.noahlab.com.hk/STC2/stc-cn.htm\nCitation Context: We conduct our experiments on the public Short Text Conversation (STC) dataset [URL_CITE] released in NTCIR-13. STC maintains a large reposit-ory of post-comment pairs from the Sina Weibo which is one of the popular Chinese social sites.\nFootnote or Reference text (if exists): 1 http://ntcirstc.noahlab.com.hk/STC2/stc-cn.htm\nSection Titles (if exists):  ['4 Experiment', '4.1 Dataset Description']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://homes.cs.washington.edu/~eunsol/project_page/acl16\nCitation Context: We evaluate the approach on a newly gathered corpus with dense document-level sentiment la-bels in news articles. [URL_CITE] This data includes compre-hensively annotated sentiment between all entity pairs, including those that do not appear together in any single sentence. Experiments demon-strate that the global model significantly improves performance over a pairwise classifier and other strong baselines.\nFootnote or Reference text (if exists): 1 All data will be made publicly available. You can browse it at http://homes.cs.washington.edu/\u02dceunsol/project_page/acl16, and download it from the author\u2019s webpage.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/cosmozhang/Modular_Neural_CRF\nCitation Context: All of our models beat the state-of-the-art results by a large margin. The source code and experimental setup are avail-able online [URL_CITE] .\nFootnote or Reference text (if exists): 4 https://github.com/cosmozhang/ Modular_Neural_CRF\nSection Titles (if exists):  ['6 Experimental Evaluation', '6.2 Q1: Monolithic vs. Modular Learning']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool to implement and evaluate the models in the research.\n* **TYPE: Code** -"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://bit.ly/2Qbr0w1\nCitation Context: Whereas a decade ago most mon NLP models, compared to familiar consumption. [URL_CITE] NLP models could be trained and developed on a commodity laptop or server, many now require multiple instances of specialized hardware such as GPUs or TPUs, therefore limiting access to these highly accurate models on the basis of finances.\nFootnote or Reference text (if exists): 1 Sources: (1) Air travel and per-capita consumption: https://bit.ly/2Hw0xWc; (2) car lifetime: https: //bit.ly/2Qbr0w1.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.cs.nyu.edu/pubs/\nCitation Context: This paper begins with an informal description of GMTG. It continues with an investigation of this formalism\u2019s generative capacity. Next, we prove that in GMTG each component grammar retains its generative power, a requirement for synchronous formalisms that Rambow and Satta (1996) called the \u201cweak language preservation property.\u201d Lastly, we propose a synchronous generalization of Chom-sky Normal Form, which lays the groundwork for synchronous parsing under GMTG using a CKY-style algorithm (Younger, 1967; Melamed, 2004 [URL_CITE] ).\nFootnote or Reference text (if exists): I. Dan Melamed, G. Satta, and B. Wellington. 2004. Gener-alized multitext grammars. Technical Report 04-003, NYU Proteus Project. http://nlp.cs.nyu.edu/pubs/.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://diamt.limsi.fr/eval.html\nCitation Context: We created two contrastive test sets to help com-pare how well different contextual MT mod-els handle (i) anaphoric pronoun translation and (ii) coherence and cohesion. [URL_CITE] For each test set, models are assessed on their ability to rank the cor-rect translation of an ambiguous sentence higher than the incorrect translation, using the disam-biguating context provided in the previous source and/or target sentence. All examples in the test sets are hand-crafted but inspired by real examples from OpenSubtitles2016 (Lison and Tiedemann, 2016) to ensure that they are credible and that vo-cabulary and syntactic structures are varied.\nFootnote or Reference text (if exists): 2 The test sets are freely available at https://diamt.limsi.fr/eval.html.\nSection Titles (if exists):  ['2 Evaluating contextual phenomena', '2.1 Our contrastive discursive test sets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The resource is a dataset of test cases designed for evaluating machine translation models. \n* **TYPE: Dataset**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/BLINK\nCitation Context: We don\u2019t evaluate multi-hop specific baselines on KILT but the current best F1-score for HotpotQA is 75.43 according to the official lead-earboard , that is quite far from what achieved by our general solutions. BLINK results are in line with what reported in the GitHub repository [URL_CITE] for all three entity linking datasets. The Tranformer MemNet of Dinan et al.\nFootnote or Reference text (if exists): 20 https://github.com/facebookresearch/ BLINK\nSection Titles (if exists):  ['7:453\u2013466.']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/seatgeek/fuzzywuzzy\nCitation Context: Figure 7: Average number of citations per paper that are 15 years or older, by venue of publication. tance ratio [URL_CITE] is \u2264 95%.\nFootnote or Reference text (if exists): 12 As implemented by https://github.com/seatgeek/fuzzywuzzy.\nSection Titles (if exists):  ['A Fuzzy paper matching']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/neukg/GRTE\nCitation Context: Ex-perimental results show our model is effective and it achieves state-of-the-art results on all of these datasets. The source code of our work is available at: [URL_CITE] https://github.com/neukg/GRTE.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.chokkan.org/software/crfsuite/\nCitation Context: For word-level prediction, Q U E ST ++ provides an interface for CRFSuite (Okazaki, 2007) [URL_CITE] , a se-quence labelling C++ library for Conditional Ran-dom Fields (CRF). One can configure CRFSuite training settings, produce models and test them.\nFootnote or Reference text (if exists): N. Okazaki. 2007. CRFsuite: a fast implementation of Conditional Random Fields. http://www.chokkan.org/software/crfsuite/.\nSection Titles (if exists):  ['2 Architecture']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/archive/p/word2vec/\nCitation Context: Word2vec We average word embeddings trained with word2vec. [URL_CITE] We use both architec-tures, Skipgram and CBOW, and apply default settings: minimum word frequency 5, word embedding size 300, context window 5, sample threshold 10 -5 , no hierarchical softmax, 5 negative examples.\nFootnote or Reference text (if exists): 2 The code is available from https://code.google.com/archive/p/word2vec/.\nSection Titles (if exists):  ['3 Experimental Setup', '3.2 Baselines']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.englishbaby.com/lessons/4349/slang/fruitcake\nCitation Context: She is a total fruitcake. [URL_CITE]\nFootnote or Reference text (if exists): 12 http://www.englishbaby.com/lessons/4349/slang/ fruitcake\nSection Titles (if exists):  ['5 Task 2: Finding most similar words for slang across languages', '5.2 Baseline and Our Methods']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a website explaining the meaning of the slang term \"fruitcake\". This information is supplementary to the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://svmlight.joachims.org\nCitation Context: The full details of SVR and its implementation are beyond the scope of this paper; interested readers are referred to Scho\u0308lkopf and Smola (2002). SVM light (Joachims, 1999) is a freely available implementa-tion of SVR training that we used in our experi-ments. [URL_CITE]\nFootnote or Reference text (if exists): 2 Available at http://svmlight.joachims.org.\nSection Titles (if exists):  ['3 Problem Formulation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/pytorch-pretrained-BERT\nCitation Context: bert-base-uncased). [URL_CITE] We optimize us-ing ADAM (Kingma and Ba, 2015) with an initial learning rate of 5e-5 and a warm-up rate of 0.1. We regularize using Dropout (Srivastava et al., 2014) after the BERT encoder with a rate of 0.4.\nFootnote or Reference text (if exists): 2 We use the BERT implementation from https://github.com/huggingface/ pytorch-pretrained-BERT\nSection Titles (if exists):  ['4 Experiment', '4.1 Experimental setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wapiti.limsi.fr\nCitation Context: De-spite the reduced set of features, training error rate at both token and sentence level is under 1%. We didn\u2019t carry out optimization for parameters \u03c1 1 and \u03c1 [URL_CITE] of the elastic net (see section 3.1), default values lead in most cases to very accurate models.\nFootnote or Reference text (if exists): 2 available at http://wapiti.limsi.fr\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Tool \nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Tool:** The citation refers to a software tool (\"WAPITI\") used in the experiments. \n* **TYPE: Tool"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/N16-1142\nCitation Context: More closely related is our prior work (Vyas and Carpuat, 2016) [URL_CITE] where we used lexical context based embeddings to detect cross-lingual lexical entailment. In contrast, the focus of this work is on hypernymy, a more well-defined relation than entailment. Also, we improve upon our previ-ous approach by using dependency based embed-dings (\u00a76.1), and show that the improvements hold even when exposed to data scarce settings (\u00a76.3).\nFootnote or Reference text (if exists): Yogarshi Vyas and Marine Carpuat. 2016. Sparse Bilingual Word Representations for Cross-lingual Lexical Entailment. Association for Computational Linguistics, San Diego, California, pages 1187\u2013 1197. http://www.aclweb.org/anthology/N16-1142.\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://mosaickg.apps.allenai.org/comet_conceptnet\nCitation Context: COMET is an adaptation framework for constructing common-sense knowledge based on pre-trained language models. Our work only leverages the HasProp-erty relation from COMET [URL_CITE] .\nFootnote or Reference text (if exists): 9 https://mosaickg.apps.allenai.org/ comet_conceptnet\nSection Titles (if exists):  ['2 SCOPE: Style Transfer through COmmonsense PropErty', '2.1 Automatic Parallel Corpus Creation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://plata.ar.media.kyoto-u.ac.jp/tool/EDA\nCitation Context: (2011), as implemented in the Eda toolkit. [URL_CITE] In order to convert dependencies into phrase-structure trees typically used in T2S translation, we use the head rules implemented in the Travatar toolkit. In addition, we also train a latent variable CFG using the Berkeley Parser and use Egret for parsing.\nFootnote or Reference text (if exists): 5 http://plata.ar.media.kyoto-u.ac.jp/tool/EDA\nSection Titles (if exists):  ['3 Parsing', '3.1 Parsing Overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ccsasuke/umwe\nCitation Context: We focus on the minimally supervised scenario which only uses similar character strings between any languages for supervision in order to mirror the hard, realistic scenario of not having anno-tated training dictionaries between the languages. We learn MWE with the MAT+MPSR method using the pub-licly available code, [URL_CITE] aligning several language subsets varying the hub language. We decided against compar-ing to the incremental hub (IHS) method of Heyman et al.\nFootnote or Reference text (if exists): 12 https://github.com/ccsasuke/umwe is English in only 17 instances (less than 20% of the\nSection Titles (if exists):  ['4 Lexicon Induction Experiments', '4.1 Methods and Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/transformers\nCitation Context: Transformers is an ongoing effort maintained by the team of engineers and researchers at Hugging Face with support from a vibrant community of over 400 external contributors. The library is re-leased under the Apache 2.0 license and is available on GitHub [URL_CITE] . Detailed documentation and tutorials are available on Hugging Face\u2019s website .\nFootnote or Reference text (if exists): 1 https://github.com/huggingface/ transformers\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/\nCitation Context: For the synthetic dataset training method, we con-sider two QA models: finetuning BERT (Devlin et al., 2018) and BiDAF + Self Attention (Clark and Gardner, 2017). [URL_CITE] For the posterior maximisa-tion method, we extract cloze questions from both sentences and sub-clauses, and use the NMT mod-els to estimate p(q|c,a). We evaluate using the standard Exact Match (EM) and F1 metrics.\nFootnote or Reference text (if exists): 5 We use the HuggingFace implementation of BERT, available at https://github.com/huggingface/ pytorch-pretrained-BERT, and the documentQA implementation of BiDAF+SA, available at https://github.com/allenai/document-qa\nSection Titles (if exists):  ['3 Experiments', '3.1 Unsupervised QA Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The citation refers to a code implementation (HuggingFace's implementation of BERT and BiDAF+SA) that is"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.gjopen.com/\nCitation Context: To explore the connections between language and forecasting skill, we make use of data from Good Judgment Open, [URL_CITE] an online prediction forum. Users of this website share predictions in response to a number of pre-specified questions about future events with uncertain outcomes, such as: \u201cWill North Korea fire another intercontinental ballistic missile before August 2019?\u201d Users\u2019 predictions consist of an estimated chance the event will oc-cur (for example, 5%) in addition to an optional text justification that explains why the forecast was made. A sample is presented in Figure 1.\nFootnote or Reference text (if exists): 2 https://www.gjopen.com/\nSection Titles (if exists):  ['2 Linguistic Cues of Accurate Forecasting', '2.1 Geopolitical Forecasting Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://clic.cimec.unitn.it/composes\nCitation Context: The data set contains the following 14 preposi-tions: after, against, at, before, between, by, for, from, in, on, per, under, with, without. [URL_CITE]\nFootnote or Reference text (if exists): 8 This dataset is available at http://clic.cimec.unitn.it/composes\nSection Titles (if exists):  ['5 Noun phrase generation', '5.2 Recursive decomposition']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dzonesoftware.com/products/open-source-question-answer-software/\nCitation Context: On a different line of research, several Textual-based Question Answering (QA) systems (Qanda , QANUS , QSQA [URL_CITE] etc.) are developed that retrieve answers from the Web and other tex-tual sources.\nFootnote or Reference text (if exists): 7 http://www.dzonesoftware.com/products/open-source-question-answer-software/\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The citation introduces a specific QA system (QSQA) and its source. It's not a core method,"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/adithya7/constrained-fever\nCitation Context: \u2022 We create an anonymized version of the FEVER dataset to facilitate investigation into the factual knowledge through named entities. Our datasets and code are publicly available. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/adithya7/ constrained-fever\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://corpus.korean.go.kr\nCitation Context: We construct an experimental dataset using the cor-pus that we produced in-house and the public Ko-rean dialogue corpus [URL_CITE] . We split these corpora into three, and each is for training, validation, and test.\nFootnote or Reference text (if exists): 1 https://corpus.korean.go.kr Meeting of the Special Interest Group on Discourse and Dialogue, pages 285\u2013294.\nSection Titles (if exists):  ['4 Experiments and Results', '4.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://t.co/XExWwxmjnk#travel\nCitation Context: Tweet Are #Airlines doing enough with #Ebola? [URL_CITE] http://t.co/XExWwxmjnk #travel\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Analysis']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Introduce \n\n\nLet's break down why:\n\n* **ROLE: Supplement** - The tweet is not directly used in the analysis but serves as an example or point of reference related to the topic"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.18653/v1/P17-1161\nCitation Context: Many NLP tasks, including part-of-speech tagging, named entity recognition, chunking, and error detec-tion, are often formulated as variations of se-quence labeling. Recent state-of-the-art models make use of bidirectional LSTM architectures (Ir-soy and Cardie, 2014), character-based represen-tations (Lample et al., 2016), and additional ex-ternal features (Peters et al., 2017) [URL_CITE] . Optimiza-tion of these models requires appropriate training data where individual tokens are manually labeled, which can be time-consuming and expensive to obtain for each different task, domain and target language.\nFootnote or Reference text (if exists): Matthew E. Peters, Waleed Ammar, Chandra Bhaga-vatula, and Russell Power. 2017. Semi-supervised sequence tagging with bidirectional language mod-els. In ACL 2017. https://doi.org/10.18653/v1/P17-1161.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.cs.nyu.edu/evalb/\nCitation Context: The reason we have not included these aspects in our representation and conversion yet is that we are focused here first on the evaluation for comparison with previous work, and the basis for this previous work is the usual evalb program (Sekine and Collins, 2008) [URL_CITE] , which ignores function tags and empty cate-gories. We return to this issue in the conclusion.\nFootnote or Reference text (if exists): Satoshi Sekine and Michael Collins. 2008. Evalb. http://nlp.cs.nyu.edu/evalb/.\nSection Titles (if exists):  ['2 Overview and Example', '2.1 Creation of Dependency Representation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mallet.cs.umass.edu/\nCitation Context: (2009) we use asymmetric \u03b1 and symmetric \u03b2; rather than using fixed values for these hyperparameters we es-timate them from data in the course of LDA train-ing using an EM-like method. [URL_CITE] We use standard set-tings for the number of training iterations (1000), the length of the burnin period before hyperparameter estimation begins (200 iterations) and the frequency of hyperparameter estimation (50 iterations).\nFootnote or Reference text (if exists): 2 We use the estimation methods provided by the MAL-LET toolkit, available from http://mallet.cs.umass.edu/.\nSection Titles (if exists):  ['3 Models', '3.1 Latent variable context models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt08/shared-task.html\nCitation Context: This PT was obtained processing the training data of the English-Spanish Europarl corpus used in the WMT 2008 shared task [URL_CITE] . We used a 2,000 sentence test set of the same shared evaluation for experi-menting with the querying phase.\nFootnote or Reference text (if exists): 5 http://www.statmt.org/wmt08/shared-task.html\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1145/3374217\nCitation Context: Almost all the character-level perturbations presented here were already tested in adversarial attack scenarios (Heigold et al., 2018; Zeng et al., 2020; Zhang et al., 2020 [URL_CITE] ), but were not yet implemented in a non-adversarial testing framework, except the misspelling perturbation implemented by CheckList. Among the word-level perturbations, Deletion, Repetition, Singular/plural verbs, Word order, and Verb tense were not already used to test the robustness. However, Negation was included in CheckList, and Replacement with Synonyms was used for adversarial attack (Dong et al., 2020; Ren et al., 2019).\nFootnote or Reference text (if exists): Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial Attacks on Deep-learning Models in Natural Language Processing: A Survey. ACM Trans. Intell. Syst. Technol., 11(3): Article 24. https://doi.org/10.1145/3374217. Max sequence length 64 64 Batch size 12 12 Learning rate 2e-5 1e-5 Num epochs 20 15 Classification, SA: Sentiment Analysis, QA: Question Answering, NER: Named Entity Recognition, SS: Semantic Similarity.\nSection Titles (if exists):  ['4 Perturbation methods']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.freebase.com/\nCitation Context: Given a structured knowledge base, such as Free-base [URL_CITE] , a single relation question Q (in natural language) with its answer can be first parsed into a fact formatted as he sbj ,rel,e obj i, where e sbj denotes a subject entity detected from the question, rel denotes the relationship expressed by the question, e obj denotes an object entity found from the knowledge base based on e sbj and rel. Then we can get hQ,reli pairs.\nFootnote or Reference text (if exists): 5 http://www.freebase.com/\nSection Titles (if exists):  ['4 Response Ranking', '4.5 Relation-level Feature']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - Freebase is a structured knowledge base, which falls under the category of \"Knowledge\" resources.  The citation"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.brandeis.edu/j\u0303amesp/arda/time/documentation/TimeML-use-in-qa-v1.0.pdf\nCitation Context: For the evaluation a corpus of questions containing as many simple as complex questions is required. Due to the fact that question corpora used in TREC (TREC, ) and CLEF (CLEF, ) do not contain com-plex questions, the TERQAS question corpus has been chosen (Radev and Sundheim, 2002 [URL_CITE] ; Puste-jovsky, 2002). It consists of 123 temporal questions.\nFootnote or Reference text (if exists): D. Radev and B. Sundheim. 2002. Us-ing timeml in question answering. http://www.cs.brandeis.edu/j\u0303amesp/arda/time/documentation/TimeML-use-in-qa-v1.0.pdf.\nSection Titles (if exists):  ['4 Question Decomposition Unit', '4.3.3 Example']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/zhanglu-cst/ClassKG\nCitation Context: Our code has already been released. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/zhanglu-cst/ ClassKG\nSection Titles (if exists):  ['4 Experiments', '4.3 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://alpage.inria.fr/~sagot/lefff-en.html\nCitation Context: The continuous word representations are used to train a logis-tic regression classifier 2 for each morphological feature: gender and number for noun and adjec-tives; tense for verbs (with labels: present, fu-ture, imperfect, or simple past). Word labels are taken from the Lefff French morphological lexicon (Sagot, 2010) [URL_CITE] . To ensure a fair comparison be-tween context-independent and context-dependent embedding classification, words that are ambigu-ous with respect to a given feature are excluded from the respective classifier\u2019s training and test data.\nFootnote or Reference text (if exists): 3 Lexique des Formes Fle\u0301chies du Franc\u0327ais: http://alpage.inria.fr/\u02dcsagot/lefff-en.html\nSection Titles (if exists):  ['2 Methods']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The resource is a lexicon (a dictionary of words and their morphological features), which is a type of knowledge base."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://jsoup.org/\nCitation Context: Text Collection: Using jsoup (Hedley, 2017) [URL_CITE] , we parse the HTML file and for each non-empty tag encountered we extract a tuple consisting of the text and its XPath.\nFootnote or Reference text (if exists): Jonathan Hedley. 2017. jsoup (1.11.3). https://jsoup.org/.\nSection Titles (if exists):  ['3 Approach', '3.1 Domain-Independent Approach (DI)']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ucrel.lancs.ac.uk/usas/USASSemanticTagset.pdf\nCitation Context: USAS semantic categories [URL_CITE] ): advance JJ N4 advance NN1 A9- M1 A5.1+/A2.1 advance VV0 M1 A9- Q2.2 A5.1+/A2.1 advance VVI M1 S8+ A9- A5.1+/A2.1 Q2.1\nFootnote or Reference text (if exists): 1 For definitions of the POS and semantic tags, see websites http://ucrel.lancs.ac.uk/claws7tags.html and http://ucrel.lancs.ac.uk/usas/USASSemanticTagset.pdf\nSection Titles (if exists):  ['3 Generating Multilingual Semantic Lexi-cons by Automatic Mapping']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2007T03\nCitation Context: The experiments were carried out on a Chinese corpus, which consists of one year (2004) of the Xinhua news corpus from LDC [URL_CITE] , containing about 28 millions of Chinese words. Since punc-tuations are rarely used to construct collocations, they were removed from the corpora. To auto-matically estimate the precision of extracted col-locations on the Chinese corpus, we built a gold set by collecting Chinese collocations from handcrafted collocation dictionaries, containing 56,888 collocations.\nFootnote or Reference text (if exists): 2 Available at: http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2007T03\nSection Titles (if exists):  ['3 Initial Experiments', '3.1 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dwadden/dygiepp\nCitation Context: For instance, propagat-ing span representations via predicted coref-erence links can enable the model to disam-biguate challenging entity mentions. Our code is publicly available at [URL_CITE] https://github.com/dwadden/dygiepp and can be easily adapted for new tasks or datasets.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dl.acm.org/citation.cfm?id=1557769.1557821\nCitation Context: Associa-tion for Computational Linguistics, Strouds-burg, PA, USA, ACL \u201907, pages 177\u2013 180. [URL_CITE] http://dl.acm.org/citation.cfm?id=1557769.1557821.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://naudio.codeplex.com/\nCitation Context: The recorder, built using the open-source library NAudio, [URL_CITE] takes the default audio input device as its source and records one channel with a sampling rate of 8 kHz, as the recognition engine we employ is designed for low-quality audio (see Section 4.1).\nFootnote or Reference text (if exists): 8 http://naudio.codeplex.com/\nSection Titles (if exists):  ['5 User interface', '5.1 Audio input and recording']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** -  NAudio is used as a tool within the research process to build the audio recorder.\n* **TYPE: Tool**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://svn.ask.it.usyd.edu.au/trac/candc/wiki/Download\nCitation Context: When it is reason-able to assume that the input sentence for the gram-maticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via supertagging (Clark and Curran, 2007) on the input sequence. We use the C&C supertagger [URL_CITE] to assign a set of probable lexical categories to each input word using the gold-standard order. When the input is noisy, the accuracy of a supertagger tends to be lower than when the in-put is grammatical.\nFootnote or Reference text (if exists): 1 http://svn.ask.it.usyd.edu.au/trac/candc/wiki/Download.\nSection Titles (if exists):  ['6 Experiments', '6.1 Development Tests']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wiktionary.org/Frequencylists/Telugu\nCitation Context: Initially, we create data lists for Hindi and Telugu. For this, we have extracted a corpus of most frequent Hindi words and most frequent Telugu words [URL_CITE] . We have also extracted Hindi movie names and Telugu movie names of the movies released between the years 1930 and 2018 from Wikipedia which constitute phrases in the data lists.\nFootnote or Reference text (if exists): 3 https://en.wiktionary.org/Frequencylists/Telugu\nSection Titles (if exists):  ['4 Experiments and Results', '4.1 Dataset details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/natashamjaques/neural_chat/tree/master/BatchRL\nCitation Context: After chatting, users were asked to provide a Likert scale rating of the bot\u2019s conversation quality, fluency, diversity, contingency/relatedness, and empathy. The code for the RL models is available in open-source at [URL_CITE] https://github.com/natashamjaques/neural_chat/tree/master/BatchRL. Using the server, we collected a batch of human interaction data containing 46,061 pairs of user input and agent response.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Learning from talking to humans', '4.2 Hosting real-time conversations online']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool within the research process to collect data and facilitate the conversations.\n* **TYPE: Code"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/software/segmenter.shtml\nCitation Context: For a given full form, we first segment it us-ing a standard word segmenter to get a coarse-grained segmentation result. Here we use the Stan-ford Chinese Word Segmenter [URL_CITE] . Then we use the MSU set to segment each word using the strategy of \u201cMaximum Forward Matching\u201d to get the fine-grained MSU segmentation result.\nFootnote or Reference text (if exists): 3 http://nlp.stanford.edu/software/segmenter.shtml\nSection Titles (if exists):  ['2 System Architecture', '2.2 MSU Based Tagging', '2.2.1 Minimum Semantic Unit']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.phontron.com/kytea/\nCitation Context: To suppress having possible chunking errors affect the translation quality, we removed extremely long chunks from the train-ing data. Specifically, among the [URL_CITE] million pre-processed translation pairs, we excluded sentence pairs that matched any of following conditions: (1) The length of the source sentence or target sen-tence is larger than 64 (3% of whole data); (2) The maximum length of a chunk in the target sen-tence is larger than 8 (14% of whole data); and (3) The maximum number of chunks in the target sen-tence is larger than 20 (3% of whole data). Table 1 shows the details of the extracted data.\nFootnote or Reference text (if exists): 2 http://www.phontron.com/kytea/\nSection Titles (if exists):  ['4 Experiments', '4.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://compprag.christopherpotts.net/swda.html\nCitation Context: We use the Switch-board Dialogue Act (SwDA) corpus (Calhoun et al., 2010) in our experiments [URL_CITE] . SwDA contains the transcripts of several people discussing a given topic on the telephone. There are 42 dialogue act tags in SwDA, and we list the 10 most frequent tags in Table 3.\nFootnote or Reference text (if exists): 5 http://compprag.christopherpotts.net/swda.html.\nSection Titles (if exists):  ['4 Experiments', '4.2 Dialogue Act Analysis', '4.2.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.acronymsearch.com/\nCitation Context: Here, we assume that the list of possible defi-nitions for an acronym is given from sources ex-ternal to this work. Listing pairs of acronyms and their original definitions, on which many studies have been done, such as Nadeau and Turney (2005), results in high performance. Some sites such as [URL_CITE] http://www.acronymsearch.com/ or http://www.findacronym.com/ provide us with this function.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: 2. GloVe: We use pre-trained vectors avaiable from the GloVe project [URL_CITE] . The vocabulary size in this case is 2,195,904.\nFootnote or Reference text (if exists): 6 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['5 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.jtf.org.tw\nCitation Context: Then, the CIP randomly selects one seed pattern per run without replacement from the seed set, and iteratively induces relevant patterns from the psychiatry web corpora. The psychiatry web corpora used here include some professional mental health web sites, such as PsychPark (http://www.psychpark.org) (Bai, 2001) and John Tung Foundation ( [URL_CITE] http://www.jtf.org.tw).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Experimental Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://openke.thunlp.org/\nCitation Context: Besides the toolkit, we also provide the pre-trained embeddings of several well-known large-scale KGs, which can be used directly for other relevant works without repeatedly spending much time for embedding KGs. In this paper, we mainly present the architecture design and implementa-tion of OpenKE, as well as the benchmark eval-uation results of some typical KE models im-plemented with OpenKE. Other related resources and details can be found on [URL_CITE] http://openke.thunlp.org/.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://stream.twitter.com\nCitation Context: We created a new data set consisting of two streams (document and topic stream). The document stream consists of 52 million tweets gathered through Twitter\u2019s streaming API [URL_CITE] . The tweets are order by their time-stamps.\nFootnote or Reference text (if exists): 1 http://stream.twitter.com\nSection Titles (if exists):  ['Corpora']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/lipiji/SongNet\nCitation Context: Extensive experiments conducted on two collected corpora demonstrate that our pro-posed framework generates significantly better results in terms of both automatic metrics and the human evaluation. [URL_CITE]\nFootnote or Reference text (if exists): 1 Code: http://github.com/lipiji/SongNet\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool in the research, specifically for conducting experiments.\n* **TYPE: Code** - The"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://open.weibo.com/wiki/Trends/hourly\nCitation Context: Note that we do not consider retweet rela-tions, i.e., reposting behaviors on Twitter, because retweets provide limited extra textual information for the reason that Twitter did not allow users to add comments in retweets until 2015. To build the Weibo dataset, we tracked real-time trending hashtags [URL_CITE] on Weibo and used the hashtag-search API to crawl the posts matching the given hash-tag queries. In the end, a large-scale Weibo corpus is built containing Weibo messages posted during January 2nd to July 31st, 2014.\nFootnote or Reference text (if exists): 6 http://open.weibo.com/wiki/Trends/ hourly\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.gurobi.com/\nCitation Context: We preprocessed the para-graphs with the Stanford CoreNLP pipeline ver-sion 3.4 (Manning et al., 2014) and Illinois SRL (Punyakanok et al., 2008; Clarke et al., 2012). We used the Gurobi optimization package [URL_CITE] for infer-ence.\nFootnote or Reference text (if exists): 3 http://www.gurobi.com/\nSection Titles (if exists):  ['6 Empirical Evaluation', '6.1 Experimental setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cmu.edu/~yww/data/emnlp2013.zip\nCitation Context: The coffee shop dataset is freely available [URL_CITE] for re-search purposes.\nFootnote or Reference text (if exists): 6 http://www.cs.cmu.edu/\u02dcyww/data/emnlp2013.zip\nSection Titles (if exists):  ['Coffee Shops Reviews']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://developers.google.com/freebase\nCitation Context: For the choice of the Knowledge Base, we use a subset of Freebase [URL_CITE] that includes 3 million entities with the most connections, similar to Xu and Barbosa (2019). For all pairs appearing in the test set of NYT 10 (both positive and negative), we remove all links in the subset of Freebase to ensure that we will not memorise any relations between them (Weston et al., 2013). The resulting KB contains approximately 24 million triples.\nFootnote or Reference text (if exists): 2 https://developers.google.com/freebase 3 https://www.wikidata.org/\nSection Titles (if exists):  ['3 Experimental Settings', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://help.bet365.com/en/privacy-policy\nCitation Context: Tags are also nested with varying depths. Figure 1 illus-trates this problem: similar title and prose text seg-ments from four website privacy policies [URL_CITE] have al-together different HTML tag structures. The sec-ond problem is that it is not straightforward to dis-tinguish the information (encoded in HTML) that is necessary for title-prose detection from the rest of the HTML structure, including unrelated links, multiple tags with little or no content and page headers and footers.\nFootnote or Reference text (if exists): 2 All the policies were retrieved on 2018-01-20, from the below URLs: https://rule.alibaba.com/rule/detail/2034.htm https://www.apple.com/legal/privacy/en-ww/ https://www.cbsinteractive.com/legal/cbsi/privacy-policy https://help.bet365.com/en/privacy-policy\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.5281/zenodo.4064408\nCitation Context: We hope that our public release of data will encourage others to further improve models for this task. [URL_CITE]\nFootnote or Reference text (if exists): 6 Our dataset can be downloaded from https://doi.org/10.5281/zenodo.4064408 and code is available at https://github.com/dgaddy/silent_speech. Samples of predicted outputs can be found in the supplementary material.\nSection Titles (if exists):  ['5 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://gitlab.com/sutdnlp/statnlp-core\nCitation Context: We implemented our neural component with the Torch7 library (Collobert et al., 2011). Our com-plete implementation is based on the StatNLP [URL_CITE] structured prediction framework (Lu, 2017).\nFootnote or Reference text (if exists): 12 https://gitlab.com/sutdnlp/statnlp-core\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.tensorflow.org/\nCitation Context: Multiple general machine learning frame-works, such as SCIKIT - LEARN (Pedregosa et al., 2011), P Y T ORCH , T HEANO (Theano Develop-ment Team, 2016) and T ENSOR F LOW (Abadi et al., 2015) [URL_CITE] , among others, enable quick proto-typing and deployment of ML models. However, unlike J ACK , they do not offer a simple framework for defining and evaluating MR models.\nFootnote or Reference text (if exists): Mart\u00edn Abadi et al. 2015. TensorFlow: Large-scale machine learning on heterogeneous sys-tems. Software available from tensorflow.org. https://www.tensorflow.org/.\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://azure.microsoft.com/en-us/services/cognitive-services/translator-text-api/\nCitation Context: On the other hand, the test-on-trans(lation) method trains an English sequence tagger, and utilizes MT to translate the test set of each target language into English in order to make predictions. In this work, we adopt the Mi-crosoft Translator [URL_CITE] , a strong commercial MT sys-tem. Note that for a MT system to work for se-quence tagging tasks, word alignment informa-tion must be available, in order to project word-level annotations across languages.\nFootnote or Reference text (if exists): 4 https://azure.microsoft.com/en-us/services/cognitive-services/translator-text-api/\nSection Titles (if exists):  ['4 Experiments', '4.1 Cross-Lingual Semantic Slot Filling', '4.1.1 Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The citation refers to a tool used in the research process (Microsoft Translator) to perform machine translation. \n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ilk.uvt.nl/conll/software.html\nCitation Context: Parsing Quality The parsing quality was evalu-ated using the CONLL-X (Buchholz and Marsi, 2006) standard. Dependencies were extracted from the output HPSG trees, and evaluated using the official script [URL_CITE] . Due to this conversion, the accuracy on the relation labels is less important.\nFootnote or Reference text (if exists): 6 http://ilk.uvt.nl/conll/software.html\nSection Titles (if exists):  ['6 Evaluation', '6.3 Evaluation Metric']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/software/lex-parser.shtml\nCitation Context: The syntactic backoff behavior is calculated in an analogous fashion: it verifies for the existence of n-grams of POS tags in a POS-tagged LM. The POS tags of target sentence are produced by the Stanford Parser [URL_CITE] (integrated in Q U E ST ++ ).\nFootnote or Reference text (if exists): 4 http://nlp.stanford.edu/software/lex-parser.shtml\nSection Titles (if exists):  ['3 Features', '3.1 Word level']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://projectile.sv.cmu.edu/research/public/tools/bootStrap/tutorial.htm\nCitation Context: We calculated statistical significance for the main results on the development section using bootstrap random sampling. [URL_CITE] After re-sampling 1000 times, significance was calculated using a paired t-test (999 d.f.). The results indicated that lp-only exceeded the baseline, lp-ngram and lp-syn exceeded lp-only, and the full model exceeded lp-syn, with p < 0.0001 in each case.\nFootnote or Reference text (if exists): 6 Scripts for running these tests are available at http://projectile.sv.cmu.edu/research/public/tools/bootStrap/tutorial.htm\nSection Titles (if exists):  ['4 Evaluation', '4.2 Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://opennlp.sourceforge.net\nCitation Context: A number of systems have tried to address the question of coreference in RTE as a preprocessing step prior to inference proper, with most systems using off-the-shelf coreference resolvers such as JavaRap (Qiu et al., 2004) or OpenNLP [URL_CITE] . Gen-erally, anaphoric expressions were textually re-placed by their antecedents.\nFootnote or Reference text (if exists): 3 http://opennlp.sourceforge.net\nSection Titles (if exists):  ['2 Background', '2.2 Discourse in Textual Entailment']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/cfmrp/mtool\nCitation Context: (2017). For UCCA parsing, we employ the official evaluation metric [URL_CITE] of the shared task, conceptually similar to the Smatch score.\nFootnote or Reference text (if exists): 15 https://github.com/cfmrp/mtool\nSection Titles (if exists):  ['4 Experimental Setup', '4.3 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://help.twitter.com/en/rules-and-policies/twitter-limits\nCitation Context: User tweets are simply all the tweets from that user\u2019s Twitter account, and measure perhaps in the thousands. Indeed, the number of tweets per user per day is limited to 2400 per day by current Twitter policy ( [URL_CITE] https://help.twitter.com/en/rules-and-policies/twitter-limits). The negative exam-ples consist of all tweets written by other Twitter users, a total of approximately 500 million per day (https://business.twitter.com).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['2 Problem Formulation', '2.1 Methodology']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The URL points to Twitter's official policy page regarding tweet limits. This information is sourced from Twitter and used"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.tensorflow.org/\nCitation Context: The data was split using stratified sampling, to ensure that there is a similar distribution of classes in each of the train-ing and test splits. The Feed Forward Neural Net-work was implemented using TensorFlow (Abadi et al., 2015) [URL_CITE] in Python. We ran the neural network over 10,000 epochs, with a learning rate of 0.001 in 10 batches.\nFootnote or Reference text (if exists): Mart\u0131\u0301n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Cor-rado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane\u0301, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Tal-war, Paul Tucker, Vincent Vanhoucke, Vijay Va-sudevan, Fernanda Vie\u0301gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2015. TensorFlow: Large-scale machine learning on heterogeneous sys-tems. Software available from tensorflow.org. https://www.tensorflow.org/.\nSection Titles (if exists):  ['5 Experiment Details', '5.5 Classification Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://stackoverflow.com/\nCitation Context: A typical example for CQA is shown in Table 1. In this example, Answer [URL_CITE] is a good answer, be-cause it provides helpful information, e.g., \u201ccheck it to the traffic dept\u201d. Although Answer 2 is rele-vant to the question, it does not contain any useful information so that it should be regarded as a bad answer.\nFootnote or Reference text (if exists): 1 https://stackoverflow.com/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.metaversum.com/\nCitation Context: The KomParse system, described in this paper, provides NPCs for a virtual online world named Twinity, a product of the Berlin startup company Metaversum [URL_CITE] . The KomParse NPCs offer vari-ous services through conversation with game users using question-answering and dialog functional-ity. The utilization of Semantic Web technology with RDF-encoded generic and domain-specific ontologies furthermore enables semantic search and inference.\nFootnote or Reference text (if exists): 1 http://www.metaversum.com/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ibm/loa\nCitation Context: Our LOA also provides open-sourced implementation in Python for the reinforce-ment learning environment to facilitate an ex-periment for studying neuro-symbolic agents. Demo site: https://ibm.biz/acl21-loa, Code: [URL_CITE] https://github.com/ibm/loa\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://fdalvi.github.io\nCitation Context: Fahim Dalvi, Software Engineer, Qatar Comput-ing Research Institute, Qatar Email: faimaduddin@hbku.edu.qa Website: [URL_CITE] https://fdalvi.github.io Fahim Dalvi is an experienced Software En-gineer with a demonstrated history of working in the research industry and is currently employed at the Qatar Computing Research Institute. Fahim\u2019s research is centered around the intersection of Natural Language Processing and Deep Learning, and he has worked on wide variety of problems in these fields including Machine Translation, Language Modelling and Explainability in Deep Neural Networks.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['6 Instructor Information (Alphabetic order']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.itl.nist.gov/iad/mig/tests/mt/\nCitation Context: We choose NIST MT 06 dataset (1664 sentence pairs) as our develop-ment set, and NIST MT 02, 03, 04, and 05 datasets (878, 919, 1788 and 1082 sentence pairs, respec-tively) as our test sets. [URL_CITE] To get the source syn-tax for sentences on the source-side, we parse the Chinese sentences with Berkeley Parser (Petrov and Klein, 2007) trained on Chinese TreeBank 7.0 (Xue et al., 2005). We use the case insensitive 4-gram NIST BLEU score (Papineni et al., 2002) for the translation task.\nFootnote or Reference text (if exists): 5 http://www.itl.nist.gov/iad/mig/tests/mt/\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The NIST MT datasets are the core data used for training and evaluating the translation model. They are the raw material upon which the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wiktionary.org/wiki/Wiktionary:Idioms_that_survived_RFD\nCitation Context: Second, the baseline method assumes that for any non-compositional MWE, all components must be equally non-compositional, despite the wealth of MWEs where one or more components are com-positional (e.g. from the Wiktionary guidelines for idiom inclusion, [URL_CITE] computer chess, basketball player, telephone box).\nFootnote or Reference text (if exists): 3 http://en.wiktionary.org/wiki/ Wiktionary:Idioms_that_survived_RFD\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://trainomatic.org\nCitation Context: We believe that the ability of T-O-M to over-come the current paucity of annotated data for WSD, coupled with video games with a pur-pose for validation purposes (Jurgens and Nav-igli, 2014; Vannella et al., 2014), paves the way for high-quality multilingual supervised WSD. All the training corpora, including approximately one million sentences which cover English, Italian and Spanish, are made available to the community at [URL_CITE] http://trainomatic.org.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['8 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/moses-smt/mosesdecoder/blob/master/scripts/analysis/boots\nCitation Context: For evaluation, we train all the mod-els with maximum 150k/300k/300k steps for NIST Zh-En, WMT En-De and WMT Zh-En, respec-tively, and we select the model which performs the best on the validation set and report its per-formance on the test sets. We measure the case-insensitive/case-sensitive BLEU scores using multi-bleu.perl with the statistical significance test (Koehn, 2004) [URL_CITE] for NIST Zh-En and WMT\u201914 En-De, respectively. For WMT\u201918 Zh-En, we use case sensitive BLEU scores calculated by Moses mteval-v13a.pl script .\nFootnote or Reference text (if exists): 5 https://github.com/moses-smt/mosesdecoder/blob/master/scripts/analysis/bootstrap-hypothesis-difference-significance. pl\nSection Titles (if exists):  ['4 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool:** The cited resource is a script (`bootstrap-hypothesis-difference-significance.pl`) used for statistical significance testing in the research"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.cs.lth.se/lth_srl\nCitation Context: We have described a dependency-based system [URL_CITE] for semantic role labeling of English in the PropBank framework. Our evaluations show that the perfor-mance of our system is close to the state of the art.\nFootnote or Reference text (if exists): 1 Our system is freely available for download at http://nlp.cs.lth.se/lth_srl.\nSection Titles (if exists):  ['4 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/Irina_Dunn\nCitation Context: However, this simplifi-cation (of representing sarcasm merely as positive verbs followed by negative situation) may not capture difficult forms of context incongruity. Consider the sarcastic sen-tence \u2018A woman needs a man like a fish needs bicycle\u2019 [URL_CITE] . The sarcasm in this sentence is understood from the fact that a fish does not need bicycle - and hence, the sentence ridicules the target \u2018a man\u2019.\nFootnote or Reference text (if exists): 2 This quote is attributed to Irina Dunn, an Australian writer (https://en.wikipedia.org/wiki/Irina_Dunn\nSection Titles (if exists):  ['2 Motivation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.natcorp.ox.ac.uk\nCitation Context: First, we build a co-occurrence based space (DS cooc ), in which a word is represented by co-occurrence counts with content words (nouns, verbs, adjectives and adverbs). As a source corpus, we use a concatenation of the ukWaC, a 2009 dump of the English Wikipedia and the BNC [URL_CITE] , which consists of about 2.8 billion tokens. We select the top 10K content words for the contexts, using a bag-of-words approach and counting co-occurrences within a sentence.\nFootnote or Reference text (if exists): 4 http://wacky.sslmit.unibo.it, http://www.natcorp.ox.ac.uk\nSection Titles (if exists):  ['4 Semantic spaces', '4.1 The distributional semantic space']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The cited resource is a source corpus used in the research. \n* **TYPE: DataSource** - The BNC ("
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/\nCitation Context: For training on very large datasets, Python-based tokenization is often undesirably slow. In the most recent release, Transformers switched its im-plementation to use a highly-optimized tokeniza-tion library by default. This low-level library, available at [URL_CITE] https://github.com/huggingface/ tokenizers , is written in Rust to speed up the tokenization procedure both during training and deployment.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Library Design']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/freesunshine0316/neural-graph-to-seq-mp\nCitation Context: We release our code and models at [URL_CITE] https: //github.com/freesunshine0316/ neural-graph-to-seq-mp.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://cocolab.stanford.edu/datasets/colors.html\nCitation Context: Our contribution includes a new dataset of hu-man utterances in a color reference game in Man-darin Chinese, which we release to the public [URL_CITE] with our code and trained model parameters. setting up the data collection platform, and mem-bers of the Stanford NLP group\u2014particularly Reid Pryzant, Sebastian Schuster, and Reuben Cohn-Gordon\u2014for valuable feedback on earlier drafts.\nFootnote or Reference text (if exists): 7 https://cocolab.stanford.edu/datasets/colors.html\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me break down why:\n\n* **ROLE: Material** - The resource is a dataset of human utterances in a color reference game. This aligns with the \"Material\" role as"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.senseval.org/senseval3\nCitation Context: Conversely, researchers interested in producing richer semantic outputs have concen-trated on two-stage systems, where the semantic la-belling task is performed on the output of a parser, in a pipeline architecture divided in several stages (Gildea and Jurafsky, 2002). See also the common task of (CoNLL, 2004 2005; Senseval, 2004 [URL_CITE] ).\nFootnote or Reference text (if exists): Senseval. 2004. Third international workshop on the evalua-tion of systems for the semantic analysis of text (acl 2004). http://www.senseval.org/senseval3.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://stp.lingfil.uu.se/~nivre/research/Penn2Malt.html\nCitation Context: We follow previous work and conduct experiments on the Penn Treebank (PTB), using Wall Street Jour-nal sections 2\u201321 for training, 22 for development testing and 23 for final testing. Gold-standard de-pendency trees are derived from bracketed sentences in the treebank using Penn2Malt [URL_CITE] , and base noun phrases are treated as a single word (Wan et al., 2009; Zhang, 2013). The BLEU score (Papineni et al., 2002) is used to evaluate the performance of lin-earization, which has been adopted in former liter-als (Wan et al., 2009; White and Rajkumar, 2009; Zhang and Clark, 2011b) and recent shared-tasks (Belz et al., 2011).\nFootnote or Reference text (if exists): 1 http://stp.lingfil.uu.se/\u02dcnivre/research/Penn2Malt.html\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://bit.ly/9rs6pa\nCitation Context: (rumor) \u201cRT @johnnyA99 Ann Coulter Tells Larry King Why People Think Obama Is A Muslim [URL_CITE] http://bit.ly/9rs6pa #Hussein via @NewsBusters #tcot ..\u201d\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Problem Definition']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a tweet containing a link to an article. This type of resource is primarily used to introduce or"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://scikit-learn.org/\nCitation Context: For the pairwise classifier, we use a class-weighted linear SVM. [URL_CITE] We include annotated pairs, and randomly sample negative examples from pairs without a label in the crowd-sourced training dataset. We made two versions of pair-wise classifiers by tuning weight on polarized classes and negative sampling ratio by grid search.\nFootnote or Reference text (if exists): 12 http://scikit-learn.org/\nSection Titles (if exists):  ['5 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cog.brown.edu/\u223cmj/software.htm\nCitation Context: There are 0.8M fea-tures in our final set, considerably fewer than that of Charniak and Johnson which has about 1.3M fea-tures in the updated version. [URL_CITE] However, our initial experiments show that, even with this much simpler feature set, our 50-best reranker performed equally well as theirs (both with an F-score of 91.4, see Ta-bles 3 and 4). This result confirms that our feature set design is appropriate, and the averaged percep-tron learner is a reasonable candidate for reranking.\nFootnote or Reference text (if exists): 5 http://www.cog.brown.edu/\u223cmj/software.htm. We follow this version as it corrects some bugs from their 2005 paper which leads to a 0.4% increase in performance (see Table 4).\nSection Titles (if exists):  ['packed forest for each sentence. 3', '5.1 Data Preparation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6214\nCitation Context: We apply three types of transformation from Xu et al. (2017) [URL_CITE] to interpret the TAG parses.\nFootnote or Reference text (if exists): Pauli Xu, Robert Frank, Jungo Kasai, and Owen Rambow. 2017. TAG parser evaluation us-ing textual entailments. In TAG+. Association for Computational Linguistics, Umea\u030a, Sweden, pages 132\u2013141. http://www.aclweb.org/anthology/W17-6214.\nSection Titles (if exists):  ['A.1 Transformations from PETE']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/software/parser-faq.shtml\nCitation Context: The Stanford parser score is not designed to measure grammat-icality, however, it will generally prefer a gram-matical parse to a non-grammatical one. [URL_CITE] Thus, lower parser scores indicate less grammatically-correct utterances. In future work, we aim to use specifically designed grammar-scoring functions, e.g.\nFootnote or Reference text (if exists): 7 http://nlp.stanford.edu/software/parser-faq.shtml\nSection Titles (if exists):  ['4 Metrics', '4.2 Grammar-based metrics (GBMs)']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.kelp-ml.org\nCitation Context: Learning and classification allow to apply a variety of learning algorithms on vectorial or structured data. Currently KeLP (Filice et al., 2018) [URL_CITE] is integrated in the pipeline. KeLP allows to apply a growing number of kernel-based algo-rithms and kernel functions to perform unsuper-vised, online and batch supervised kernel meth-ods.\nFootnote or Reference text (if exists): 2 http://www.kelp-ml.org\nSection Titles (if exists):  ['5 Software Package']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.kaggle.com/c/asap-aes/\nCitation Context: At the outset, our goal is to develop a framework that strengthens the validity of state-of-the-art neu-ral AES approaches with respect to adversarial in-put related to local aspects of coherence. For our experiments, we use the Automated Student As-sessment Prize (ASAP) dataset, [URL_CITE] which contains essays written by students ranging from Grade 7 to Grade 10 in response to a number of different prompts (see Section 4).\nFootnote or Reference text (if exists): 3 https://www.kaggle.com/c/asap-aes/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google/svcca\nCitation Context: Ecco is built on top of open source libraries including Scikit-Learn (Pedregosa et al., 2011), Matplotlib (Hunter, 2007), NumPy (Walt et al., 2011), PyTorch (Paszke et al., 2019) and Trans-formers (Wolf et al., 2020). Canonical Correla-tion Analysis is calculated using the code open-sourced [URL_CITE] by the authors (Raghu et al., 2017; Mor-cos et al., 2018; Kornblith et al., 2019).\nFootnote or Reference text (if exists): 4 https://github.com/google/svcca\nSection Titles (if exists):  ['6 System Design']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wordnet.princeton.edu/glosstag.shtml\nCitation Context: Let L p be the set containing p and all the Wikipedia pages hav-ing an outgoing link to p, and R s be the set con-sisting of s and all other synsets that are in its di-rect neighbourhood. We further enrich R s by in-cluding the coordinate synsets of s and the related synsets from its disambiguated gloss [URL_CITE] . Let B be a function mapping each WordNet synset s 0 to its cor-responding Wikipedia page p, if such mapping ex-ists in BabelNet, and to the empty set otherwise.\nFootnote or Reference text (if exists): 2 http://wordnet.princeton.edu/glosstag.shtml\nSection Titles (if exists):  ['2 Semantic Representation of Concepts', '2.1 Collecting contextual information']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://demo.patrickpantel.com/\nCitation Context: Consider the set of seed terms S and an errone-ous expanded instance e. In the SIM method of Section 3.1 all set elements that have a feature vec-tor (i.e., context vector) similar to e are removed. The Feature Modification Method (FMM) instead tries to identify the subset of features of the error e which represent the unintended sense of the seed terms S. For example, let S = {Minerva, Neptune, Baccus, Juno, Apollo}. Looking at the contexts of these words in a large corpus, we construct a cen-troid context vector for S by taking a weighted av-erage of the contexts of the seeds in S. In Wikipedia articles we see contexts (i.e., features) such as [URL_CITE] :\nFootnote or Reference text (if exists): 4 The full feature vector for these and all other terms in Wiki-pedia can be found at http://demo.patrickpantel.com/..\nSection Titles (if exists):  ['3 Dynamic Similarity Modeling', '3.2 Feature Modification Method (FMM)']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The resource provides data (context vectors for Wikipedia terms) that is used in the research.\n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/hanxiao/bert-as-service\nCitation Context: For experiments with the con-textualized representation, we adopt the pre-trained language model BERT (Devlin et al., 2019) for the four datasets. Specifically, we use bert-as-service (Xiao, 2018) [URL_CITE] to generate the contextualized word representation without fine-tuning. Following Luo et al.\nFootnote or Reference text (if exists): Han Xiao. 2018. bert-as-service. https://github.com/hanxiao/bert-as-service.\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl\nCitation Context: For evaluation, we train all the mod-els with maximum 150k/300k/300k steps for NIST Zh-En, WMT En-De and WMT Zh-En, respec-tively, and we select the model which performs the best on the validation set and report its per-formance on the test sets. We measure the case-insensitive/case-sensitive BLEU scores using multi-bleu.perl [URL_CITE] with the statistical significance test (Koehn, 2004) for NIST Zh-En and WMT\u201914 En-De, respectively. For WMT\u201918 Zh-En, we use case sensitive BLEU scores calculated by Moses mteval-v13a.pl script .\nFootnote or Reference text (if exists): 4 https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl\nSection Titles (if exists):  ['4 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/atschneid/DebugSL\nCitation Context: In this paper we have presented the system DebugSL and described its usage. The project source code is available at [URL_CITE] https://github.com/atschneid/DebugSL and a screencast can be viewed at https://cis.temple.edu/\u02dcedragut/DebugSL.webm. The sys-tem will be deployed online for use by the public.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Method \nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is presented as a tool used in the research (the DebugSL system).\n* **TYPE: Code"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.codeplex.com/NodeXL\nCitation Context: We can think of these connections as relationships of contrast in meaning and seman-tic orientation, not just between the two words but also between the two categories. To better aid our understanding of the automatically deter-mined category relationships we visualized this network using the Fruchterman-Reingold force-directed graph layout algorithm (Fruchterman and Reingold, 1991) and the NodeXL network analy-sis tool (Smith et al., 2009) [URL_CITE] .\nFootnote or Reference text (if exists): 5 Available from http://www.codeplex.com/NodeXL\nSection Titles (if exists):  ['6 Visualizing the semantic orientation of thesaurus categories']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cs.umd.edu/miyyer/qblearn/\nCitation Context: LSTMs have re-cently achieved state-of-the-art results in a vari-ety of tasks due to their ability to model long-term context information as opposed to other neu-ral networks based techniques. (5) The fifth base-line (called QANTA) [URL_CITE] is taken from Iyyer et al. (2014).\nFootnote or Reference text (if exists): 6 http://cs.umd.edu/miyyer/qblearn/\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.imdb.com/\nCitation Context: Thus, our models include movie genre as an additional feature. Genres for each movie were obtained from IMDb [URL_CITE] and transformed into a multi-hot encoding.\nFootnote or Reference text (if exists): 3 https://www.imdb.com/\nSection Titles (if exists):  ['3 Method', '3.3 Role of Movie Genre']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hierplane.allenai.org/explain/stanford/\nCitation Context: For instance: [URL_CITE] http://hierplane.allenai.org/explain/stanford/ He%20ate%20pasta%20with% 20chopsticks\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 APIs', '4.1 Basic Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/D14-1162\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe (Pen-nington et al., 2014) [URL_CITE] , and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): Jeffrey Pennington, Richard Socher, and Christo-pher D. Manning. 2014. GloVe: Global Vectors for Word Representation. In Empirical Methods in Nat-ural Language Processing (EMNLP). pages 1532\u2013 1543. http://www.aclweb.org/anthology/D14-1162.\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/lancopku/SGM\nCitation Context: We include it as a baseline by using its publicly released code. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/lancopku/SGM\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.imsdb.com\nCitation Context: Data Collection For the dyadic Speaker-Addressee Model we used scripts from the American television comedies Friends and The Big Bang Theory, available from Internet Movie Script Database (IMSDb). [URL_CITE] We collected 13 main characters from the two series in a corpus of 69,565 turns. We split the corpus into train-ing/development/testing sets, with development and testing sets each of about 2,000 turns.\nFootnote or Reference text (if exists): 4 http://www.imsdb.com\nSection Titles (if exists):  ['5 Datasets', '5.3 Television Series Transcripts']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6213\nCitation Context: We hypothesize that our multi-task learning yields feature representations in the LSTM layers that are more linguistically relevant and that gener-alize better (Caruana, 1997). We provide support for this hypothesis by analyzing syntactic analo-gies across induced vector representations of su-pertags (Kasai et al., 2017; Friedman et al., 2017 [URL_CITE] ). The end-to-end TAG parser substantially outper-forms the previously reported best results.\nFootnote or Reference text (if exists): Dan Friedman, Jungo Kasai, R. Thomas McCoy, Robert Frank, Forrest Davis, and Owen Rambow. 2017. Linguistically rich vector representations of supertags for TAG parsing. In TAG+. Associa-tion for Computational Linguistics, Umea\u030a, Sweden, pages 122\u2013131. http://www.aclweb.org/anthology/W17-6213.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/\nCitation Context: For all experiments, we use the Word2Vec imple-mentation in Gensim [URL_CITE] to learn the skip-gram model with dimensionality 500 for each language. The CCA code for projecting mono-lingual embeddings is from Faruqui and Dyer (2014) in which the ratio parameter is set to 0.5 (i.e., the resulting multilingual embeddings have dimensionality 250).\nFootnote or Reference text (if exists): 2 https://radimrehurek.com/gensim/\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool** - Gensim is a software library specifically designed for topic modeling and word embedding analysis. It's a tool used in the research"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ziyi-yang/GEM\nCitation Context: Finally, we summarize our work in Section 5. Our implemen-tation is available online [URL_CITE] .\nFootnote or Reference text (if exists): 1 https://github.com/ziyi-yang/GEM\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.qatarliving.com/forum\nCitation Context: We use the CQA-QL corpus from Subtask A of SemEval-2015 Task 3 on Answer Selection in CQA. The corpus contains data from the Qatar Living forum, [URL_CITE] and is publicly available on the task\u2019s website. The dataset consists of ques-tions and a list of answers for each question, i.e., question-answer threads.\nFootnote or Reference text (if exists): 1 http://www.qatarliving.com/forum\nSection Titles (if exists):  ['2 The Task']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://youtu.be/-hGd2399dnA\nCitation Context: Nor do they enable iteration; a user cannot revise earlier sen-tences and have the system update later genera-tions. We develop a system [URL_CITE] that allows a user to interact in all of these ways that were limita-tions in previous systems; it enables involvement in planning, editing, iterative revising, and control of novelty. We conduct experiments to understand which types of interaction are most effective for improving stories and for making users satisfied and engaged.\nFootnote or Reference text (if exists): 1 The live demo is at http://cwc-story.isi.edu, with a video at https://youtu.be/-hGd2399dnA. Code and models are available at https://github.com/seraphinatarrant/plan-write-revise.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The video is supplementary material demonstrating the system described in the paper. It's not the core method or data used"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cornell.edu/~jhessel/cats/cats.html\nCitation Context: Many non-content factors can influence commu-nity reception of posts, e.g., Hessel et al. (2017) [URL_CITE] find that when a post is made on Reddit can signif-icantly influence its eventual popularity.\nFootnote or Reference text (if exists): Jack Hessel, Lillian Lee, and David Mimno. 2017. Cats and captions vs. creators and the clock: Comparing multimodal content to context in pre-dicting relative popularity. In WWW. Project homepage at http://www.cs.cornell.edu/\u02dcjhessel/cats/cats.html.\nSection Titles (if exists):  ['4 Early Prediction of Controversy', '4.2 Post-time Metadata']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/craigastewart/qe\nCitation Context: In experiments over five settings in three language pairs, we extend a QE pipeline to estimate in-terpreter performance (as approximated by the METEOR evaluation metric) and pro-pose novel features reflecting interpreta-tion strategy and evaluation measures that further improve prediction accuracy. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/craigastewart/qe sim interp Proceedings of the 56th Annual Meeting of the Association for\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ShyamSubramanian/HESM\nCitation Context: Our ex-perimental results show that HESM outper-forms 7 state-of-the-art methods for fact ex-traction and claim verification. Our source code is available at [URL_CITE] https://github.com/ShyamSubramanian/HESM.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Produce\nTYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/asahi417/kex\nCitation Context: In this section, we explain our keyword extrac-tion experimental setting. All our experiments are run on a 16-core Ubuntu computer equipped with 3.8GHz i7 core and 64GiB memory. [URL_CITE]\nFootnote or Reference text (if exists): 5 All the details to reproduce our experiments are available at https://github.com/asahi417/kex\nSection Titles (if exists):  ['3 Experimental Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.aclweb.org/anthology/D17-1180\nCitation Context: Recent work has explored neural network mod-els for supertagging in TAG (Kasai et al., 2017) [URL_CITE] and CCG (Xu et al., 2015; Lewis et al., 2016; Vaswani et al., 2016; Xu, 2016), and has shown that such models substantially improve perfor-mance beyond non-neural models. We extend pre-viously proposed BiLSTM-based models (Lewis et al., 2016; Kasai et al., 2017) in three ways: 1) we add character-level Convolutional Neural Net-works (CNNs) to the input layer, 2) we perform concatenation of both directions of the LSTM not only after the final layer but also after each layer, and 3) we use a modified BiLSTM with highway connections.\nFootnote or Reference text (if exists): Jungo Kasai, Robert Frank, Tom McCoy, Owen Rambow, and Alexis Nasr. 2017. TAG pars-ing with neural networks and vector representa-tions of supertags. In EMNLP. Association for Computational Linguistics, Copenhagen, Denmark, pages 1713\u20131723. https://www.aclweb.org/anthology/D17-1180.\nSection Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.python.org/\nCitation Context: \u2022 Minimal requirements on the underlying server structure: Sisyphus only requires Python 3 [URL_CITE] with a few basic packages and a Unix-type operating system.\nFootnote or Reference text (if exists): 1 https://www.python.org/\nSection Titles (if exists):  ['1 Introduction', '1.2 Design Goals']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Material\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.daviddlewis.com/resources/\nCitation Context: We used the \u201cModApte\u201d split of the Reuters-21578 dataset collected from the Reuters newswire in 1987 (Lewis et al., 1987) [URL_CITE] . The corpus has 9,603 training (not to be confused with D) and 3,299 test documents (which represents D u ).\nFootnote or Reference text (if exists): Lewis, D. et al. (1987). Reuters-21578. http: //www.daviddlewis.com/resources/\nSection Titles (if exists):  ['5 Results', '5.1 Reuters-21578']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/asiddhant/Active-NLP\nCitation Context: In this paper, we present a large-scale study [URL_CITE] , comparing various acquisition functions across multiple tasks: Sentiment Classification (SC), Named Entity Recognition (NER), and Semantic Role Labeling (SRL). For each task we consider, with multiple datasets, multiple models, and mul-tiple acquisition functions.\nFootnote or Reference text (if exists): 1 Code for all of our models and for running active learn-ing experiments can be found at https://github.com/asiddhant/Active-NLP\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/zhanghainan/TailoredSeq2Seq2DifferentConversationScenarios\nCitation Context: We randomly split the data to training, validation, and testing sets, which contains 3,000,000, 388,571 and 400,000 pairs, respectively. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/zhanghainan/TailoredSeq2Seq2 DifferentConversationScenarios\nSection Titles (if exists):  ['5 Experiments', '5.1 Experimental Settings', '5.1.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource provides the dataset used in the research. Datasets are a core material used in many research projects.\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://docs.python.org/3/library/difflib.html\nCitation Context: To restrain the vocab-ulary size and correct the typos, we use a default vocabulary of fixed size 42K words from spaCy. Each word in the dataset is then compared with the vocabulary using the difflib library [URL_CITE] in Python (algorithm based on the Levenshtein distance), and mapped to the most similar word in the vocabu-lary. If no word with more than 90% of similarity is found, the word is considered a rare word or a typo, and is mapped to the out-of-vocabulary (OOV) word.\nFootnote or Reference text (if exists): 2 https://docs.python.org/3/library/difflib.html\nSection Titles (if exists):  ['4 Model Training', '4.1 Corpora']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.csie.ntu.edu.tw/~cjlin/libsvm\nCitation Context: In our experiments, we used the LIBLINEAR (Fan et al., 2008) package for the linear kernel and the LIBSVM (Chang and Lin, 2001) [URL_CITE] package for the RBF and sigmoid kernels. We discarded any peri-ods and parentheses, but kept apostrophes and hy-phens, and we converted all letters to lower case.\nFootnote or Reference text (if exists): C.-C. Chang and C.-J. Lin, 2001. LIBSVM: a li-brary for support vector machines. Software available at http://www.csie.ntu.edu.tw/\u02dccjlin/libsvm.\nSection Titles (if exists):  ['3 Language identification with SVMs']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.yelp.com/dataset/download\nCitation Context: Author profiling (Age dataset ) is to predict the age range of the user by giving their tweets. Sentiment analysis (Yelp dataset [URL_CITE] ) is to predict the number of stars the user assigned to by analysis their reviews. Tex-tual entailment (SNLI dataset 3 ) is to tell whether the semantics in the two sentences are entailment or contradiction or neutral.\nFootnote or Reference text (if exists): 2 https://www.yelp.com/dataset/download\nSection Titles (if exists):  ['B Additional Experimental Details', 'B.1 Self-attentive Sentence Classification']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://lucene.apache.org/core/\nCitation Context: Our system encourages refining retrieved results and viewing relations in different contexts by sup-porting multiple queries. All queries and their cor-responding results are visualized together to aid a better understanding of their relationships. To il-lustrate the differences to phrase vector-based sen-tence retrieval, we also offer a retrieval option based on direct word-to-text matching using the EDICT Japanese-English dictionary (Breen, 2004) and Apache Lucene [URL_CITE] for sentence retrieval.\nFootnote or Reference text (if exists): 1 https://lucene.apache.org/core/\nSection Titles (if exists):  ['3 Crosslingual Vector-Based Writing Assistance (CroVeWA)']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cfilt.iitb.ac.in/cognitive-nlp/\nCitation Context: Secondly, we show that if a reader has understood the text com-pletely, their gaze behaviour is more reliable. Thirdly, we also release our dataset [URL_CITE] to help in further research in using gaze features in other tasks involving predicting the quality of texts.\nFootnote or Reference text (if exists): 3 The dataset can be downloaded from http://www.cfilt.iitb.ac.in/cognitive-nlp/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/xiaochang13/AMR-generation\nCitation Context: Since incorporating unaligned words will introduce noise, we rank the translation candi-dates for each AMR fragment by their counts in the training data, and select the top N candidates. [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code for grammar induction can be downloaded from https://github.com/xiaochang13/AMR-generation\nSection Titles (if exists):  ['2 Method', '2.3 Rule Acquisition']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool within the research method described in the paper.\n* **TYPE: Code** - The"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ssl-acl08.wikidot.com/\nCitation Context: There are also issues related to degenerate solutions (all un-labeled samples classified as belonging to a single class) (Blum and Chawla, 2001; Joachims, 2003; Zhu and Ghahramani, 2002). For more background on graph-based and general SSL and their applica-tions, see (Zhu, 2005a; Chapelle et al., 2007; Blitzer and Zhu, 2008 [URL_CITE] ).\nFootnote or Reference text (if exists): Blitzer, J. and Zhu, J. (2008). ACL 2008 tutorial on Semi-Supervised learning. http://ssl-acl08.wikidot.com/.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface\nCitation Context: We build SentiBERT on the HuggingFace li-brary [URL_CITE] and initialize the model parameters using pre-trained BERT-base and RoBERTa-base models whose maximum length is 128, layer number is 12, and embedding dimension is 768. For the train-ing on SST-phrase, the learning rate is 2 \u00d7 10 \u22125 , batch size is 32 and the number of training epochs is 3.\nFootnote or Reference text (if exists): 1 https://github.com/huggingface\nSection Titles (if exists):  ['4 Experiments', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dmoz.org/\nCitation Context: We set up a spider to download roughly 70 million web pages from the Internet. Initially, we use the links from Open Directory project [URL_CITE] as seed links for our spider. Each webpage is stripped of HTML tags, tokenized, and sentence segmented.\nFootnote or Reference text (if exists): 3 http://www.dmoz.org/\nSection Titles (if exists):  ['4 Building Noun Similarity Lists', '4.1 Web Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/rtmaww/SENT\nCitation Context: We further design an iterative training algorithm to take full advantage of these data-refining processes, which significantly boost performance. Our codes are publicly available at Github [URL_CITE] .\nFootnote or Reference text (if exists): 1 https://github.com/rtmaww/SENT\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2003T05\nCitation Context: We also experiment with the English Gigaword corpus, [URL_CITE] which contains data from several English newswire sources. Jansen et al. (2014) used this cor-pus to train word embeddings, which were then in-cluded as features in their answer reranker.\nFootnote or Reference text (if exists): 6 https://catalog.ldc.upenn.edu/ LDC2003T05\nSection Titles (if exists):  ['3 Experiments', '3.1 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/utils.html\nCitation Context: 20% of randomly selected training instances are used to form development set. We preprocess our English datasets, i.e., Snippets, TagMyNews, and Twit-ter, with gensim tokenizer [URL_CITE] for tokenization. As to the Chinese Weibo dataset, we use FudanNLP toolkit (Qiu et al., 2013) for word segmentation.\nFootnote or Reference text (if exists): 8 https://radimrehurek.com/gensim/utils.html\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.phontron.com/kftt\nCitation Context: We trained Nile and tested both methods on the Japanese-English alignments provided with the Kyoto Free Translation Task (Neubig, 2011) [URL_CITE] (430k parallel sentences, 1074 manually aligned training sentences, and 120 manually aligned test sentences). As creating manual alignment data is costly, we also created two training sets that con-sisted of 1/4 and 1/16 of the total data to test if we can achieve an effect with smaller amounts of manually annotated data. The details of data size and alignment accuracy are shown in Table 3.\nFootnote or Reference text (if exists): Graham Neubig. 2011. The Kyoto free translation task. http://www.phontron.com/kftt.\nSection Titles (if exists):  ['4 Alignment', '4.1 Alignment Overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/abisee/cnn-dailymail\nCitation Context: We used the CNN/Daily Mail dataset 1 (Her-mann et al., 2015), a summary corpus of En-glish news articles, consisting of 287,226 train-ing pairs, 13,368 validation pairs, and 11,490 test pairs. On average, the source documents and sum-mary sentences have 781 and 56 tokens, respec-tively. For data preprocessing, we followed the in-struction provided in the CNN/Daily Mail dataset [URL_CITE] and fairseq .\nFootnote or Reference text (if exists): 1 CNN/Daily Mail dataset: https://github.com/abisee/cnn-dailymail\nSection Titles (if exists):  ['4 Experiments', '4.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlpado.de/~sebastian/data.shtml\nCitation Context: Our projection on the English side results in 53K V and 35K T sentences, of which 731 are labeled as both T and V. Finally, from the English labeled sentences we ex-tracted a training set with 72 novels (63K sentences) and a test set with 21 novels (15K sentences). [URL_CITE]\nFootnote or Reference text (if exists): 4 The corpus can be downloaded for research purposes from http://www.nlpado.de/~sebastian/data.shtml.\nSection Titles (if exists):  ['2 A Parallel Corpus of Literary Texts', '2.3 T/V Gold Labels for English Utterances']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ahrq.gov/professionals/prevention-chronic-care/improve/system/pfhandbook/mod8appbmonicalatte.html\nCitation Context: Consider the publicly available EHR note [URL_CITE] in Figure 1. The note is divided into the 10 sections found in that EHR (Problems, Medications, His-tory, etc.).\nFootnote or Reference text (if exists): 1 http://www.ahrq.gov/professionals/prevention-chronic-care/improve/system/pfhandbook/mod8appbmonicalatte.html\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt16/translation-task.html\nCitation Context: For the syntax-based NMT, we take syntac-tic trees of source texts as inputs. We evaluate our model on both English-German (En-De) and English-Czech (En-Cs) News Commentary v11 datasets from the WMT16 translation task [URL_CITE] . Both sides are tokenized and split into subwords using BPE with 8000 merge operations.\nFootnote or Reference text (if exists): 1 http://www.statmt.org/wmt16/translation-task.html\nSection Titles (if exists):  ['3 Experiments', '3.1 Data and preprocessing']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://scikit-learn.org/stable/\nCitation Context: \u2022 Logistic regression classifier: [URL_CITE] http://scikit-learn.org/stable/\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Supplement\nTYPE:  Website\nFUNCTION:  Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to the official website of scikit-learn, a popular machine learning library.  "
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/data/glove.6B.zip\nCitation Context: To obtain pattern-based word-pair embeddings, we extracted triples (w 1 ,w 2 ,p) \u2208 T from the Wikipedia corpus, where (w 1 , w 2 ) is a word pair composed of nouns, verbs, or adjectives in the the 100K most frequent words of the GloVe [URL_CITE] (Pen-nington et al., 2014), and p is the co-occurring shortest dependency path . We discarded the triples if p occurred less than five times and sub-sampled the triples based on word-pair probability with a threshold of 5 \u00b7 10 \u22127 , following Joshi et al. (2019).\nFootnote or Reference text (if exists): 1 http://nlp.stanford.edu/data/glove.6B.zip\nSection Titles (if exists):  ['4 Experiments and Results', '4.1 Obtaining Word-Pair Embedding']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://groups.csail.mit.edu/sls/downloads/\nCitation Context: Table 1 shows the distribution over the stance labels, [URL_CITE] which turns out to be very similar to that for the FNC dataset. We can see that there are very few documents disagreeing with true claims (about 0.5%), which suggests that stance is pos-itively correlated with factuality. However, the number of documents agreeing with false docu-ments is larger than the number of documents dis-agreeing with them, which illustrates one of the main challenges when trying to predict the factu-ality of news based on stance.\nFootnote or Reference text (if exists): 7 The corpus is available at http://groups.csail.mit.edu/sls/downloads/ and also at http://alt.qcri.org/resources/\nSection Titles (if exists):  ['3 The Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.statmt.org/wmt14/translation-task.html\nCitation Context: 4 We use WMT14 EN-DE translation dataset as the EN-DE sentence-level parallel dataset which consists of 4.4M sentence pairs. [URL_CITE]\nFootnote or Reference text (if exists): 5 https://www.statmt.org/wmt14/translation-task.html\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1007/978-3-540-30586-638\nCitation Context: The use of such metrics is, however, only sensible if they are known to be sufficiently correlated with human preferences. This is rarely the case, as shown by various studies in NLG (Stent et al., 2005 [URL_CITE] ; Belz and Reiter, 2006; Reiter and Belz, 2009), as well as in related fields, such as dialogue systems (Liu et al., 2016), machine translation (MT) (Callison-Burch et al., 2006), and image captioning (Elliott and Keller, 2014; Kilick-aya et al., 2017). This paper follows on from the above previous work and presents another evalu-ation study into automatic metrics with the aim to firmly establish the need for new metrics.\nFootnote or Reference text (if exists): Amanda Stent, Matthew Marge, and Mohit Singhai. 2005. Evaluating evaluation methods for gener-ation in the presence of variation. In Computa-tional Linguistics and Intelligent Text Processing: 6th International Conference, CICLing 2005, Mex-ico City, Mexico, February 13-19, 2005. Proceed-ings. Springer, Berlin/Heidelberg, pages 341\u2013351. https://doi.org/10.1007/978-3-540-30586-638.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/iceboal/word-representations-bptf\nCitation Context: These pairs were provided by Zhang et al. (2014) [URL_CITE] . There were 52,760 entries (words), each of which had 11.7 synonyms on average, and 21,319 entries, each of which had 6.5 antonyms on average.\nFootnote or Reference text (if exists): 1 https://github.com/iceboal/ word-representations-bptf\nSection Titles (if exists):  ['3 Experiments', '3.1 Evaluation settings', '3.1.2 Resource for training']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://fakenewschallenge.org/\nCitation Context: The Fake News challenge (Pomerleau and Rao, 2017) [URL_CITE] modelled verification as stance classifica-tion: given a claim and an article, predict whether the article supports, refutes, observes (neutrally states the claim) or is irrelevant to the claim. It consists of 50K labelled claim-article pairs, com-bining 300 claims with 2,582 articles.\nFootnote or Reference text (if exists): Dean Pomerleau and Delip Rao. 2017. Fake news chal-lenge. http://fakenewschallenge.org/.\nSection Titles (if exists):  ['2 Related Works']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The Fake News Challenge provides labeled data (claim-article pairs) which is a core component used in research. "
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.chinasmack.com/glossary\nCitation Context: Slang Terms. We collect the Chinese slang terms from an online Chinese slang glossary [URL_CITE] consisting of 200 popular slang terms with English expla-nations. For English, we resort to a slang word Truth Sets.\nFootnote or Reference text (if exists): 8 https://www.chinasmack.com/glossary\nSection Titles (if exists):  ['5 Task 2: Finding most similar words for slang across languages', '5.1 Ground Truth']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lingpy.org\nCitation Context: The code was implemented in Python, as part of the LingPy library (Version 2.5, List and Forkel (2016) [URL_CITE] , http://lingpy.org). The Igraph soft-ware package (Cs\u00e1rdi and Nepusz 2006) is needed to apply the Infomap algorithm.\nFootnote or Reference text (if exists): Johann-Mattis List and Robert Forkel. 2016. LingPy. A Python library for historical linguis-tics. Max Planck Institute for the Science of Hu-man History, Jena. Version 2.5. URL: http: //lingpy.org. With contributions by Steven Moran, Peter Bouda, Johannes Dellert, Taraka Rama, Frank Nagel, and Simon Greenhill.\nSection Titles (if exists):  ['3 Methods', '3.5 Implementation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://yjernite.github.io/lfqa.html\nCitation Context: In this section, we describe our proposed LFQA system, which conditions answer generation on Wikipedia articles identified by a pretrained re-triever. We use a dense retriever trained by scaling up a distantly supervised algorithm from Jernite (2020) [URL_CITE] . Since retrieved articles can be quite long and often exceed the maximum sequence length of pretrained models like BERT (Devlin et al., 2019), we use a sparse-attention variant of the Transformer to allow modeling over longer sequences.\nFootnote or Reference text (if exists): Yacine Jernite. 2020. Explain anything like i\u2019m five: A model for open domain long form question answer-ing. https://yjernite.github.io/lfqa.html.\nSection Titles (if exists):  ['2 A state-of-the-art LFQA system']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact:\n\n* **ROLE:** Method \n* **TYPE:**  Tool \n* **FUNCTION:** Use \n\n\n**Explanation:**\n\n* **ROLE: Method** - The cited resource (Jernite"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://syntagnet.org/\nCitation Context: SyntagRank leverages the disambiguated pairs of co-occurring words included in SyntagNet, a lexical-semantic combination resource, to perform state-of-the-art knowledge-based WSD in a multilingual setting. Our service provides both a user-friendly interface, available at [URL_CITE] http://syntagnet.org/ , and a RESTful endpoint to query the system programmatically (accessible at http://api.syntagnet.org/).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://sourceforge.net/projects/jazzydicts\nCitation Context: For spell-checking, we use British and US-American English Jazzy dic-tionaries. [URL_CITE] Markup elements are detected by the Sweble Wikitext parser (Dohrn and Riehle, 2011).\nFootnote or Reference text (if exists): 3 http://sourceforge.net/projects/ jazzydicts\nSection Titles (if exists):  ['3 Experiments', '3.2 Features for Edit Category Classification']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://tac.nist.gov/2009/Summarization/\nCitation Context: Datasets We use two multi-document summa-rization datasets from the Text Analysis Confer-ence (TAC) shared task: TAC-2008 and TAC-2009. [URL_CITE] TAC-2008 and TAC-2009 contain 48 and 44 topics, respectively. Each topic consists of 10 news articles to be summarized in a maximum of 100 words.\nFootnote or Reference text (if exists): 1 http://tac.nist.gov/2009/Summarization/, http://tac.nist.gov/2008/Summarization/\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://api.syntagnet.org\nCitation Context: In this paper we presented and described the architecture of SyntagRank, our state-of-the-art knowledge-based system for multilingual Word Sense Disambiguation using syntagmatic informa-tion. We also provided details concerning the use of SyntagRank\u2019s Web interface and RESTful API, accessible at http://syntagnet.org/ and [URL_CITE] http://api.syntagnet.org , respectively.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['6 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.ualberta.ca/~ab31/langid/\nCitation Context: We manually classified these names as being of ei-ther Indian or non-Indian origin, occasionally resort-ing to web searches to help disambiguate them. [URL_CITE] We discarded those names that fell into both categories (e.g. \u201cMaya\u201d) as well as those that we could not confidently classify.\nFootnote or Reference text (if exists): 1 Our tagged data are available online at http://www.cs.ualberta.ca/\u02dcab31/langid/.\nSection Titles (if exists):  ['5 Application to machine transliteration', '5.1 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://archive.ics.uci.edu/ml\nCitation Context: Since the constraint type is determined by syntactic and dependency parse features, this component does not need to be retrained for new domains. In this work, we trained this classifier based on a manually annotated set of 80 sentences describing classes in the small UCI Zoo dataset (Lichman, 2013) [URL_CITE] , and used this model for all experiments.\nFootnote or Reference text (if exists): M. Lichman. 2013. UCI machine learning repository. http://archive.ics.uci.edu/ml.\nSection Titles (if exists):  ['3 Learning Classifiers from Language', '3.1 Mapping language to constraints', '3.1.1 Semantic Parser components']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The UCI Machine Learning Repository provides datasets for machine learning research. Datasets are a type of material resource used in research.\n*"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aclweb.org/anthology/N/N16/N16-1148.pdf\nCitation Context: We modify the experiments of Cheng et al. (2016) [URL_CITE] slightly, and assume that the user only pro-vides sequences of up to three words which are missing from the hypothesis. To simulate user interaction, at each iteration we chose a phrase of up to three tokens from the reference transla-tion which does not appear in the current MT hy-potheses.\nFootnote or Reference text (if exists): Shanbo Cheng, Shujian Huang, Huadong Chen, Xinyu Dai, and Jiajun Chen. 2016. PRIMT: A pick-revise framework for interactive machine trans-lation. In NAACL HLT 2016, The 2016 Con-ference of the North American Chapter of the Association for Computational Linguistics: Hu-man Language Technologies, San Diego Califor-nia, USA, June 12-17, 2016. pages 1240\u20131249. http://aclweb.org/anthology/N/N16/N16-1148.pdf.\nSection Titles (if exists):  ['4 Experiments', '4.1 Pick-Revise for Interactive Post Editing']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.stackoverflow.com\nCitation Context: Discussion forums have become a popular knowl-edge source for finding solutions to common prob-lems. StackOverflow [URL_CITE] , a popular discussion forum for programmers is among the top-100 most vis-ited sites globally . Now, there are discussion fo-rums for almost every major product ranging from automobiles 3 to gadgets such as those of Mac 4 or Samsung 5 .\nFootnote or Reference text (if exists): 1 http://www.stackoverflow.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.microsoft.com/en-us/download/details.aspx?id=52419\nCitation Context: WikiQA [URL_CITE] is a retrieval-based question answer-ing dataset based on Wikipedia. We follow the data split of original paper.\nFootnote or Reference text (if exists): 6 https://www.microsoft.com/en-us/download/details.aspx?id=52419\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets and Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The resource is a dataset used in the research.\n* **TYPE: Dataset** - The URL points to a download page"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/moses-smt/mgiza/\nCitation Context: G IZA ++ estimates IBM1-5 models and a first-order hidden Markov model (HMM) as introduced in (Brown et al., 1993) and (Vo-gel et al., 1996), respectively. In particular, we perform [URL_CITE] iterations of IBM1, HMM, IBM3 and IBM4. Furthermore, the alignment models are trained in both translation directions and sym-metrized by employing the grow-diagonal heuristic (Koehn et al., 2005).\nFootnote or Reference text (if exists): 5 https://github.com/moses-smt/mgiza/\nSection Titles (if exists):  ['5 Experiments', '5.2 Statistical Baseline']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: Transformers is designed to mirror the standard NLP machine learning model pipeline: process data, apply a model, and make predictions. Al-though the library includes tools facilitating train-ing and development, in this technical report we focus on the core modeling specifications. For complete details about the features of the library refer to the documentation available on [URL_CITE] https: //huggingface.co/transformers/ .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Library Design']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://kheafield.com/code/kenlm/\nCitation Context: This pruning is done efficiently through a varia-tion of cube-pruning (Chiang, 2007). We use KenLM [URL_CITE] (Heafield, 2011) for computing the target language model score. Decoding is made more efficient by using some of the more advanced features of KenLM such as state-reduction ((Li and Khudanpur, 2008), (Heafield et al., 2011)) and rest-cost estima-tions(Heafield et al., 2012).\nFootnote or Reference text (if exists): 3 http://kheafield.com/code/kenlm/\nSection Titles (if exists):  ['4 Decoding']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool** - KenLM is a software tool used for language modeling.\n* **TYPE: Code** - KenLM is a codebase"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/uclmr/jack/blob/master/conf/nli/esim.yaml\nCitation Context: via attention mech-anisms). For such a reason, J ACK allows to de-scribe these models at a high level, as a composi-tion of simpler building blocks [URL_CITE] , leaving concrete implementation details to the framework.\nFootnote or Reference text (if exists): 7 For instance, see https://github.com/uclmr/jack/blob/master/conf/nli/esim.yaml\nSection Titles (if exists):  ['3 Overview', '3.2 Distinguishing Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dodgejesse/sparsifying_regularizers_for_RRNNs\nCitation Context: We publicly release our code. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/dodgejesse/ sparsifying_regularizers_for_RRNNs\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mmihaltz/word2vec-GoogleNews-vectors\nCitation Context: We use the open-domain word embeddings [URL_CITE] for the initialization of word vectors. We initialize other model parameters from a uniform distribu-tion U(-0.05, 0.05).\nFootnote or Reference text (if exists): 1 https://github.com/mmihaltz/word2vec-GoogleNews-vectors\nSection Titles (if exists):  ['6 Experiments', '6.3 Training Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/p/word2vec/\nCitation Context: We used the extra-trees ensemble classifier im-plemented in (Pedregosa et al., 2011), with hyper-parameters optimized on the validation data: for-est of 500 trees and the maximum number of features\u221ato consider when looking for the best split is number features. We present a 3-fold evaluation: first, we compare our system with state-of-the-art systems on the same task, then we compare our domain-relevant vector representa-tions (DRVR-50) to more generic word embed-dings (C&W50, HLBL-50) 3 and finally to another word representation construction on the domain-specific data (W2V-50) [URL_CITE] .\nFootnote or Reference text (if exists): 4 W2V-50 are the embeddings induced from the MUC4 data set using the negative sampling training algorithm (Mikolov et al., 2013a; Mikolov et al., 2013b; Mikolov et al., 2013c), available at https://code.google.com/p/word2vec/\nSection Titles (if exists):  ['3 Experiments and Results', '3.2 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.leffingwell.com/top_10.htm\nCitation Context: The lack of vocabulary for smells and flavors contrasts starkly with the interest people in the West have for flavors and fragrances, and what they are willing to spend on such products. The flavor and fragrance industry is estimated to be worth over $20 billion in 2015 [URL_CITE] . In this context, experts\u2019 recommendations are used by the pub-lic in order to help them make decisions about purchases.\nFootnote or Reference text (if exists): 1 http://www.leffingwell.com/top_10.htm\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/liushulinle/event\nCitation Context: We publish our code for further study by the NLP community. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/liushulinle/event detection without triggers\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being presented as a tool or method for further study within the NLP community. \n* **TYPE: Code"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.inuktitutcomputing.ca/\nCitation Context: Additionally, they could be very useful for building educational applications for languages of under-represented communities (along with their inverse, morphological analyzers). Encouraging examples are the Yupik morphological analyzer (Schwartz et al., 2019) and the Inuktitut educa-tional tools from the respective Native Peoples communities. [URL_CITE] The social impact of such applica-tions can be enormous, effectively raising the sta-tus of the languages slightly closer to the level of the dominant regional language.\nFootnote or Reference text (if exists): 2 http://www.inuktitutcomputing.ca/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://alt.qcri.org/tools/\nCitation Context: These high scores allowed us to de-velop successful discourse similarity metrics. [URL_CITE]\nFootnote or Reference text (if exists): 2 The discourse parser is freely available from http://alt.qcri.org/tools/\nSection Titles (if exists):  ['3 Our Discourse-Based Measures', '3.1 Generating Discourse Trees']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.systransoft.com\nCitation Context: MT systems We test six widely used MT mod-els, representing the state of the art in both commercial and academic research: (1) Google Translate, (2) Microsoft Translator, (3) Amazon Translate, (4) SYSTRAN, [URL_CITE] (5) the model of Ott et al. (2018), which recently achieved the best per-formance on English-to-French translation on the WMT\u201914 test set, and (6) the model of Edunov et al.\nFootnote or Reference text (if exists): 4 http://www.systransoft.com\nSection Titles (if exists):  ['3 Evaluation', '3.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION:  Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The citation introduces a specific MT system (SYSTRAN) and its provider. It's not directly used"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wing.comp.nus.edu.sg/~linzihen/summeval/\nCitation Context: Experimental results on AESOP 2011 show that DICOMER significantly outperforms all sub-mitted metrics on both initial and update tasks with large gaps, while TESLA-S and CREMER signifi-cantly outperform all metrics on the initial task. [URL_CITE]\nFootnote or Reference text (if exists): 3 Our metrics are publicly available at http://wing.comp.nus.edu.sg/\u02dclinzihen/summeval/.\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.itl.nist.gov/iad/mig/tests/ace/2005/\nCitation Context: We conduct experiments on the ACE2005 corpus. [URL_CITE] It contains text documents from a variety of sources such as newswire reports, weblogs, and discussion forums. We use the same data split as in Li et al.\nFootnote or Reference text (if exists): 6 http://www.itl.nist.gov/iad/mig/tests/ace/2005/\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlm.nih.gov/mesh/meshhome.html\nCitation Context: These nodes have children, for example, Abdomen (A01.047) and Back (A01.176) are level [URL_CITE] children of Body Regions. The longer the ID of the MeSH term, the longer the path from the root and the more precise the description. For example migraine is C10.228.140.546.800.525, that is, C (a disease), C10 (Nervous System Diseases), C10.228 (Central Nervous\nFootnote or Reference text (if exists): 1 http://www.nlm.nih.gov/mesh/meshhome.html; the work reported in this paper uses MeSH 2001.\nSection Titles (if exists):  ['3 The Lexical Hierarchy: MeSH']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Knowledge\nTYPE: Knowledge\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Knowledge:** The URL points to the MeSH (Medical Subject Headings) database, which is a controlled vocabulary used for indexing and"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1016/j.neunet.2010.10.005\nCitation Context: Reweighting for covariate shift. Although they are not typically thought of in the context of es-timating proportions, several methods have been proposed to deal directly with the problem of co-variate shift, including kernel mean matching and its extensions (Huang et al., 2006; Sugiyama et al., 2011 [URL_CITE] ). Here, we consider the two-stage method from Bickel et al.\nFootnote or Reference text (if exists): Masashi Sugiyama, Makoto Yamada, Paul von Bu\u0308nau, Taiji Suzuki, Takafumi Kanamori, and Motoaki Kawanabe. 2011. Direct density-ratio estima-tion with dimensionality reduction via least-squares hetero-distributional subspace search. Neural Net-works 24(2). https://doi.org/10.1016/j.neunet.2010.10.005.\nSection Titles (if exists):  ['3 Methods', '3.2 Existing methods appropriate for extrinsic labels']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/GeneZC/ASGCN\nCitation Context: Based on it, a novel aspect-specific sentiment classification framework is raised. Experiments on three benchmarking collections illustrate that our proposed model has comparable effectiveness to a range of state-of-the-art models [URL_CITE] , and further demon-strate that both syntactical information and long-range word dependencies are properly captured by the graph convolution structure.\nFootnote or Reference text (if exists): 1 Code and preprocessed datasets are available at https://github.com/GeneZC/ASGCN.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-entities-guidelines-v5.6.6.pdf\nCitation Context: We present in this work a new dataset of en-tity annotations for a wide sample of 210,532 to-kens from 100 literary texts to help address these issues and help advance computational work on literature. These annotations follow the guide-lines set forth by the ACE 2005 entity tagging task (LDC, 2005) [URL_CITE] in labeling all nominal entities (named and common alike), including those with nested structure. In evaluating the stylistic dif-ference between the texts in ACE 2005 (primar-ily news) and the literary texts in our new dataset, we find considerably more attention dedicated to people and settings in literature; this attention di-rectly translates into substantially improved accu-racies for those classes when models are trained on them.\nFootnote or Reference text (if exists): LDC. 2005. Ace (automatic content extrac-tion) English annotation guidelines for enti-ties. https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-entities-guidelines-v5.6.6.pdf.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Document\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.itl.nist.gov/iad/mig/tests/mt/2006/\nCitation Context: The Chinese word \u201cHE ZHANG,\u201d denoted w r , which means river custodian, only occurs once in the whole corpus. We performed EM training using GIZA++ on this corpus concatenated with 442,967 training sen-tence pairs from the NIST Open Machine Trans-lation (OpenMT) 2006 evaluation [URL_CITE] . The resulting alignment is shown in Figure 1(b).\nFootnote or Reference text (if exists): 2 http://www.itl.nist.gov/iad/mig/tests/mt/2006/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.clsp.jhu.edu/PIRE/ssr\nCitation Context: We conducted our experiments on the recently re-leased Spontaneous Speech Reconstruction (SSR) corpus (Fitzgerald and Jelinek, 2008), a medium-sized set of disfluency annotations atop Fisher conversational telephone speech data (Cieri et al., 2004) [URL_CITE] . Advantages of the SSR data include\nFootnote or Reference text (if exists): 1 The Spontaneous Speech Reconstruction corpus can be downloaded from http://www.clsp.jhu.edu/PIRE/ssr.\nSection Titles (if exists):  ['2 Approach', '2.1 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lpsolve.sourceforge.net/\nCitation Context: We used lp solve [URL_CITE] to solve our ILP optimization problems. We ran experiments on two datasets.\nFootnote or Reference text (if exists): 3 From http://lpsolve.sourceforge.net/\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://lucene.apache.org\nCitation Context: There are many successful frameworks such as S TANFORD C ORE NLP (Manning et al., 2014), NLTK (Bird et al., 2009), and SPA C Y for NLP, L UCENE [URL_CITE] and S OLR for Information Retrieval, and SCIKIT - LEARN , P Y T ORCH and T ENSOR - F LOW (Abadi et al., 2015) for general Machine Learning (ML) with a special focus on Deep Learning (DL), among others. All of these frame-works touch upon several aspects of Machine Reading, but none of them offers dedicated sup-port for modern MR pipelines.\nFootnote or Reference text (if exists): 2 https://lucene.apache.org\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/\nCitation Context: We take the 12-layer BERT BASE model of 768 hidden di-mensions and train it on English Wikipedia for 200K steps from scratch. We also take a reduced 6-layer model and train it on Wiki103 [URL_CITE] for 40 epochs (160K steps) from scratch because this re-duced model does not fit well on the full Wikipedia dataset. The voken classification task will not bring additional parameters to the language en-coder (with 110M parameters) but need more com-putations, we thus adjust the training steps for pure masked-language-model (MLM) training for a fair comparison.\nFootnote or Reference text (if exists): 10 https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/\nSection Titles (if exists):  ['A Appendices', 'A.1 Full Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1145/2700406\nCitation Context: It seems unclear that this is a good simulation of the kind of shift in distribution that one is likely to en-counter in practice. An exception to this is Esuli and Sebastiani (2015) [URL_CITE] , who test their method on the RCV1-v2 corpus, also splitting by time. They perform a large number of experiments, but un-fortunately, nearly all of their experiments involve only a very small difference in label proportions between the source and target (with the vast ma-jority < 0.01), which limits the generalizability of their findings.\nFootnote or Reference text (if exists): Andrea Esuli and Fabrizio Sebastiani. 2015. Optimiz-ing text quantifiers for multivariate loss functions. ACM Trans. Knowl. Discov. Data 9(4). https: //doi.org/10.1145/2700406.\nSection Titles (if exists):  ['5 Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Method\nTYPE: Paper\nFUNCTION: Compare \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The citation refers to a research paper that presents a specific method (optimizing text quantifiers for multivariate loss functions"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.talkspace.com/\nCitation Context: Talkspace. In this work, we study text-based mes-sages from Talkspace, an online therapy platform with thousands of licensed therapists serving more than one-million users (Talkspace, 2020) [URL_CITE] . Anyone seeking therapy, henceforth clients, can sign up for a Talkspace plan and get matched with a licensed therapist who will respond 5\u02c6 a week through a chat room accessible by clients 24-7.\nFootnote or Reference text (if exists): Talkspace. 2020. Talkspace - #1 rated online therapy, 1 million+ users. https://www.talkspace.com/ , accessed Oct 1, 2020.\nSection Titles (if exists):  ['2 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ls6-www.informatik.uni-dortmund.de/ir/projects/freeWAIS-sf/\nCitation Context: Before describing our methods, we describe text representation which we used in this study. We to-kenize a document to words, downcase them and then remove stopwords, where the stopword list of freeWAIS-sf [URL_CITE] is used. Stemming is not performed.\nFootnote or Reference text (if exists): 2 Available at http://ls6-www.informatik.uni-dortmund.de/ir/projects/freeWAIS-sf/\nSection Titles (if exists):  ['4 Virtual Examples for Text Classification', 'We assume on text classification the following:']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://joshua-decoder.com/language-packs/paraphrase/\nCitation Context: Several different size language packs are available for download. [URL_CITE] The components of the language packs are described below. Grammar Our approach to sentential paraphras-ing is analogous to machine translation.\nFootnote or Reference text (if exists): 1 http://joshua-decoder.com/language-packs/paraphrase/\nSection Titles (if exists):  ['2 Language pack description']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a website that provides additional information about language packs, specifically for paraphrasing. It's not"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/docs/indicnlp.pdf\nCitation Context: For transliterating the Urdu and Konkani to a com-mon script, we used the Indic Trans library (Bhat et al., 2014), and for the others, we used Indic NLP library (Kunchukuttan, 2020) [URL_CITE] (as Urdu and Konkani not supported). In addition, there is an exception with Urdu because it follows a right to left writing system and all other Indian languages follow left to right writing order. Hence, in the pro-cessing step, we also changed the order of Urdu to maintain consistency among all languages, and do-ing this also made our string similarity algorithms work more efficiently.\nFootnote or Reference text (if exists): Anoop Kunchukuttan. 2020. The IndicNLP Library. https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/docs/indicnlp.pdf.\nSection Titles (if exists):  ['3 Experiments', '3.1 Data Preprocessing']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ara.reuters.com\nCitation Context: After extracting the false claims from V ERIFY , we collected the true claims of our corpus from R EUTERS [URL_CITE] by extracting headlines of news docu-ments. We used a list of manually selected key-words to extract claims with the same topics as those extracted from V ERIFY . Then, we manually excluded claims that contained political rhetorical statements (see example 3 be-low), multiple facts, accusations or denials, and ultimately we only kept those claims that discuss factual events, i.e., that can be verified.\nFootnote or Reference text (if exists): 5 http://ara.reuters.com\nSection Titles (if exists):  ['3 The Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ldc.upenn.edu/Projects/TIDES/Translation/TransAssess02.pdf\nCitation Context: The 769 sentences were translated by using five commercial MT systems to investigate the relation-ship between subjective evaluation based on yes/no questions and conventional subjective evaluation based on fluency and adequacy. The instruction for the subjective evaluation based on fluency and ad-equacy followed that given in the TIDES specifi-cation (TIDES, 2002) [URL_CITE] . The subjective evaluation based on yes/no questions was done by manually answering each question for each translation.\nFootnote or Reference text (if exists): TIDES. 2002. Linguistic Data Annotation Specifi-cation: Assessment of Fluency and Adequacy in Arabic-English and Chinese-English Translations. http://www.ldc.upenn.edu/Projects/TIDES/Translation/TransAssess02.pdf.\nSection Titles (if exists):  ['2 Test Set for Evaluating Machine Translation Quality', '2.1 Test Set']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Supplement** - The document provides guidelines and specifications for evaluating machine translation quality, which is used as a reference in the cited research. It'"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://toeflpractice.ets.org/\nCitation Context: The manual annotations were provided by two ex-perts with prior experience in various types of data annotation on both text and speech. First, a pi-lot annotation was conducted to train and cali-brate the annotators based on 48 training samples drawn from the TOEFL R Practice Online (TPO) product [URL_CITE] , which offers practice tests simulating the TOEFL iBT testing experience with authentic test questions. The training samples were selected from a TPO test form with 6 test questions and were balanced according to test question and pro-ficiency score, i.e., 2 responses from each score level for each question.\nFootnote or Reference text (if exists): 3 https://toeflpractice.ets.org/\nSection Titles (if exists):  ['3 Annotation', '3.2 Pilot Annotation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wiki.answers.com\nCitation Context: For experiments we used 2 publicly available CQA datasets: Yahoo! Answers Comprehensive Ques-tions and Answers and a crawl of WikiAnswers [URL_CITE] (Fader et al., 2014). The Yahoo!\nFootnote or Reference text (if exists): 5 http://wiki.answers.com\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/XinnuoXu/\nCitation Context: For further analysis and studies, we re-domains. However, GPT-2 is pre-trained on Open- lease the data from all intermediate steps for WebText and the language style and topics thereof each domain at [URL_CITE] https://github.com/XinnuoXu/ are quite different from those of daily conversa- AugNLG/tree/master/augmented_data .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The resource being cited is a dataset (the data from intermediate steps of the AugNLG project).\n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.acronymsearch.com/\nCitation Context: We downloaded a list of acronyms in capital let-ters only from Wikipedia and filtered them by eliminating acronyms shorter than three letters. Then we obtained definitions for each acronym from [URL_CITE] http://www.acronymsearch.com/ and dis-carded acronyms that have less than five defini-tions. Finally, we randomly selected 20 acronyms.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Experiment', '3.1 Acronym and definition preparation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://stackexchange.com/sites\nCitation Context: MultiNews (Fabbri et al., 2019) is a multi-document summarization dataset where [URL_CITE] to 10 news articles share a single summary. We consider every pair of articles that share a summary to be a similar document pair. Table 2 shows summary statistics of the two document ranking datasets.\nFootnote or Reference text (if exists): 2 https://stackexchange.com/sites\nSection Titles (if exists):  ['6 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://chasen.org/~taku/software/TinySVM/\nCitation Context: The features described in the previous section give us a way to provide the learning algorithm with the necessary information to make a classi-fication decision. The next step is to convert our training data into sets of features, and feed these classification instances to the learning algorithm. For the learning task, we use the TinySVM [URL_CITE] sup-port vector machine (SVM) implementation in conjunction with YamCha 7 (Kudo & Matsumoto, 2001), a suite for general-purpose chunking.\nFootnote or Reference text (if exists): 6 http://chasen.org/~taku/software/TinySVM/ 7 http://chasen.org/~taku/software/yamcha/\nSection Titles (if exists):  ['6 Classifier Parameters']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - TinySVM is a tool used *in* the research process, specifically for training a classifier. \n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/SAG-KeLP\nCitation Context: The Java language has been cho-sen in order to be compatible with many Java NLP/IR tools that are developed by the commu-nity, such as Stanford CoreNLP , OpenNLP or Lucene . K E LP is released as open source soft-ware under the Apache 2.0 license and the source code is available on github [URL_CITE] . Furthermore it can be imported via Maven.\nFootnote or Reference text (if exists): 4 https://github.com/SAG-KeLP\nSection Titles (if exists):  ['2 Framework Overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.gutenberg.org/\nCitation Context: We show that rich multi-view representations produce better micro-clusters compared to com-petitive but simpler models, and that interpretabil-ity of the learnt representations is not compro-mised despite the more complex objective. We also qualitatively demonstrate that high-quality micro-clusters emerge from a smaller, more ho-mogeneous data set of Gutenberg [URL_CITE] novels.\nFootnote or Reference text (if exists): 3 https://www.gutenberg.org/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cqa.iyas.qcri.org/cQA-Arabic-Demo\nCitation Context: A second example is a cQA demo [URL_CITE] in Arabic, which retrieves data from multiple medical forums from middle-east. In this case physicians answer to patients\u2019 questions: the left panel shows a ques-tion from a user and the right panel similar ques-tions with the answers from the expert. In general there is only one (good) answer from the doctor, so this is mostly a question re-ranking task.\nFootnote or Reference text (if exists): 4 http://cqa.iyas.qcri.org/ cQA-Arabic-Demo\nSection Titles (if exists):  ['5 Software Package']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Website\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The cited resource is a demo showcasing a specific cQA system. This suggests it's a tool used in the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.tensorflow.org/tensorboard\nCitation Context: Notable features of EGG include: (a) Prim-itives for implementing single-symbol or variable-length communication (with vanilla RNNs (Elman, 1990), GRUs (Cho et al., 2014), LSTMs (Hochreiter and Schmidhuber, 1997)); (b) Training with optimization of the com-munication channel through REINFORCE or Gumbel-Softmax relaxation via a common interface; (c) Simplified configuration of the general components, such as check-pointing, optimization, Tensorboard support, [URL_CITE] etc. ; (d) A simple CUDA-aware command-line tool for hyperparameter grid-search.\nFootnote or Reference text (if exists): 2 https://www.tensorflow.org/ tensorboard\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/ajaech/querycompletion\nCitation Context: We use Adadelta (Zeiler, 2012) and tune the online learn-ing rate to give the best perplexity on a held-out set of 12,000 queries, having previously verified that perplexity is a good indicator of performance on the QAC task. [URL_CITE]\nFootnote or Reference text (if exists): 2 Code at http://github.com/ajaech/query completion\nSection Titles (if exists):  ['4 Experiments', '4.1 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.elra.info/\nCitation Context: The bilingual dictionary used in our experiments is the French/English dictionary ELRA-M0033 available from the ELRA catalogue [URL_CITE] . This re-source is a general language dictionary which con-tains only a few terms related to the medical do-main.\nFootnote or Reference text (if exists): 5 http://www.elra.info/\nSection Titles (if exists):  ['3 Linguistic Resources', '3.2 Bilingual Dictionary']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The resource is a dataset (a bilingual dictionary) used in the research.\n* **TYPE: Dataset**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/atcbosselut/comet-commonsense\nCitation Context: For retrieving commonsense properties of the vehi-cle, we use the pre-trained COMET model [URL_CITE] and retrieve top 5 candidates for each input. Vehicle and Overall Quality.\nFootnote or Reference text (if exists): 11 https://github.com/atcbosselut/ comet-commonsense\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://technologies.kmi.open.ac.uk/aqualog/\nCitation Context: are developed that retrieve answers from the Web and other tex-tual sources. Similarly, structured QA systems (Aqualog [URL_CITE] , NLBean etc.) obtain answers from the sub-networks.\nFootnote or Reference text (if exists): 8 http://technologies.kmi.open.ac.uk/aqualog/\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl\nCitation Context: Both with the IMDB and BBC corpora, we did not do any preprocessing other than tokenization. [URL_CITE] Penn Treebank We evaluate a normal recurrent language model, count-based n-gram language model as well as the proposed RLM-BoW-EF-n and RLM-BoW-LF-n with varying n = 1, 2, 4, 8 on the Penn Treebank Corpus. We preprocess the corpus according to (Mikolov et al., 2011) and use a vocabulary of 10k words from the training cor-pus.\nFootnote or Reference text (if exists): 3 https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl\nSection Titles (if exists):  ['5 Experimental Settings', '5.2 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool in the research process (tokenization).\n* **TYPE: Code** - The URL"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.lsi.upc.edu/asiya/\nCitation Context: Metrics from A SIYA . We used the freely avail-able version of the A SIYA toolkit [URL_CITE] in order to ex-tend the set of evaluation measures contrasted in this study beyond those from the WMT12 metrics task. A SIYA (Gime\u0301nez and Ma\u0300rquez, 2010a) is a suite for MT evaluation that provides a large set of metrics that use different levels of linguistic infor-mation.\nFootnote or Reference text (if exists): 4 http://nlp.lsi.upc.edu/asiya/\nSection Titles (if exists):  ['4 Experimental Setup', '4.1 MT Evaluation Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/Jess1ca/CoordinationExtPTB\nCitation Context: We make the coordination anno-tation publicly available, in hope that they will facilitate further research into coordi-nation disambiguation. [URL_CITE]\nFootnote or Reference text (if exists): 1 The data is available in: https://github.com/Jess1ca/CoordinationExtPTB\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/cookielee77/CLARE\nCitation Context: Human eval-uation shows significant advantages of CLARE in terms of textual similarity, fluency and gram-maticality. We release our code and models at [URL_CITE] https://github.com/cookielee77/CLARE.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['6 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/hltcoe/golden-horse\nCitation Context: We make our code and the annotated corpus available. [URL_CITE]\nFootnote or Reference text (if exists): 10 https://github.com/hltcoe/golden-horse\nSection Titles (if exists):  ['4 Weibo NER Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/archive/p/ark-tweet-nlp/downloads(twpos-data-v0.3.tgz\nCitation Context: For POS tagging, we use three datasets Ritter11- T-POS (Ritter et al., 2011), ARK-Twitter [URL_CITE] (Gim-pel et al., 2011; Owoputi et al., 2013) and T WEEBANK - V 2 (Liu et al., 2018). For NER, we employ datasets from the WNUT16 NER shared task (Strauss et al., 2016) and the WNUT17 shared task on novel and emerging entity recognition (Derczynski et al., 2017). For text classification, we employ the 3-class sentiment analysis dataset from the SemEval2017 Task 4A (Rosenthal et al., 2017) and the 2-class irony detection dataset from the SemEval2018 Task 3A (Van Hee et al., 2018).\nFootnote or Reference text (if exists): 4 https://code.google.com/archive/p/ark-tweet-nlp/downloads(twpos-data-v0.3.tgz)\nSection Titles (if exists):  ['3 Experimental setup', 'Downstream task datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://jobimtext.org\nCitation Context: The domain-specific corpora consist of web pages, selected by using a combination of BootCat (Baroni and Bernardini, 2004) and focused crawling (Remus and Biemann, 2016). Noisy IS-A relations are extracted with lexical-syntactic patterns from all corpora by applying PattaMaika [URL_CITE] , PatternSim (Panchenko et al., 2012), and WebISA (Seitner et al., 2016), following (Panchenko et al., 2016).\nFootnote or Reference text (if exists): 2 http://jobimtext.org: The PattaMaika compo-nent is based on UIMA RUTA (Kluegl et al., 2016).\nSection Titles (if exists):  ['3 Taxonomy Refinement using Hyperbolic Word Embeddings', '3.1 Domain-specific Poincare\u0301 Embedding']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Supplement\nTYPE:  Website\nFUNCTION:  Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - While the website itself isn't directly used in the research (like a dataset or tool), it"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://hackingsemantics.xyz/2019/leaderboards/\nCitation Context: This would have beneficial second-order effects as well. For example, reporting the costs of making predictions would put large institutions and poorly-resourced model creators on more equal footing (Rogers, 2019) [URL_CITE] . This might motivate the creation of simpler methods whose ease-of-use makes up for weaker performance, such as weighted-average sen-tence embeddings (Arora et al., 2019; Ethayarajh, 2018).\nFootnote or Reference text (if exists): Anna Rogers. 2019. How the transformers broke NLP leaderboards. https://hackingsemantics.xyz/2019/leaderboards/. Accessed: 2020-05- 20.\nSection Titles (if exists):  ['4 The Future of Leaderboards', '4.1 A Leaderboard for Every User']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://pytorch.org/\nCitation Context: In all the experiments, we use PyTorch [URL_CITE] (Paszke et al., 2019) as the backend. All the experiments are conducted on NVIDIA V100 32GB GPUs. We use the Higher package (Grefenstette et al., 2019) to implement the proposed algorithm.\nFootnote or Reference text (if exists): 2 https://pytorch.org/\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.imdb.com/\nCitation Context: Dataset. Our experiments are conducted on six extreme multi-label datasets and their character-istics are shown in Table 1, among which IMDb is crawled from online movie database [URL_CITE] and the rest five datasets are downloaded from the extreme classification repository . For datasets from the repository, we adopt the provided train/test split, and for IMDb we randomly choose 20% of the data as test set and the rest of 80% as training set.\nFootnote or Reference text (if exists): 2 https://www.imdb.com/\nSection Titles (if exists):  ['3 Experiments & Analysis', '3.1 Dataset & Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The IMDb website is the source from which the dataset was obtained. It's not a tool used in the research process itself"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.gjopen.com/\nCitation Context: To explore the connections between language and forecasting skill, we make use of data from Good Judgment Open, [URL_CITE] an online prediction forum. Users of this website share predictions in response to a number of pre-specified questions about future events with uncertain outcomes, such as: \u201cWill North Korea fire another intercontinental ballistic missile before August 2019?\u201d Users\u2019 predictions consist of an estimated chance the event will oc-cur (for example, 5%) in addition to an optional text justification that explains why the forecast was made. A sample is presented in Figure 1.\nFootnote or Reference text (if exists): 2 https://www.gjopen.com/\nSection Titles (if exists):  ['2 Linguistic Cues of Accurate Forecasting', '2.1 Geopolitical Forecasting Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wordnet.princeton.edu\nCitation Context: The second fea-ture is invoked if two heads are identical or a head is a substring of another. The third feature is in-voked if two heads are synonyms or derivations that are extracted from the WordNet [URL_CITE] . The fourth feature is invoked if the cosine similarity between word embeddings of two heads is larger than a threshold.\nFootnote or Reference text (if exists): 4 http://wordnet.princeton.edu\nSection Titles (if exists):  ['5 Parameterization', '5.2 Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/adhigunasurya/distillation_parser.git\nCitation Context: The code to reproduce our results is pub-licly available. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/adhigunasurya/distillation_parser.git\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Method** - The code is a tool used in the research process to reproduce the results.\n* **TYPE: Code**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jungokasai/graph_parser\nCitation Context: We implement all of our models in TensorFlow (Abadi et al., 2016). [URL_CITE]\nFootnote or Reference text (if exists): 3 Our code is available online for easy replication of our results at https://github.com/jungokasai/graph_parser.\nSection Titles (if exists):  ['3 Results and Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/detectron\nCitation Context: 2AMMC: a retrieval model in which multiple Transformers are attended over in order to make use of a combination of ResNeXt-IG-3.5B and Faster R-CNN image features (Girshick et al., 2018) [URL_CITE] . We specifically use the 2AMMC model from Ju et al. (2019) because that model has the best test-set per-formance on Image-Chat in that work.\nFootnote or Reference text (if exists): Ross Girshick, Ilija Radosavovic, Georgia Gkioxari, Piotr Doll\u00e1r, and Kaiming He. 2018. Detectron. https://github.com/facebookresearch/detectron.\nSection Titles (if exists):  ['2 Related Work', '2.3 Comparison to Existing Models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.google.com/apis\nCitation Context: Here, we give an example illustrating the prin-ciple of clustering web search results in the FGS. In submitting TREC 2004 test question 1.1 \u201dwhen was the first Crip gang started?\u201d to Google ( [URL_CITE] http://www.google.com/apis), we extract n(= 8) different candidates from the top m(= 30) Google snippets. The Google snippets containing the same candidates are aligned snippets, and thus the 12 re-tained snippets are grouped into 8 clusters, as listed in Table 2.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 The U-SVM', '3.1 Clustering Web Search Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Material** - The Google search results are the source data used in the research to demonstrate the clustering principle. \n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wacky.sslmit.unibo.it/\nCitation Context: Our source corpus is the concatenation of the ukWaC corpus [URL_CITE] , a mid-2009 dump of the English Wikipedia and the British National Corpus . The corpus is tokenized, POS-tagged and lemmatized with TreeTagger (Schmid, 1995) and contains about 2.8 billion tokens. We extracted all statistics at the lemma level, ignoring inflectional information.\nFootnote or Reference text (if exists): 2 http://wacky.sslmit.unibo.it/\nSection Titles (if exists):  ['3 Method', '3.1 Semantic space', '3.1.1 Source corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://alt.qcri.org/resources/\nCitation Context: Table 1 shows the distribution over the stance labels, [URL_CITE] which turns out to be very similar to that for the FNC dataset. We can see that there are very few documents disagreeing with true claims (about 0.5%), which suggests that stance is pos-itively correlated with factuality. However, the number of documents agreeing with false docu-ments is larger than the number of documents dis-agreeing with them, which illustrates one of the main challenges when trying to predict the factu-ality of news based on stance.\nFootnote or Reference text (if exists): 7 The corpus is available at http://groups.csail.mit.edu/sls/downloads/ and also at http://alt.qcri.org/resources/\nSection Titles (if exists):  ['3 The Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.mcs.anl.gov/petsc/\nCitation Context: The part-of-speech tagger used to extract POS features was lgtagger (Constant and Sigogne, 2011). To train the reranker, we used a MaxEnt al-gorithm [URL_CITE] as in (Charniak and Johnson, 2005).\nFootnote or Reference text (if exists): 8 We used the following mathematical libraries PETSc et TAO, freely available at http://www.mcs.anl.gov/petsc/ and http://www.mcs.anl.gov/research/projects/tao/\nSection Titles (if exists):  ['6 Evaluation', '6.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The citation refers to a tool (PETSc) used in the research process (training a reranker). \n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/datasets\nCitation Context: We obtain closed-book QA datasets from https://github.com/facebookresearch/DPR/blob/master/data/downloaddata.py, knowledge-intensive language tasks from https://github.com/facebookresearch/KILT/blob/master/scripts/donwload all kilt data.py. We obtain ROPES, WIQA and QuaRTz from hug-gingface datasets ( [URL_CITE] https://huggingface.co/datasets). For more details, see Table 6.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['D Reproducibility', 'D.1 Dataset Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://cis.temple.edu/~edragut/DebugSL.webm\nCitation Context: In this paper we have presented the system DebugSL and described its usage. The project source code is available at https://github.com/atschneid/DebugSL and a screencast can be viewed at [URL_CITE] https://cis.temple.edu/\u02dcedragut/DebugSL.webm. The sys-tem will be deployed online for use by the public.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.natcorp.ox.ac.uk\nCitation Context: The Italian language vectors for the cross-lingual ex-periments of Section 6 were trained on 1.6 bil-lion tokens from itWaC. [URL_CITE] A word token is a word-form + POS-tag string. We extract both word vec-tors and the observed phrase vectors which are required for the training procedures.\nFootnote or Reference text (if exists): 5 Corpus sources: http://wacky.sslmit.unibo. it, http://www.natcorp.ox.ac.uk\nSection Titles (if exists):  ['4 Evaluation setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The URL points to a source of data (the itWaC corpus), making it a material resource used in the research."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lucene.apache.org/java/\nCitation Context: We performed experiments on a set of 1449 questions from TREC-99-03. Using the search en-gine [URL_CITE] , we retrieved around 5 top-ranked candi-date sentences from a large newswire corpus for each question to compile around 7200 q/a pairs. We manually labeled each candidate sentence as true or false entailment depending on the contain-ment of the true answer string and soundness of the entailment to compile quality training set.\nFootnote or Reference text (if exists): 2 http://lucene.apache.org/java/\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.globalWordnet.org/gwa/Wordnet_table.html\nCitation Context: It is also free. Wordnets in many languages are being constructed and developed [URL_CITE] . However, only a few of these Wordnets are of high quality and free for downloading.\nFootnote or Reference text (if exists): 2 http://www.globalWordnet.org/gwa/Wordnet_table.html\nSection Titles (if exists):  ['3 Experiments', '3.1 Publicly available Wordnets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.usna.edu/Users/cs/\nCitation Context: We compare Rel-grams schemas against the state-of-the-art narrative schemas released by Cham-bers (Chambers and Jurafsky, 2009). [URL_CITE] Chambers\u2019 schemas are less expressive than ours \u2013 they do not associate types with actors and each schema has a constant pre-specified number of relations. For a fair comparison we use a similarly expressive ver-sion of our schemas that strips off argument types and has the same number of relations per schema (six) as their highest quality output set.\nFootnote or Reference text (if exists): 8 Available at http://www.usna.edu/Users/cs/\nSection Titles (if exists):  ['5 Evaluation', '5.2 Schemas Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Document\nFUNCTION: Compare \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a set of schemas, which fall under the category of \"Knowledge\" in the provided schema."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.sighan.org/bakeoff2005/\nCitation Context: We collect all the MSUs from the benchmark datasets provided by the second International Chi-nese Word Segmentation Bakeoff [URL_CITE] . We choose the Peking University (PKU) data because it is more fine-grained than all other corpora. Suppose we represent the segmented data as L (In our case L is the PKU word segmentation data), the MSU se-lecting algorithm is shown in T ABLE 3.\nFootnote or Reference text (if exists): 2 http://www.sighan.org/bakeoff2005/\nSection Titles (if exists):  ['2 System Architecture', '2.2 MSU Based Tagging', '2.2.1 Minimum Semantic Unit']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/bplank/bleaching-text\nCitation Context: This results in an embedding space with a vocabulary size of 16M word types. All code is available at [URL_CITE] https://github.com/bplank/bleaching-text.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Experiments', '3.1 Lexical vs Bleached Models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lucene.apache.org/\nCitation Context: K E LP is a machine learning library completely written in Java. The Java language has been cho-sen in order to be compatible with many Java NLP/IR tools that are developed by the commu-nity, such as Stanford CoreNLP , OpenNLP or Lucene [URL_CITE] . K E LP is released as open source soft-ware under the Apache 2.0 license and the source code is available on github .\nFootnote or Reference text (if exists): 3 http://lucene.apache.org/\nSection Titles (if exists):  ['2 Framework Overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.utexas.edu/users/ml/nldata/geoquery\nCitation Context: To test the coverage and precision of Locutus, I have customized it to answer questions from the G EOQUERY 250 corpus (Mooney, 1996) [URL_CITE] , which consists of a database of geographical information paired with 250 English sentences requesting in-formation from that database. 25 of these sentences are held out for the purposes of another study, and I have not examined the behavior of Locutus with respect to these sentences.\nFootnote or Reference text (if exists): Mooney, Raymond. Geoquery 1996.Data. http://www.cs.utexas.edu/users/ml/nldata/geoquery. html (accessed February 13, 2010).\nSection Titles (if exists):  ['4 Experiment']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/K17-3002\nCitation Context: For parsing, since the derivation tree in a lexicalized TAG is a type of dependency tree (Rambow and Joshi, 1994), we can directly apply dependency parsing models. In particular, we use the biaffine graph-based parser proposed by Dozat and Manning (2017) [URL_CITE] together with our novel techniques for supertagging.\nFootnote or Reference text (if exists): Timothy Dozat, Peng Qi, and Christopher D. Man-ning. 2017. Stanford\u2019s graph-based neural depen-dency parser at the CoNLL 2017 shared task. In CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Asso-ciation for Computational Linguistics, Vancouver, Canada, pages 20\u201330. http://www.aclweb.org/anthology/K17-3002.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.reddit.com\nCitation Context: Our experiments are based on Reddit [URL_CITE] , one of the world\u2019s largest public discussion forums. On Red-dit, registered users initiate a post and people re-spond with comments, either to the original post or one of its associated comments.\nFootnote or Reference text (if exists): 2 http://www.reddit.com\nSection Titles (if exists):  ['2 Popularity Prediction and Tracking']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://isw3.naist.jp/IS/TechReport/report-list.html#2009\nCitation Context: For the description of features used in our adap-tation of the Shimbo-Hara model to Japanese, see (Okuma et al., 2009) [URL_CITE] . In this model, all features are defined as indicator functions asking whether one or more attributes (e.g., surface form, part-of-speech) take specific values at the neighbor of an arc. One example of a feature assigned to a diag-onal arc at row i and column j of the alignment graph is where POS [i] denotes the part-of-speech of the ith word in a sentence.\nFootnote or Reference text (if exists): H. Okuma, M. Shimbo, K. Hara, and Y. Matsumoto. 2009. Bypassed alignment graph for learning coor-dination in Japanese sentences: supplementary ma-terials. Tech. report, Grad. School of Information Science, Nara Inst. Science and Technology. http://isw3.naist.jp/IS/TechReport/report-list.html#2009.\nSection Titles (if exists):  ['2 Alignment-based coordinate structure analysis', '2.2 Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pytorch/fairseq/blob/master/examples/translation/README.md\nCitation Context: We compare our TAA method with the following representative baselines: Back Translation (BT) (Sennrich et al., 2016; Imamura et al., 2018). We utilize WMT\u201919 English-German translation models (Ng et al., 2019) based on Transformer (Vaswani et al., 2017) to translate the text from English to German, [URL_CITE] and then trans-late it back to English. We use random sampling for decoding as recommended by (Xie et al., 2020; Edunov et al., 2018), and set the temperature to 0.8 to generate more diverse paraphrases.\nFootnote or Reference text (if exists): 4 https://github.com/pytorch/fairseq/blob/master/examples/translation/README. md\nSection Titles (if exists):  ['3 Experiments', '3.2 Baselines']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dblp.uni-trier.de/db/journals/corr/corr1412.html\nCitation Context: Network parameters for CNN, LSTM & GRU: In the fully connected layers we use 50 and 10 neurons , respectively for the two hidden layers. We use Relu activations (Glorot et al., 2011) for intermediate layers and tanh activation in the final layer. We employ 20% Dropout (Srivastava et al., 2014) in the fully connected layers as a measure of regularization and Adam optimizer (Kingma and Ba, 2014) [URL_CITE] for optimization.\nFootnote or Reference text (if exists): Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimiza-tion. CoRR abs/1412.6980. http://dblp.uni-trier.de/db/journals/corr/corr1412.html.\nSection Titles (if exists):  ['2 Proposed Methodology']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Paper\nFUNCTION: Use \n\n\nLet me break down why:\n\n* **ROLE: Method** - The cited paper introduces the Adam optimization algorithm, a technique directly used in the research.\n\n* **TYPE: Paper"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/gabedoyle/acl2017\nCitation Context: Per terms of the non-disclosure agreement we signed with the firm, we are not able to share the data underlying the analyses reported below. We can, however, share the code and dummy test data, both of which can be accessed at [URL_CITE] http: //github.com/gabedoyle/acl2017.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Data: Corporate Email Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/QAQ-v/HetGT\nCitation Context: We train the models for 250K steps on a single GeForce GTX 1080 Ti GPU. Our code is available at [URL_CITE] https://github.com/QAQ-v/HetGT.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Experiments', '3.2 Parameter Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/\nCitation Context: \u2022 DSobtainedwordviaembeddingsLatent Semantic: DS embeddingsAnalysis (LSAare) and via retraining word2vec on the test data sets using the implementation in gensim [URL_CITE] . DS embeddings via LSA are denoted by LSA and DS embeddings via word2vec are de-noted by DSw2v.\nFootnote or Reference text (if exists): 3 https://radimrehurek.com/gensim/\nSection Titles (if exists):  ['3 Domain Adapted Word Embeddings for Improved Sentiment Classification', '3.2 Experimental evaluation and results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** -  The Gensim library is used as a tool to perform a specific task (re-training word2vec on the test"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/vikas95/AutoROCC\nCitation Context: The ROCC system and the codes for generat-ing all the analysis are provided here - [URL_CITE] https: //github.com/vikas95/AutoROCC .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://pypi.python.org/pypi/jieba\nCitation Context: We apply the Adam algorithm (Kingma and Ba, 2015) for optimization, where the parameters of Adam are set as in (Kingma and Ba, 2015). The variance \u03c3 [URL_CITE] of the Gaussian Kernel layer is set as 1, and all other trainable parameters are randomly initialized by uniform distribution within [-0.08,0.08]. The mini-batch size for the update is set as 128.\nFootnote or Reference text (if exists): 2 https://pypi.python.org/pypi/jieba\nSection Titles (if exists):  ['4 Experiment', '4.3 Implementation Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2013T19\nCitation Context: It is worth noting that to attain our best perfor-mance, we require the use of both an NER system, indirectly using labelled data from OntoNotes 5, and a constituency parser for extracting sub-clauses, trained on the Penn Treebank (Marcus et al., 1994). [URL_CITE] Moreover, a language-specific wh* heuristic was used for training the best perform-ing NMT models. This limits the applicability and flexibility of our best-performing approach to do-mains and languages that already enjoy extensive linguistic resources (named entity recognition and treebank datasets), as well as requiring some hu-man engineering to define new heuristics.\nFootnote or Reference text (if exists): 7 Ontonotes 5: https://catalog.ldc.upenn.edu/LDC2013T19\nSection Titles (if exists):  ['5 Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me break down why:\n\n* **ROLE: Material** - The cited resource is a labeled dataset (OntoNotes 5) used for training a Named Entity Recognition (NER"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/vihari/we_adapt_datasets\nCitation Context: Pretrained embeddings E are trained on Wikipedia using the default settings of word2vec\u2019s CBOW model. All our data splits are made publicly available at [URL_CITE] https://github.com/vihari/we_adapt_datasets.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['Topics and tasks']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://pytorch.org/\nCitation Context: There are many successful frameworks such as S TANFORD C ORE NLP (Manning et al., 2014), NLTK (Bird et al., 2009), and SPA C Y for NLP, L UCENE and S OLR for Information Retrieval, and SCIKIT - LEARN , P Y T ORCH [URL_CITE] and T ENSOR - F LOW (Abadi et al., 2015) for general Machine Learning (ML) with a special focus on Deep Learning (DL), among others. All of these frame-works touch upon several aspects of Machine Reading, but none of them offers dedicated sup-port for modern MR pipelines.\nFootnote or Reference text (if exists): 5 http://pytorch.org/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/castorini/birch\nCitation Context: The final score used by Birch for re-reranking is: \u03b3\u00b7S BM25 +(1\u2212\u03b3)\u00b7P i \u03ba i \u00b7S(x q , x i ) where S BM25 is the baseline BM25 score and \u03b3, \u03ba i are weight coefficients. We use the published mod-els [URL_CITE] and coefficient values for evaluation.\nFootnote or Reference text (if exists): 3 https://github.com/castorini/birch\nSection Titles (if exists):  ['5 Experiments', '5.1 Tasks and Models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The cited resource is a code repository containing a specific algorithm (Birch) used in the experiments.  Code is often used as"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://fjoch.com/mkcls.html\nCitation Context: Though PoS induction was not their aim, this restriction is largely validated by empirical analysis of treebanked data, and moreover conveys the sig-nificant advantage that all the tags for a given word type can be updated at the same time, allowing very efficient inference using the exchange algorithm. This model has been popular for language mod-elling and bilingual word alignment, and an imple-mentation with improved inference called mkcls (Och, 1999) [URL_CITE] has become a standard part of statis-tical machine translation systems.\nFootnote or Reference text (if exists): 1 Available from http://fjoch.com/mkcls.html.\nSection Titles (if exists):  ['2 Background']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cogcomp.cs.illinois.edu/Data/QA/QC/\nCitation Context: In this setting, Tree Kernels allow to directly model the examples in terms of their parse trees. The reference cor-pus is the UIUC dataset (Li and Roth, 2002), in-cluding 5,452 questions for training and 500 ques-tions for test [URL_CITE] , organized in six coarse-grained classes, such as HUMAN or LOCATION. Again, Kernel-based SVM has been evaluated adopting the same setup of (Croce et al., 2011).\nFootnote or Reference text (if exists): 11 http://cogcomp.cs.illinois.edu/Data/QA/QC/\nSection Titles (if exists):  ['3 Case Studies in NLP', '3.3 Question Classification']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6213\nCitation Context: (2017) and Friedman et al. (2017) [URL_CITE] achieved state-of-the-art TAG parsing performance using an unlexicalized shift-reduce parser with feed-forward neural networks that was trained on a version of the Penn Treebank that had been annotated with TAG derivations. Here, we pursue this data-driven approach, applying a graph-based parser with deep biaffine attention (Dozat and Manning, 2017) that allows for global training and inference.\nFootnote or Reference text (if exists): Dan Friedman, Jungo Kasai, R. Thomas McCoy, Robert Frank, Forrest Davis, and Owen Rambow. 2017. Linguistically rich vector representations of supertags for TAG parsing. In TAG+. Associa-tion for Computational Linguistics, Umea\u030a, Sweden, pages 122\u2013131. http://www.aclweb.org/anthology/W17-6213.\nSection Titles (if exists):  ['2 Our Models', '2.2 Parsing Model']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION:  Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Supplement** - The citation refers to a specific paper that provides background information and context for the authors' work. It's"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/NLPWM-WHU/RACL\nCitation Context: We compare our proposed graph prediction ap-proach with three state-of-the-art baselines for extracting targets and expressions and predicting the polarity: IMN , RACL [URL_CITE] , as well as RACL-BERT, which also incorporates contextualized em-beddings. Instead of using BERT Large , we use the cased BERT-multilingual-base in order to fairly compare with our own models.\nFootnote or Reference text (if exists): 7 https://github.com/NLPWM-WHU/RACL.\nSection Titles (if exists):  ['4 Modeling', '4.3 Baselines']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.phontron.com/kftt\nCitation Context: Datasets. We evaluate TrDec on three datasets: 1) the KFTT (ja-en) dataset (Neubig, 2011) [URL_CITE] , which consists of Japanese-English Wikipedia arti-cles; 2) the IWSLT2016 German-English (de-en) dataset (Cettolo et al., 2016), which consists of TED Talks transcriptions; and 3) the LORELEI Oromo-English (or-en) dataset , which largely con-sists of texts from the Bible. Details are in Tab.\nFootnote or Reference text (if exists): Graham Neubig. 2011. The Kyoto free translation task. http://www.phontron.com/kftt.\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/e-bug/nmt-difficulty\nCitation Context: We then present the first systematic and con-trolled study of cross-lingual translation dif-ficulties using modern neural translation sys-tems. Code for replicating our experiments is available online at [URL_CITE] https://github.com/e-bug/nmt-difficulty.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.createdebate.com\nCitation Context: The second dataset (createdebate, henceforth) comes from an online debating site [URL_CITE] . It consists of 30 debates containing a total of 2,712 posts.\nFootnote or Reference text (if exists): 3 http://www.createdebate.com\nSection Titles (if exists):  ['2 Related Work', '2.4 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.infoplease.com/people.html\nCitation Context: We download from infoplease.com [URL_CITE] and biogra-phy.com two corpora of people\u2019s biographies, which include 24,975 and 24,345 bios respectively. We scan each whole corpus and extract people having spouse information.\nFootnote or Reference text (if exists): 2 http://www.infoplease.com/people.html\nSection Titles (if exists):  ['4 Experiments and Results', '4.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.galaxyforums.net/\nCitation Context: StackOverflow 1 , a popular discussion forum for programmers is among the top-100 most vis-ited sites globally 2 . Now, there are discussion fo-rums for almost every major product ranging from automobiles to gadgets such as those of Mac or Samsung [URL_CITE] . These typically start with a registered user posting a question/problem to which other users respond.\nFootnote or Reference text (if exists): 5 http://www.galaxyforums.net/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The website is not directly used in the research process (like a dataset or tool). It's cited as an"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://bllip.cs.brown.edu/download/genia1.0-division-rel1.tar.gz\nCitation Context: In the third experiment denoted by \u2019\u201cWSJ-to- G\u201d, we used WSJ corpus as the source domain and Genia corpus (G) [URL_CITE] as the target domain. Following Plank and van Noord (2011), we used the train-ing data in CoNLL 2008 shared task (Surdeanu et al., 2008) which are also from WSJ sections 2-21 but converted into dependency structure by the LTH converter (Johansson and Nugues, 2007).\nFootnote or Reference text (if exists): 4 Genia distribution in Penn Treebank format is avail-able at http://bllip.cs.brown.edu/download/genia1.0-division-rel1.tar.gz\nSection Titles (if exists):  ['3 Experiments', '3.1 Data and Tools']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/kpu/kenlm\nCitation Context: PPL and LL scores are extracted from a 5-gram Ken LM model (Heafield, 2011). [URL_CITE] Training Data Table 3 presents statistics on the training data used for supervised and unsuper-vised models across the ST evaluation aspects. For datasets that are only available for EN , we use the already available machine translated re-sources for STS and formality datasets (Briakou et al., 2021b).\nFootnote or Reference text (if exists): 9 https://github.com/kpu/kenlm\nSection Titles (if exists):  ['4 Experiment Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.isca-speech.org/archive/\nCitation Context: approx 32 0.6 ( Neighbors ( 1024 9998 Corpus 100 2 Particular 32 9998 Nearest 1024 0.4 Training 200 in 2 Words 32 of in 1024 # 0.2 % Frequency 800 99982 32 1024 max 9998 0 20 40 60 80 100 % Stability Figure 6: Stability of word2vec on the PTB. Stability is measured across ten randomized embedding spaces trained on the training data of the PTB (determined us-ing language modeling splits (Mikolov et al., 2010) [URL_CITE] ). Each word is placed in a frequency bucket (left y-axis) and stability is determined using a varying number of\nFootnote or Reference text (if exists): Tomas Mikolov, Martin Karafia\u0301t, Lukas Burget, Jan Cernocky\u0300, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Interspeech. volume 2, page 3. https: //www.isca-speech.org/archive/ interspeech 2010/i10 1045.html.\nSection Titles (if exists):  ['5 Lessons Learned: What Contributes to the Stability of an Embedding']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Material** - The resource cited is a dataset (the Penn Treebank, PTB) used for training a language model. "
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://universaldependencies.github.io\nCitation Context: \u2022 We convert the representation of coordination structures into a format inspired by Universal Dependencies. [URL_CITE] In the original Treex anno-tation style, the conjunction heads both con-juncts, whereas in our modification, the first conjunct is at the top, heading the coordina-tion and the second conjunct (see Figure 4).\nFootnote or Reference text (if exists): 8 http://universaldependencies.github.io\nSection Titles (if exists):  ['5 Experimental Setup', '5.1 Data set']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wiki.answers.com\nCitation Context: For h W2W , GIZA++ is used to train word alignments on 11.6M \u2018question-related question\u2019 pairs (Fader et al., 2013) crawled from WikiAnswers. [URL_CITE] . For h W2V , Word2Vec (Mikolov et al., 2013) is used to train word embedding on sentences from Wikipedia in English.\nFootnote or Reference text (if exists): 7 http://wiki.answers.com\nSection Titles (if exists):  ['7 Experiments', '7.1 Evaluation on QA (English)', '7.1.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1017/CBO9780511809071.007\nCitation Context: Only a small percentage of the words appearing in news can be used for meaningful information extraction and analysis (Manning et al., 1999; Ho-vold, 2005). Specifically, we eliminated too fre-quent (at least once in more than 50% of the days) or too rare (appearing in less than 100 articles) (Manning et al., 2008) [URL_CITE] . Many common English nouns, adjectives and verbs, whose contribution to semantics is minimal (Forman, 2003) were also removed from the vocabulary.\nFootnote or Reference text (if exists): Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schtze. 2008. Scoring, term weighting, and the vector space model. Cambridge University Press, 100123. https://doi.org/10.1017/CBO9780511809071.007\nSection Titles (if exists):  ['3 Predictive Causal Graph', '3.1 Selecting Informative Words:']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Document\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The cited resource is a book chapter, which is a form of knowledge captured in a document.\n* **TYPE: Document"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: https://www.comet.ml/docs/python-sdk/introduction-optimizer/\nCitation Context: For OOV words, we randomly replace tokens by \"UNK\" token with p = 0.02 during training and use it for testing (\u017dilka and Jurc\u030c\u00edc\u030cek, 2015). We perform hyperparameter search using Comet\u2019s Bayesian search algorithm [URL_CITE] , maximising F1 score for sequence tagging and accuracy for sequence classification on the validation set. The hyperparameter search trials are limited to 20 for all of our experiments.\nFootnote or Reference text (if exists): 4 https://www.comet.ml/docs/python-sdk/introduction-optimizer/\nSection Titles (if exists): [\\'Training details\\']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PaddlePaddle/ERNIE/tree/repro\nCitation Context: ERNIE baselines. E RNIE [URL_CITE] (Sun et al., 2019a,b) enhances B ERT through knowledge integration using a entity-level masked LM task and more raw text from the Web resources, which achieves the currently best results on Chinese NER. E RNIE +F UR +E NT is a stronger baseline, which uses the same entity dictionary as ours for entity-level masking and further pre-trains E RNIE on the same raw text as ours.\nFootnote or Reference text (if exists): 5 https://github.com/PaddlePaddle/ERNIE/tree/repro\nSection Titles (if exists):  ['4 Experiments', '4.2 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/electra\nCitation Context: We compare the number of train-ing steps per second. For direct comparison, we modify the ELECTRA reference code [URL_CITE] . For TPU v3 with 8 TPU cores, ELECTRA and SCRIPT achieve 31.3 and 22.7 training iterations per sec-ond with a mean MXU utilization of 14.93% and 17.91% for small models, respectively.\nFootnote or Reference text (if exists): 2 https://github.com/google-research/ electra\nSection Titles (if exists):  ['3 Experiments', '3.3 Computational Efficiency']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Compare \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool to directly compare the training speed of different models (ELECTRA and SCRIPT). \n*"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://aka.ms/Splash_dataset\nCitation Context: While we estimated hu-man correction accuracy is 81.5%, our best model achieves only 25.1%, which leaves a large gap for improvement in future research. SPLASH is publicly available at [URL_CITE] https://aka.ms/Splash_dataset.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html\nCitation Context: In Akamon, we support the usage of deep syn-tactic structures for obtaining fine-grained transla-tion rules as described in our former work (Wu et al., 2010) . Similarly, Enju [URL_CITE] , a state-of-the-art and freely available HPSG parser for English, can be used to generate packed parse forests for source sentences . Deep syntactic structures are included in the HPSG trees/forests, which includes a fine-grained description of the syntactic property and a semantic representation of the sentence.\nFootnote or Reference text (if exists): 8 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html\nSection Titles (if exists):  ['4 Using Deep Syntactic Structures']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mat-annotation.sourceforge.net/\nCitation Context: This process can then be repeated until the ma-chine learning model is performing well enough to be partly or fully automated. This is similar to the \u201ctag-a-little, learn-a-little loop\u201d from MAT (Bayer, 2015) [URL_CITE] . If combined with enabling pre-annotations, it is also very similar to the annotation process of RapTAT (Gobbel et al., 2014).\nFootnote or Reference text (if exists): Samuel Bayer. 2015. MITRE Annotation Toolkit (MAT). http://mat-annotation.sourceforge.net/.\nSection Titles (if exists):  ['4 Annotation Generator', '4.2 Active Learning Process']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The citation refers to a tool (MAT) used in a specific research process (annotation).  Tools are often classified"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/sameenmaruf/selective-attn\nCitation Context: For the Transformer, we use Transformer-DyNet implementation and extend it for our context-aware NMT model. [URL_CITE] The hidden dimensions and feed-forward layer size is set to 512 and 2048 respectively. We use 4 layers each in the encoder and decoder with 8 attention heads and employ label smoothing with a value of 0.1.\nFootnote or Reference text (if exists): 8 The code is available at https://github.com/sameenmaruf/selective-attn\nSection Titles (if exists):  ['4 Experiments', '4.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/archive/p/word2vec/\nCitation Context: We implemented the CPAE (Section 2.1) as a baseline and compared it to CPAE with the word-pair embeddings (Section 3.1), which is our pro-posed method. The word embeddings in the def-inition encoder were initialized by the Google Word2Vec vectors [URL_CITE] . Google Word2Vec vectors and GloVe were used as the other baselines.\nFootnote or Reference text (if exists): 4 https://code.google.com/archive/p/word2vec/\nSection Titles (if exists):  ['4 Experiments and Results', '4.2 Definition Embedding']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.efset.org/research/~/media/centralefcom/efset/pdf/\nCitation Context: First, as mentioned previously, in our dataset the MET and reported TOEFL scores have a Pearson\u2019s r correlation of 0.74. We further note an external study conducted by the testing com-pany Education First (EF) which measured the correlation of their flagship standardized English proficiency test EFSET-PLUS with TOEFL-iBT (Luecht, 2015) [URL_CITE] . Using 384 participants who took both tests, the study found a Pearson\u2019s r of 0.63 for the reading comprehension and 0.69 for the listen-ing comprehension sections of these tests.\nFootnote or Reference text (if exists): Richard M Luecht. 2015. EFSET PLUS - TOEFL iBT correlation study report. https://www.efset.org/research/\u02dc/media/centralefcom/efset/pdf/ EFSET_TOEFL_correlational_report_ Sep_v1.pdf.\nSection Titles (if exists):  ['4 English Proficiency Scoring Based on Eye Movements in Reading', '4.1 Correlation with MET and TOEFL']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Compare \n\n\nLet me break down why:\n\n* **ROLE: Supplement** - The cited document provides external research findings that are being compared to the authors' own findings. It's not a"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/PyTorch-BigGraph\nCitation Context: Ganea and Hofmann (2017) provide pretrained embed-dings for a subset of approximately 470K entities. Early experiments with embeddings derived from Wikidata relations [URL_CITE] did not improve results.\nFootnote or Reference text (if exists): 4 https://github.com/facebookresearch/ PyTorch-BigGraph\nSection Titles (if exists):  ['4 Experiments', '4.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/wenlinyao/EMNLP20-SubeventAcquisition\nCitation Context: The evalua-tion showed that the acquired subevent tuples (239K) are of high quality (90.1% accuracy) and cover a wide range of event types. The acquired subevent knowledge has been shown useful for discourse analysis and identifying a range of event-event relations [URL_CITE] .\nFootnote or Reference text (if exists): 1 Code and the knowledge base are avail-able at https://github.com/wenlinyao/ EMNLP20-SubeventAcquisition\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/\nCitation Context: Sil et al. (2010) extract sequences of verb constructions from webpages to learn common 8 See [URL_CITE] https://en.wikipedia.org/wiki/ preconditions of actions and events, and Cham- Wikipedia:Notability_(events) be transferable to the cross-document case. on Empirical Methods in Natural Language Process-To the best of our knowledge, we are the first to ing: System Demonstrations, pages 205\u2013215, On-propose a cheap and high-quality data extraction approach specifically for cross-document event ex-traction and coreference which does not depend on pre-existing resources, combining past work on event extraction from raw newswire text and min-ing of hyperlinks.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Discussion and Future Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Compare \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The Wikipedia article is cited as a reference point for understanding the concept of \"Notability\" in the context of events"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: https://github.com/facebookresearch/vilbert-multi-task\nCitation Context: Faster R-CNN Finally, we consider Faster R-CNN features (Ren et al., 2017), using models trained in the Detectron framework (Girshick et al., 2018); specifically, we use a ResNeXt-152 back-bone trained on the Visual Genome dataset (Kr-ishna et al., 2016) with the attribute head (Singh et al., 2020a) [URL_CITE] . The Faster R-CNN features are 2048\u00d7100-dimensional representations, and we re-fer to these features as \u201cFaster R-CNN\".\nFootnote or Reference text (if exists): 5 https://github.com/facebookresearch/ vilbert-multi-task\nSection Titles (if exists): [\\'References\\']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://alchemy.cs.washington.edu/\nCitation Context: 2 Alchemy includes a discriminative EM algorithm, but it as-sumes that only a few values are missing, and cannot handle completely hidden predicates. Kok & Domingos (2007) [URL_CITE] applied Markov logic to relational clustering, but they used hard EM.\nFootnote or Reference text (if exists): Kok, S.; Singla, P.; Richardson, M.; Domingos, P.; Sumner, M.; Poon, H. & Lowd, D. 2007. The Alchemy system for statistical relational AI. http://alchemy.cs.washington.edu/.\nSection Titles (if exists):  ['3 Markov Logic']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset\nCitation Context: The proposed model learns relation representations along the shortest dependency path (SDP) extracted from the structure regularized de-pendency tree, which has the benefits of re-ducing the complexity of the whole model. Experimental results show that the proposed method significantly improves the F 1 score by 10.3, and outperforms the state-of-the-art ap-proaches on Chinese literature text [URL_CITE] .\nFootnote or Reference text (if exists): 1 The Chinese literature text corpus for relation classi-fication, developed and used by this paper, is available at https://github.com/lancopku/Chinese-Li terature-NER-RE-Dataset\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Material** - The dataset is a core resource used in the research, providing the data for training and evaluation.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ryanzhumich/editsql\nCitation Context: EditSQL (Zhang et al., 2019): EditSQL (with BERT) is the highest-performing model on the Spi-der dataset that also provides an open-source im-plementation along with a downloadable trained model. [URL_CITE] The model was built for edit-based multi-turn parsing tasks, but can also be used as a single-turn parser for Spider or KaggleDBQA. It employs a sequence-to-sequence model with a question-table co-attention encoder for schema encoding.\nFootnote or Reference text (if exists): 3 https://github.com/ryanzhumich/ editsql\nSection Titles (if exists):  ['4 Experiments', '4.1 Baseline Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pytorch/fairseq/blob/master/examples/translation/prepare-iwslt14.sh\nCitation Context: We use translation benchmarks IWSLT14 En\u2013De, En\u2013Fr, En\u2013It, and IWSLT15 En\u2013Vi in our experi-ments. The datasets of IWSLT14 are pre-processed with the script in Fairseq [URL_CITE] . For IWSLT14 datasets, we use tst2011 as validation set and tst2012 as test set.\nFootnote or Reference text (if exists): 3 https://github.com/pytorch/fairseq/blob/master/examples/translation/prepare-iwslt14.sh\nSection Titles (if exists):  ['6 Experiments', '6.1 Neural Machine Translation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pstadler1990/nmt_paper21_appendix\nCitation Context: We created 10 sentences per phe-nomenon, resulting in a total of 585 sentences, ex-amining 49 phenomena organised in 13 categories. The raw test items, as well as the translations eval-uated can be found in our repository [URL_CITE] . The phe-nomena selected for this experiment are a subset of the ones of German\u2192English MT, as described in Macketanz et al.\nFootnote or Reference text (if exists): 1 https://github.com/pstadler1990/nmt_ paper21_appendix\nSection Titles (if exists):  ['4 Experiment setup', '4.1 Test suite setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://sarathchandar.in/bridge-corrnet\nCitation Context: In this paper, we propose Bridge Correlational Neu-ral Networks which can learn common representa-tions for multiple views even when parallel data is available only between these views and a pivot view. Our method performs better than the existing state of the art approaches on the cross language clas-sification task and gives very promising results on the cross modal access task. We also release a new multilingual image caption benchmark (MIC bench-mark) which will help in further research in this field [URL_CITE] .\nFootnote or Reference text (if exists): 5 Details about the MIC benchmark and performance of var-ious state-of-the-art models will be maintained at http://sarathchandar.in/bridge-corrnet\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://dev.twitter.com/\nCitation Context: The experiments are conducted on the 24 Twitter trending topics collected using Twitter APIs [URL_CITE] . The statistics are shown in Table 1.\nFootnote or Reference text (if exists): 3 https://dev.twitter.com/\nSection Titles (if exists):  ['3 Experiments and Evaluations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://archive.ics.uci.edu/ml/\nCitation Context: Two multiclass document classification datasets were used: Reuters Transcribed and Mini News-groups, distributed at [URL_CITE] http://archive.ics.uci.edu/ml/. The properties of the datasets are summarized in Ta-ble 2.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Experiments', '7.2 Document classification', '7.2.1 Task and dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/IBM/WordMoversEmbeddings\nCitation Context: Moreover, WME often achieves orders of magnitude speed-up compared to KNN-WMD while obtaining the same testing accuracy. Our code and data is available at [URL_CITE] https://github.com/IBM/WordMoversEmbeddings.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dice-group/Palmetto\nCitation Context: In this section, we study whether jointly learning topic models and classification can be helpful in producing coherent and meaningful top-ics. We use the C V metric (Ro\u0308der et al., 2015) computed by Palmetto toolkit [URL_CITE] to evaluate the topic coherence, which has been shown to give the closest scores to human evaluation compared to other widely-used topic coherence metrics like NPMI (Bouma, 2009). Table 4 shows the compar-ison results of LDA, BTM, NTM, and TMN on the three English datasets.\nFootnote or Reference text (if exists): 12 https://github.com/dice-group/ Palmetto\nSection Titles (if exists):  ['4 Experimental Results', '4.2 Topic Coherence Comparison']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cis.upenn.edu/dbikel/software.html\nCitation Context: The sec-ond largest gain was on PPs, where we improved by 1.7% over 3,775 constituents. We tested the signif-icance of our results (on all the data combined) us-ing Dan Bikel\u2019s randomized parsing evaluation com-parator [URL_CITE] and found that both the precision and recall gains were significant at p \u2264 0.01.\nFootnote or Reference text (if exists): 6 Available at http://www.cis.upenn.edu/dbikel/software.html\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://kbqademo.gstore.cn\nCitation Context: Moreover, we develop a novel data annotation strategy that facilitates the node-to-mention alignment, a dataset with such strat-egy is also published to promote further re-search. An online demo of NAMER [URL_CITE] is pro-vided to visualize our framework and supply extra information for users, a video illustra-tion of NAMER is also available.\nFootnote or Reference text (if exists): 2 http://kbqademo.gstore.cn\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.scalanlp.org\nCitation Context: First, the text is processed with a part-of-speech and a named entity taggers. [URL_CITE] Next, each detected noun or entity is disambiguated in the same way as in the single word disambiguation mode described above, yet the disambiguation re-sults are represented as annotations of a running text. The best matching sense is represented by a hypernym and an image as depicted in Figure 3.\nFootnote or Reference text (if exists): 10 http://www.scalanlp.org\nSection Titles (if exists):  ['3 Unsupervised Knowledge-Free Interpretable WSD', '3.3 User Interface for Interpretable WSD']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.npm.gov.tw\nCitation Context: We use the Chinese/English web pages of the National Palace Museum [URL_CITE] as our underlying parallel corpus. It contains about 30,000 sentences in each language.\nFootnote or Reference text (if exists): 2 http://www.npm.gov.tw\nSection Titles (if exists):  ['3 Experimental Results', '3.1 Experimental Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://webdatacommons.org/webtables\nCitation Context: WDC WebTable Corpus (Lehmberg et al., 2016) is a large collection of Web tables extracted from the Common Crawl Web scrape [URL_CITE] . We use its 2015 English-language relational subset, which consists of 50.8 million relational tables and their surrounding NL contexts.\nFootnote or Reference text (if exists): 10 http://webdatacommons.org/webtables\nSection Titles (if exists):  ['A Pretraining Details', 'A.1 Training Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://dev.twitter.com/streaming/\nCitation Context: The English tweets containing one of the selected hashtags are crawled using Twit-ter streaming API. [URL_CITE] The tweet temporal orienta-tion classifier is validated on a manually annotated test set. Finally, we use this classifier to automat-ically classify a large dataset consisting of \u224810 million tweets from 5,191 users mapped to their user-level features.\nFootnote or Reference text (if exists): 1 https://dev.twitter.com/streaming/overview. Last accessed on 10-01-2018.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dx.doi.org/10.3765/sp.11.10\nCitation Context: These player ut-terances are the \u201clinguistic\u201d turns. In addition the corpus contains information given visually in the game interface but transcribed in the corpus into Server or interface messages, \u201cnon-linguistic\u201d turns (Hunter et al., 2018) [URL_CITE] . All turns are seg-mented into DUs, and these units are then con-nected by semantic relations.\nFootnote or Reference text (if exists): Julie Hunter, Nicholas Asher, and Alex Lascarides. 2018. A formal semantics for situated conver-sation. Semantics and Pragmatics, 11. DOI: http://dx.doi.org/10.3765/sp.11.10.\nSection Titles (if exists):  ['3 The STAC Annotated Corpus', '3.1 Overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Document\nFUNCTION: Use \n\n\nLet me break down why:\n\n* **ROLE: Material** - The cited resource is a scholarly paper, which is a type of knowledge resource.\n* **TYPE: Document**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.nltk.org/\nCitation Context: Preprocessing and Hyperparameter Setting. To preprocess the training corpus D, we use the word tokenizer provided by NLTK [URL_CITE] . We also use a phrase mining tool, AutoPhrase (Shang et al., 2017), to extract meaningful phrases such as \u201cgreat wine\u201d and \u201cnumeric keypad\u201d such that they can capture complicated semantics in a single text unit.\nFootnote or Reference text (if exists): 3 https://www.nltk.org/\nSection Titles (if exists):  ['5 Evaluation', '5.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://alchemy.cs.washington.edu/\nCitation Context: We implemented our method as an extension to the Alchemy system (Kok et al., 2007) [URL_CITE] . Since our learn-ing uses sampling, all results are the average of five runs using different random seeds.\nFootnote or Reference text (if exists): Kok, S.; Singla, P.; Richardson, M.; Domingos, P.; Sumner, M.; Poon, H. & Lowd, D. 2007. The Alchemy system for statistical relational AI. http://alchemy.cs.washington.edu/.\nSection Titles (if exists):  ['6 Experiments', '6.1 System']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://zenodo.org/record/4421380\nCitation Context: All models are of dimensionality d = 768 and have 12 layers, plus one static embedding layer. We also include two 300 dimensional non-contextual mod-els, Word2Vec [URL_CITE] and GloVe, for comparison. Our corpus O is an 85k token sample of random arti-cles from English Wikipedia.\nFootnote or Reference text (if exists): 3 https://zenodo.org/record/4421380\nSection Titles (if exists):  ['3 Rogue Dimensions and', '3.1.2 Experiment']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Material\nTYPE:  Dataset\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://youtu.be/-hGd2399dnA\nCitation Context: The three-minute video demonstrating the interac-tion capabilities of the system can be viewed at [URL_CITE] https://youtu.be/-hGd2399dnA. (Same video as linked in the paper footnote).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://oracc.museum.upenn.edu/dcclt/\nCitation Context: The process begins with the human expert submitting an unlemmatized transliteration in a format called ATF (ASCII Transliteration For-mat). This format is the standard interchange for-mat for transliteration across many projects dealing in and exchanging Assyriological textual represen-tations (such as CDLI, BDTNS, the Pennsylvania Sumerian Dictionary (PSD, 2006), and Digital Cor-pus of Cuneiform Lexical Texts (DCCLT, 2014) [URL_CITE] ). Via the Emacs interface, the transliteration is sub-mitted to the linguistic annotatation system, which identifies an existing project-specific glossary based on directives provided by the human expert in the transliteration, and returns a preliminary lemmatiza-tion whose completeness and content depends on the referenced project glossary.\nFootnote or Reference text (if exists): DCCLT - Digital Corpus of Cuneiform Lexical Texts. 2014. http://oracc.museum.upenn.edu/dcclt/\nSection Titles (if exists):  ['2 CDLI and the Annotations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/NLPIR-team/NLPIR\nCitation Context: If use the maximum length of all conversations as the input length for en-coders, padding the inputs will lead to a sparse ma-trix. Therefore, for long conversations (with more than 10 messages), we use KLSum (Haghighi and Vanderwende, 2009) to produce summaries with a length of [URL_CITE] messages and then encode the pro-duced summaries. In contrast, we do not sum-marize Twitter conversations because their length range is much narrower (from 4 to 1,035 words).\nFootnote or Reference text (if exists): 10 https://github.com/NLPIR-team/NLPIR\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool:**  The cited resource is a GitHub repository containing code for the NLPIR toolkit. Tools are used in research.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://levyomer.wordpress.com/2014/04/25/dependency-based-word-embeddings/\nCitation Context: 3. Dependency Weights: We use pre-trained vectors [URL_CITE] weighted using dependency distance, as given in Levy and Goldberg (2014). The vocabulary size is 174,015.\nFootnote or Reference text (if exists): 7 https://levyomer.wordpress.com/2014/04/25/dependency-based-word-embeddings/\nSection Titles (if exists):  ['5 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cwc-story.isi.edu\nCitation Context: Nor do they enable iteration; a user cannot revise earlier sen-tences and have the system update later genera-tions. We develop a system [URL_CITE] that allows a user to interact in all of these ways that were limita-tions in previous systems; it enables involvement in planning, editing, iterative revising, and control of novelty. We conduct experiments to understand which types of interaction are most effective for improving stories and for making users satisfied and engaged.\nFootnote or Reference text (if exists): 1 The live demo is at http://cwc-story.isi.edu, with a video at https://youtu.be/-hGd2399dnA. Code and models are available at https://github.com/seraphinatarrant/plan-write-revise.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/IBM/twitter-customer-care-document-prediction\nCitation Context: Two of these datasets are internal: one from an internal customer support service on Mac devices (Mac-Support) and another from an external client in the telecommunication domain (Telco-Support). We also release a new Twitter dataset, containing conversations between users and CC agents in 25 organizations on the Twitter platform [URL_CITE] . We summarize the statistics of the three datasets in Table 2.\nFootnote or Reference text (if exists): 3 The Twitter dataset is available at: https://github.com/IBM/ twitter-customer-care-document-prediction based language models. In Proceedings of the 24th Annual International ACM SIGIR Conference on Re-search and Development in Information Retrieval, tion set of Telco-Support dataset for dialog context se-quence input handling.\nSection Titles (if exists):  ['2 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me break down why:\n\n* **ROLE: Material** - The cited resource is a dataset used in the research. \n* **TYPE: Dataset** - The URL points"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ukp.tu-darmstadt.de/data/edit-classification\nCitation Context: Additional information necessary to reproduce our results, including word lists and training, development and test data, is re-leased online. [URL_CITE] To the best of our knowledge, this is the first approach allowing to classify each single edit in Wikipedia into one or more of 21 different edit categories using a supervised machine learning approach.\nFootnote or Reference text (if exists): 2 http://www.ukp.tu-darmstadt.de/data/ edit-classification\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.icsi.berkeley.edu/~framenet/\nCitation Context: This section presents the semantic role paradigm and the role-annotated corpus on which the present study is based. FrameNet [URL_CITE] is a lexical resource based on Fillmore\u2019s Frame Semantics (Fillmore, 1985). It de-scribes frames, representations of prototypical situa-tions.\nFootnote or Reference text (if exists): 1 http://www.icsi.berkeley.edu/~framenet/\nSection Titles (if exists):  ['2 FrameNet']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://crfpp.sourceforge.net/\nCitation Context: The CRF model we compare with was trained with the CRF++ tool, available at [URL_CITE] http://crfpp.sourceforge.net/. The model is equiva-lent to the one described in (Hahn et al., 2008). As features, we used word and morpho-syntactic cat-egories in a window of [-2, +2] with respect to the current token, plus bigrams of concept tags (see (Hahn et al., 2008) and the CRF++ web site for more details).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Experiments', '5.2 Experimental setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The CRF++ tool is used as a method for training the CRF model, making it a key part of the research"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: Transformers is an ongoing effort maintained by the team of engineers and researchers at Hugging Face with support from a vibrant community of over 400 external contributors. The library is re-leased under the Apache 2.0 license and is available on GitHub . Detailed documentation and tutorials are available on Hugging Face\u2019s website [URL_CITE] .\nFootnote or Reference text (if exists): 2 https://huggingface.co/transformers/ in small details, but need to be in sync with pretraining. (Left) Transformer architectures specialized for different tasks, e.g. understanding versus generation, or for specific use-cases, e.g. speed, image+text. (Top) heads allow a Transformer to be used for different tasks. Here we assume the input token sequence is x 1:N from a vocabulary V, and y represents different possible outputs, possibly from a class set C. Example datasets represent a small subset of example code distributed with the library.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://download.wikipedia.com/zhwiki/20170120/\nCitation Context: The data source is downloaded from the Chi-nese Wikipedia dump of the version January 20th, 2017 [URL_CITE] . Because some Wikipedia pages are not related to entities, we use heuristic rules to fil-ter out disambiguation, redirect, template and list pages.\nFootnote or Reference text (if exists): 8 http://download.wikipedia.com/zhwiki/20170120/\nSection Titles (if exists):  ['6 Experiments', '6.1 Data Source and Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.reddit.com/\nCitation Context: There are a total of 8675 users in this dataset and each user has 45-50 posts. Pan-dora is another dataset collected from Reddit, [URL_CITE] where personality labels are extracted from short descriptions of users with MBTI results to intro-duce themselves. There are dozens to hundreds of posts for each of the 9067 users in this dataset.\nFootnote or Reference text (if exists): 7 https://www.reddit.com/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/facebookresearch/EmpatheticDialogues\nCitation Context: We evaluate our method on E MPATHETIC D IA - LOGUES [URL_CITE] (Rashkin et al., 2018), a dataset that con-tains 24,850 open-domain dyadic conversations be-tween two users, where one responds emphatically to the other. For our experiments, we use the 8:1:1 train/validation/test split, defined by the authors of this dataset.\nFootnote or Reference text (if exists): 1 https://github.com/facebookresearch/ EmpatheticDialogues\nSection Titles (if exists):  ['4 Experimental Settings', '4.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://code.google.com/p/word2vec/\nCitation Context: Our experiments are based on the publicly avail-able word2vec [URL_CITE] and GloVe packages. We mod-ified the original CBOW code to incorporate the CBSOW, CBOM and CBSOWM extensions de-scribed above, and trained models on three En-glish Wikipedia corpora of varying sizes, includ-ing the enwik8 and enwik9 files suggested in the word2vec documentation, containing the first 10 8 and 10 9 characters of a 2006 download, and also a full download from 2009.\nFootnote or Reference text (if exists): 1 https://code.google.com/p/word2vec/\nSection Titles (if exists):  ['4 Training']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/lex4all/lex4all\nCitation Context: We have developed lex4all as a desktop applica-tion for Microsoft Windows, since it relies on the Microsoft Speech Platform (MSP) as explained in Section 4.1. The application and its source code are freely available via GitHub. [URL_CITE]\nFootnote or Reference text (if exists): 6 http://github.com/lex4all/lex4all\nSection Titles (if exists):  ['3 System overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Method\nTYPE: Tool\nFUNCTION: Produce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The citation refers to a tool (the lex4all application) that is directly used in the research (developing"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6214\nCitation Context: Xu et al. (2017) [URL_CITE] provided a set of linguistically-motivated transformations to use TAG derivation trees to solve the PETE task. We follow their pro-cedures and evaluation for our new parsers.\nFootnote or Reference text (if exists): Pauli Xu, Robert Frank, Jungo Kasai, and Owen Rambow. 2017. TAG parser evaluation us-ing textual entailments. In TAG+. Association for Computational Linguistics, Umea\u030a, Sweden, pages 132\u2013141. http://www.aclweb.org/anthology/W17-6214.\nSection Titles (if exists):  ['5 Downstream Tasks', '5.1 PETE']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://lucene.apache.org\nCitation Context: There are many successful frameworks such as S TANFORD C ORE NLP (Manning et al., 2014), NLTK (Bird et al., 2009), and SPA C Y for NLP, L UCENE [URL_CITE] and S OLR for Information Retrieval, and SCIKIT - LEARN , P Y T ORCH and T ENSOR - F LOW (Abadi et al., 2015) for general Machine Learning (ML) with a special focus on Deep Learning (DL), among others. All of these frame-works touch upon several aspects of Machine Reading, but none of them offers dedicated sup-port for modern MR pipelines.\nFootnote or Reference text (if exists): 2 https://lucene.apache.org\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www-nlp.stanford.edu/software/sempre/\nCitation Context: Because there can be more than one answer to a question, precision, recall and F 1 are computed based on the system output for each individual question. The average F 1 score is reported as the main evaluation metric [URL_CITE] .\nFootnote or Reference text (if exists): 6 We used the official evaluation script from http://www-nlp.stanford.edu/software/sempre/.\nSection Titles (if exists):  ['4 Experiments', '4.1 Data & evaluation metric']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The cited resource is a script used to evaluate the system's performance.  Evaluation scripts are tools used in the research process"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://archive.org/download/\nCitation Context: ; \u03c6). All intermediate pre-training is done with input sequence length of 128, batch size of 2048, learning rate of 0.0001, up to a total num-ber of 100, 000 updates, using Wikipedia snapshot from December 20, 2018 [URL_CITE] .\nFootnote or Reference text (if exists): 1 The snapshot is available at https://archive.org/download/enwiki-20181220. Wikipedia is licensed under CC BY-SA 3.0.\nSection Titles (if exists):  ['3 Analysis Setup', '3.1 Experiment Procedure']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mounicam/lexical_simplification\nCitation Context: Additionally, we also produce SimplePPDB++, a lexical resource of over 10 million simplifying paraphrase rules, by ap-plying our model to the Paraphrase Database (PPDB). [URL_CITE]\nFootnote or Reference text (if exists): 1 The code and data are publicly available on the au-thors\u2019 homepages and GitHub: https://github.com/mounicam/lexical_simplification.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dgaddy/silent_speech\nCitation Context: We hope that our public release of data will encourage others to further improve models for this task. [URL_CITE]\nFootnote or Reference text (if exists): 6 Our dataset can be downloaded from https://doi.org/10.5281/zenodo.4064408 and code is available at https://github.com/dgaddy/silent_speech. Samples of predicted outputs can be found in the supplementary material.\nSection Titles (if exists):  ['5 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact based on the provided information:\n\n* **ROLE:**  Mixed \n* **TYPE:** Mixed\n* **FUNCTION:** Use \n\n\n**Explanation:**\n\n* **ROLE: Mixed** - The citation refers"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/marcotcr/checklist\nCitation Context: In this work, we propose CheckList, a new eval-uation methodology and accompanying tool [URL_CITE] for comprehensive behavioral testing of NLP models. CheckList guides users in what to test, by provid-ing a list of linguistic capabilities, which are appli-cable to most tasks.\nFootnote or Reference text (if exists): 1 https://github.com/marcotcr/checklist\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://universaldependencies.github.io/docs/\nCitation Context: We proposed a typed dependency scheme based on the well-known and widely used Stanford typed dependencies (SD), which originated in English and has since been extended to many languages, but not to Japanese. The Universal dependencies (UD) (McDonald et al., 2013; de Marneffe et al., 2014) has been developed based on SD in order to design the cross-linguistically consistent treebank annotation [URL_CITE] . The UD for Japanese has also been discussed, but no treebanks have been provided yet.\nFootnote or Reference text (if exists): 4 http://universaldependencies.github.io/docs/.\nSection Titles (if exists):  ['2 Related work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/nju-websoft/GLRE\nCitation Context: We implemented our GLRE with PyTorch 1.5. The source code and datasets are available online. [URL_CITE] In this section, we report our experimental results.\nFootnote or Reference text (if exists): 1 https://github.com/nju-websoft/GLRE\nSection Titles (if exists):  ['4 Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Method\nTYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/trec-web/trec-web-2014\nCitation Context: In total, there are 300 queries and more than 100k judgments (qrels). Three years (2012\u201314) of query-likelihood baselines provided by T REC [URL_CITE] serve as baseline runs in the R ERANK S IMPLE benchmark. In the R ERANK ALL setting, the search results from runs submitted by participants from each year are also considered: there are 71 (2009), 55 (2010), 62 (2011), 48 (2012), 50 (2013), and 27 (2014) runs.\nFootnote or Reference text (if exists): 5 https://github.com/trec-web/ trec-web-2014\nSection Titles (if exists):  ['3 Evaluation', '3.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.gsk.or.jp/en/catalog//\nCitation Context: 6. We have released a part of it to the public on the web [URL_CITE] .\nFootnote or Reference text (if exists): 4 The corpus data are available at https://www.gsk.or.jp/en/catalog//.\nSection Titles (if exists):  ['4 Data Development']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://bitbucket.org/TomKenter/siamese-cbow\nCitation Context: We use Theano (Theano Development Team, 2016) to implement our network. [URL_CITE] We ran our ex-periments on GPUs in the DAS5 cluster (Bal et al., 2016).\nFootnote or Reference text (if exists): 4 The code for Siamese CBOW is available under an open-source license at https://bitbucket.org/TomKenter/siamese-cbow.\nSection Titles (if exists):  ['3 Experimental Setup', '3.4 Network']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is a tool used in the research to implement the Siamese CBOW network.\n* **TYPE: Code**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://worrydream.com/ExplorableExplanations/\nCitation Context: Ecco provides tools and interactive explorable explanations [URL_CITE] aiding the examination and intuition of:\nFootnote or Reference text (if exists): 3 http://worrydream.com/ExplorableExplanations/ Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/SAG-KeLP\nCitation Context: The Java language has been cho-sen in order to be compatible with many Java NLP/IR tools that are developed by the commu-nity, such as Stanford CoreNLP , OpenNLP or Lucene . K E LP is released as open source soft-ware under the Apache 2.0 license and the source code is available on github [URL_CITE] . Furthermore it can be imported via Maven.\nFootnote or Reference text (if exists): 4 https://github.com/SAG-KeLP\nSection Titles (if exists):  ['2 Framework Overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/stanfordnlp/GloVe\nCitation Context: For all other hyper-parameters, we use the default values of previous implementations. [URL_CITE] For each corpus-algorithm pair, we train k = 32 word embedding models using different random seeds.\nFootnote or Reference text (if exists): 6 For SGNS, we use Gensim 3.8.3 (R\u030cehu\u030ar\u030cek and Sojka, 2010) with a window size of 5, a minimum word count of 5 and 5 iterations. For GloVe, we use the official implemen-tation https://github.com/stanfordnlp/GloVe, with a window size of 15, a minimum word count of 5 and 15 iterations. Because we do not fine-tune hyper-parameters, our results do not necessarily indicate which algorithm itself is of better reliability. To investigate the potential impact of this decision, we also include an explorative study on the influence of hyper-parameters in Appendix E.\nSection Titles (if exists):  ['5 Experiments', '5.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://timex2.mitre.org/tern.html\nCitation Context: Time chunk label: The value of this feature is a B-I-O label indicating whether or not this word is contained in a temporal annotation. The temporal annotations are produced by a word-chunking SVM-based system trained on the temporal ex-pressions (TIMEX2 annotations) in the TERN 2004 data [URL_CITE] . In addition to identifying expres-sions like Monday and this year, the TERN data identifies event-containing expressions like the time she arrived at her doctor's office.\nFootnote or Reference text (if exists): 4 http://timex2.mitre.org/tern.html\nSection Titles (if exists):  ['5 Classifier Features', '5.6 Temporal features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aclweb.org/anthology/N/N16/N16-1148.pdf\nCitation Context: Recently, some attention has also been given to SMT decoding with multiple lexical constraints. The Pick-Revise (PRIMT) (Cheng et al., 2016) [URL_CITE] framework for Interactive Post Editing introduces the concept of edit cycles. Translators specify con-straints by editing a part of the MT output that is incorrect, and then asking the system for a new hypothesis, which must contain the user-provided correction.\nFootnote or Reference text (if exists): Shanbo Cheng, Shujian Huang, Huadong Chen, Xinyu Dai, and Jiajun Chen. 2016. PRIMT: A pick-revise framework for interactive machine trans-lation. In NAACL HLT 2016, The 2016 Con-ference of the North American Chapter of the Association for Computational Linguistics: Hu-man Language Technologies, San Diego Califor-nia, USA, June 12-17, 2016. pages 1240\u20131249. http://aclweb.org/anthology/N/N16/N16-1148.pdf.\nSection Titles (if exists):  ['5 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.clsp.jhu.edu/workshops/18-workshop/\nCitation Context: This work was mostly conducted at the 2018 Fred-erick Jelinek Memorial Summer Workshop on Speech and Language Technologies, [URL_CITE] hosted and sponsored by Johns Hopkins University. Shruti Palaskar received funding from Facebook and Ama-zon grants.\nFootnote or Reference text (if exists): 1 https://www.clsp.jhu.edu/workshops/18-workshop/\nSection Titles (if exists):  ['Acknowledgements']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/software/dependenciesmanual.pdf\nCitation Context: If we consider the dependency graphs output by the Stanford parser as directed (minimally cyclic) graphs, we can define for each node x a set of nodes N x that are reachable from x using a subset of the relations (i.e., edge types) [URL_CITE] . We variously define \u201creachable\u201d in four ways to create four subgraphs defined for each node. These are as follows:\nFootnote or Reference text (if exists): 2 For more information on the relations used in this experi-ment, consult the Stanford Typed Dependencies Manual at http://nlp.stanford.edu/software/dependenciesmanual.pdf\nSection Titles (if exists):  ['3 Answer Grading System', '3.1 Node to Node Matching']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.public.asu.edu/~jye02/Software/MALSAR\nCitation Context: Domain-Specific Models Only LS 77.80 77.88 81.63 84.33 80.41 SVM 78.56 78.66 83.03 84.74 81.25 LR 79.73 80.14 84.54 86.10 82.63 MLP 81.70 81.65 85.45 85.95 83.69 Shared Model Only LS 78.40 79.76 84.67 85.73 82.14 SVM 79.16 80.97 85.15 86.06 82.83 LR 80.05 81.88 85.19 86.56 83.42 MLP 82.40 82.15 85.90 88.20 84.66 MAN-L2-MLP 82.05 83.45 86.45 88.85 85.20 MAN-NLL-MLP 81.85 83.10 85.75 89.10 84.95 Shared-Private Models RMTL 1 81.33 82.18 85.49 87.02 84.01 MTLGraph 2 79.66 81.84 83.69 87.06 83.06 CMSC-LS 3 82.10 82.40 86.12 87.56 84.55 CMSC-SVM 3 82.26 83.48 86.76 88.20 85.18 CMSC-LR 3 81.81 83.73 86.67 88.23 85.11 SP-MLP 82.00 84.05 86.85 87.30 85.05 MAN-L2-SP-MLP ( 82 \u00b10 .46 83.98 87.22* 88.53 85.55* .25) (\u00b10.17) (\u00b10.04) (\u00b10.19) (\u00b10.07) MAN-NLL-SP-MLP 82.98* 84.03 87.06 88.57* 85.66* (\u00b10.28) (\u00b10.16) (\u00b10.23) (\u00b10.15) (\u00b10.14) 1 Evgeniou and Pontil (2004) 2 Zhou et al. (2011) [URL_CITE] 3 Wu and Huang (2015) 3 Zhao et al. (2017)\nFootnote or Reference text (if exists): J. Zhou, J. Chen, and J. Ye. 2011. MAL-SAR: Multi-tAsk Learning via StructurAl Regularization. Arizona State University. http://www.public.asu.edu/\u02dcjye02/Software/MALSAR.\nSection Titles (if exists):  ['3 Theories of Multinomial Adversarial Networks']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pytorch/fairseq\nCitation Context: We query the online API for the first four commercial MT systems, while for the latter two academic models we use the pre-trained models provided by the Fairseq toolkit. [URL_CITE]\nFootnote or Reference text (if exists): 5 https://github.com/pytorch/fairseq\nSection Titles (if exists):  ['3 Evaluation', '3.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/gabedoyle/acl2017\nCitation Context: Per terms of the non-disclosure agreement we signed with the firm, we are not able to share the data underlying the analyses reported below. We can, however, share the code and dummy test data, both of which can be accessed at [URL_CITE] http: //github.com/gabedoyle/acl2017.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Data: Corporate Email Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://jwebpro.sourceforge.net/data-web-snippets.tar.gz\nCitation Context: \u2022 Web Snippet: includes 12340 Web search snippets with 8 categories, we remove the words with fewer than 3 characters and with document frequency less than 3 in the dataset [URL_CITE] .\nFootnote or Reference text (if exists): 3 http://jwebpro.sourceforge.net/data-web-snippets.tar.gz\nSection Titles (if exists):  ['4 Experiments', '4.1 Data and Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://spacy.io/\nCitation Context: For all English processing we will use tools available in the NLTK toolkit (Bird et al., 2009) or SpaCy. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://spacy.io/\nSection Titles (if exists):  ['3 Experimental Framework', '3.3 Tools and Models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.wikipedia.com\nCitation Context: Lan-guage models, and especially transformer-based language models, have shown to contain com-monsense and factual knowledge (Petroni et al., 2019; Jiang et al., 2019). We adopt this direc-tion in our model and build an encoder, pre-trained with Roberta (Liu et al., 2019c), which has been pre-trained on the huge language corpora (e.g., BooksCorpus (Zhu et al., 2015), Wikipedia (Remy, 2002) [URL_CITE] ) to capture implicit knowledge. We tokenize a description Q using WordPiece (Wu et al., 2016) as in BERT (Devlin et al., 2019a), giving us a se-quence of |Q| tokens and embed them with the pre-trained Roberta embeddings and append Roberta\u2019s positional encoding, giving us a sequence of d-dimensional token representation x Q1 , ..., x Q|Q| .\nFootnote or Reference text (if exists): M. Remy. 2002. Wikipedia: The free encyclope-dia200214wikipedia: The free encyclopedia. 2001 \u2013 updated daily. gratis http://www.wikipedia.com.\nSection Titles (if exists):  ['3 Methodology', '3.3 Pre-trained Knowledge Encoder']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://tinyurl.com/joccfqy\nCitation Context: This provides a reasonable upper bound on the performance of any extractor trained on this data. Implementation Details We use CPLEX4 [URL_CITE] to solve the ILP described in Sec. 2.\nFootnote or Reference text (if exists): 11 http://tinyurl.com/joccfqy\nSection Titles (if exists):  ['5 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://babelnet.org\nCitation Context: To cope with these issues, we exploit Babel-Net, [URL_CITE] a huge multilingual semantic network ob-tained from the automatic integration of WordNet, Wikipedia, Wiktionary and other resources (Nav-igli and Ponzetto, 2012), and create the Babel-Net subgraph induced by the WordNet vertices. The result is a graph whose vertices are BabelNet synsets that contain at least one WordNet synset and whose edge set includes all those relations in BabelNet coming either from WordNet itself or from links in other resources mapped to Word-Net (such as hyperlinks in a Wikipedia article con-necting it to other articles). The greatest contribu-tion of syntagmatic relations comes, indeed, from Wikipedia, as its articles are linked to related ar-ticles (e.g., the English Wikipedia Bus article is linked to Passenger, Tourism, Bus lane, Timetable, School, and many more).\nFootnote or Reference text (if exists): 2 http://babelnet.org\nSection Titles (if exists):  ['3 Creating a Denser and Multilingual Semantic Network']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet me explain the reasoning:\n\n* **ROLE: Material** - BabelNet is a semantic network, a type of knowledge resource. It's not a tool used in the research"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://code.google.com/p/thebeast\nCitation Context: MLNs have been applied to many NLP tasks and achieved good performance by leveraging rich re-lations among objects (Poon and Domingos, 2008; Meza-Ruiz and Riedel, 2009; Fahrni and Strube, 2012, inter alia). We use thebeast [URL_CITE] to learn weights for the formulas and to perform inference. thebeast employs cutting plane inference (Riedel, 2008) to improve the accuracy and efficiency of MAP infer-ence for Markov logic.\nFootnote or Reference text (if exists): 5 http://code.google.com/p/thebeast\nSection Titles (if exists):  ['4 Models for Bridging Resolution', '4.2 Markov Logic Networks']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://answers.yahoo.com\nCitation Context: F p denotes 2 phrase-level features, h PP and h PT . For h PP , bilingual data is used to extrac-t a phrase-based translation table (Koehn et al., 2003), from which paraphrases are extracted (Sec-tion 4.2.1). For h PT , GIZA++ trains word align-ments on 4M \u2018question-answer\u2019 pairs crawled from Yahoo Answers [URL_CITE] , and then a phrase ta-ble is extracted from word alignments using the intersect-diag-grow refinement.\nFootnote or Reference text (if exists): 10 https://answers.yahoo.com\nSection Titles (if exists):  ['7 Experiments', '7.1 Evaluation on QA (English)', '7.1.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ofai.at/\nCitation Context: For comparison, we also tested two recently pro-posed approaches to hub reduction: transformation of the base similarity measure (in our case, K) by Mutual Proximity (Schnitzer et al., 2012) [URL_CITE] , and the one (Suzuki et al., 2012) based on graph Laplacian kernels. Since the Laplacian kernels are defined for graph nodes, we computed them by taking the co-sine similarity matrix K as the weighted adjacency (affinity) matrix of a graph. For Laplacian kernels, we computed both the regularized Laplacian ker-nel (Chebotarev and Shamis, 1997; Smola and Kon-dor, 2003) with several parameter values, as well as the commute-time kernel (Saerens et al., 2004), but present only the best results among these kernels.\nFootnote or Reference text (if exists): 2 We used the Matlab script downloaded from http://www.ofai.at/ \u223c dominik.schnitzer/mp/.\nSection Titles (if exists):  ['7 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Tool:** The cited resource is a Matlab script, which is a tool used for implementing the Mutual Proximity algorithm.\n* **TYPE: Code"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/Word_Association\nCitation Context: Word association test is a simple and sometimes entertaining game in which participants are asked to respond with the first several words that come out in their mind (the response) after being pre-sented with a word (the cue) [URL_CITE] . Table 1 lists some examples of the test.\nFootnote or Reference text (if exists): 2 https://en.wikipedia.org/wiki/Word_ Association\nSection Titles (if exists):  ['2 Word Association Test']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/S10-1009\nCitation Context: Finally, we apply our new parsers to the down-stream tasks of Parsing Evaluation using Tex-tual Entailements (PETE, Yuret et al. (2010) [URL_CITE] ) and Unbounded Dependency Recovery (Rimell et al., 2009). We demonstrate that our end-to-end parser outperforms the best results in both tasks.\nFootnote or Reference text (if exists): Deniz Yuret, Aydin Han, and Zehra Turgut. 2010. SemEval-2010 task 12: Parser evaluation using tex-tual entailments. In SemEval. Association for Com-putational Linguistics, Uppsala, Sweden, pages 51\u2013 56. http://www.aclweb.org/anthology/S10-1009.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://open-platform.theguardian.com/\nCitation Context: Input Articles: For each entity from the ground-truth timelines, we search for news articles using TheGuardian API [URL_CITE] . We use this source because it provides access to all published articles starting from 1999.\nFootnote or Reference text (if exists): 7 http://open-platform.theguardian.com/\nSection Titles (if exists):  ['4 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: DataSource\nTYPE: Website\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: DataSource** - The Guardian API is used to retrieve data (news articles) which is then used in the research.  It's a"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/miyyer/rmn\nCitation Context: Parameter settings Across all experiments and corpus-specific models, we set \u03b2=0.99 for MV-Plot, and for both MVPlot and RMN we set \u03b1=0.5, \u03bb=10 \u22125 , k=50. We train both RMN and MVPlot for 15 epochs using SGD and ADAM (Kingma and Ba, 2014). [URL_CITE]\nFootnote or Reference text (if exists): 8 Our implementation builds on the available RMN code https://github.com/miyyer/rmn.\nSection Titles (if exists):  ['6 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cogcomp.cs.illinois.edu/page/software_view/SRL\nCitation Context: The general abstract-anaphora features in the SR feature class capture the semantic role of the can-didate in the candidate sentence. We used the Illinois Semantic Role Labeler [URL_CITE] for SR features. The gen-eral abstract-anaphora features also contain a few lexical features (e.g., M, SC).\nFootnote or Reference text (if exists): 9 http://cogcomp.cs.illinois.edu/page/software_view/SRL\nSection Titles (if exists):  ['4 Resolution Algorithm', '4.2 Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://homepages.inf.ed.ac.uk/s0677528/data.html\nCitation Context: As mentioned earlier, we use the dataset created in Feng and Lapata (2008). [URL_CITE] It contains 3,361 articles that have been downloaded from the BBC News website . Each article contains a news image which in turn is associated with a caption.\nFootnote or Reference text (if exists): 2 Available from http://homepages.inf.ed.ac.uk/s0677528/data.html.\nSection Titles (if exists):  ['3 Problem Formulation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://spacy.io/\nCitation Context: For the former, we take all tokens excluding stop words. [URL_CITE] Together with gender attributes from Caliskan et al. (2017), we calculate and show the\nFootnote or Reference text (if exists): 8 We use spaCy (https://spacy.io/) to tokenize the corpus and remove stop words.\nSection Titles (if exists):  ['3 Detecting Gender Biases in Events']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://academic.research.microsoft.com\nCitation Context: Our second keyphrase dataset comes from the Mi-crosoft Academic (MSRA) search corpus (Mi-crosoft, 2015) [URL_CITE] . While particularly focused on\nFootnote or Reference text (if exists): Microsoft. 2015. Microsoft academic search. http://academic.research.microsoft.com. Accessed: 2015-2-26.\nSection Titles (if exists):  ['4 Overlap with Keyphrase Corpora', '4.2 Microsoft Academic (MSRAC ORPUS )']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/slavpetrov/berkeleyparser\nCitation Context: We choose NIST MT 06 dataset (1664 sentence pairs) as our develop-ment set, and NIST MT 02, 03, 04, and 05 datasets (878, 919, 1788 and 1082 sentence pairs, respec-tively) as our test sets. To get the source syn-tax for sentences on the source-side, we parse the Chinese sentences with Berkeley Parser [URL_CITE] (Petrov and Klein, 2007) trained on Chinese TreeBank 7.0 (Xue et al., 2005). We use the case insensitive 4-gram NIST BLEU score (Papineni et al., 2002) for the translation task.\nFootnote or Reference text (if exists): 6 https://github.com/slavpetrov/ berkeleyparser\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The Berkeley Parser is used as a tool within the research process to obtain source syntax for the Chinese sentences.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://cloud.google.com/sustainability\nCitation Context: As men-tioned in the Google 2019 environment report, 18 \u201cTPUs are highly efficient chips which have been specifically designed for machine learning applica-tions\u201d. These accelerators run on Google Cloud, which has \u201cmatched 100% of its electricity con-sumption with renewable energy purchases, and has committed to fully decarbonize its electricity supply by 2030\u201d ( [URL_CITE] https://cloud.google.com/sustainability). More details on train-ing time are provided in Appendix A.1.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['Ethical Considerations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/JRC1995/Multilingual-BERT-Disaster\nCitation Context: Our code, dataset, and other resources are available on Github. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/JRC1995/ Multilingual-BERT-Disaster\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.18653/v1/P17-1070\nCitation Context: We use a bidirectional LSTM (Hochreiter and Schmidhu-ber, 1997) architecture for sentence classification, with dynamic attention over words for construct-ing the sentence representations. Related archi-tectures have been successful for machine trans-lation (Bahdanau et al., 2015), sentence summa-rization (Rush and Weston, 2015), entailment de-tection (Rockta\u0308schel et al., 2016), and error cor-rection (Ji et al., 2017) [URL_CITE] . In this work, we modify the attention mechanism and training objective in order to make the resulting network suitable for also inferring binary token labels, while still per-forming well as a sentence classifier.\nFootnote or Reference text (if exists): Jianshu Ji, Qinlong Wang, Kristina Toutanova, Yongen Gong, Steven Truong, and Jianfeng Gao. 2017. A Nested Attention Neural Hybrid Model for Gram-matical Error Correction. In ACL 2017. pages 753\u2013762. https://doi.org/10.18653/v1/P17-1070.\nSection Titles (if exists):  ['2 Network Architecture']"
                },
                {
                    "role": "assistant",
                    "content": "Here's a classification of the artifact and citation reason:\n\n* **ROLE:**  Method \n* **TYPE:** Paper\n* **FUNCTION:** Compare \n\n\n**Explanation:**\n\n* **ROLE: Method:** The cited paper presents a specific"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.gstatic.com/gumdrop/sustainability/google-2019-environmental-report.pdf\nCitation Context: Our final models were trained using 64 Google Cloud TPUs for a total of 32 hours. As men-tioned in the Google 2019 environment report, [URL_CITE] \u201cTPUs are highly efficient chips which have been specifically designed for machine learning applica-tions\u201d. These accelerators run on Google Cloud, which has \u201cmatched 100% of its electricity con-sumption with renewable energy purchases, and has committed to fully decarbonize its electricity supply by 2030\u201d (https://cloud.google.com/sustainability).\nFootnote or Reference text (if exists): 18 https://www.gstatic.com/gumdrop/sustainability/google-2019-environmental-report.pdf\nSection Titles (if exists):  ['Ethical Considerations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://webdatacommons.org/webtables\nCitation Context: WDC WebTable Corpus (Lehmberg et al., 2016) is a large collection of Web tables extracted from the Common Crawl Web scrape [URL_CITE] . We use its 2015 English-language relational subset, which consists of 50.8 million relational tables and their surrounding NL contexts.\nFootnote or Reference text (if exists): 10 http://webdatacommons.org/webtables\nSection Titles (if exists):  ['A Pretraining Details', 'A.1 Training Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.wikidata.org/wiki/Wikidata:List_of_properties\nCitation Context: For Freebase we select 5, 000 triples as the validation set, while for Wikidata we use the validation set provided in the transductive setting (5, 136 triples). A.4 W IKI D ISTANT Relation Categories Since W IKI D ISTANT contains 454 relations, their labels are used directly from the WikiData proper-ties [URL_CITE] . Here, we add explanations about the top 10 most frequent categories used in Figures 4c, 4d.\nFootnote or Reference text (if exists): 9 https://www.wikidata.org/wiki/Wikidata: List_of_properties\nSection Titles (if exists):  ['A Appendix', 'A.3 Hyper-parameter Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://leaderboard.allenai.org/orb/submissions/public\nCitation Context: ORB Evaluation Finally, Table 4 shows that our model trained with dynamic sampling and het-erogeneous batches significantly outperforms the previous ORB state-of-the-art NABERT baseline model (submitted on 11/12/2019 on the leader-board site [URL_CITE] ).\nFootnote or Reference text (if exists): 4 https://leaderboard.allenai.org/orb/submissions/ public Language Processing (EMNLP).\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.verify-sy.com\nCitation Context: Claim Extraction We consider two websites as the source of our claims. V ERIFY [URL_CITE] is a project that was established to expose false claims made about the war in Syria and other related Middle Eastern issues. It is an independent platform that debunks claims made by all parties to the conflict.\nFootnote or Reference text (if exists): 4 http://www.verify-sy.com\nSection Titles (if exists):  ['3 The Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1016/j.engappai.2020.103641\nCitation Context: Since it has been proven that sentences that contain few typos, misspellings, or minor character-level errors can be still fully understandable to humans (Belinkov and Bisk, 2018; Xu and Du, 2020 [URL_CITE] ), character-level perturbations are not expected to change the text\u2019s meaning in most cases. Therefore, they can be automatically produced and used for testing the robustness of NLP systems.\nFootnote or Reference text (if exists): Jincheng Xu, and Qingfeng Du. 2020. TextTricker: Loss-based and gradient-based adversarial attacks on text classification models. Engineering Applications of Artificial Intelligence, 92: 103641. https://doi.org/10.1016/j.engappai.2020.103641.\nSection Titles (if exists):  ['5 Experimental results', '5.1 Performance on perturbed inputs']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Paper\nFUNCTION: Compare \n\n\nLet me explain:\n\n* **ROLE: Method** - The cited paper presents a method (TextTricker) for generating adversarial examples for text classification models. This method is likely being"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aclweb.org/anthology/N/N16/N16-1148.pdf\nCitation Context: Pick-Revise is an interaction cycle for MT Post-Editing proposed by Cheng et al. (2016) [URL_CITE] . Starting with the original translation hypothesis, a (sim-ulated) user first picks a part of the hypothesis which is incorrect, and then provides the correct translation for that portion of the output.\nFootnote or Reference text (if exists): Shanbo Cheng, Shujian Huang, Huadong Chen, Xinyu Dai, and Jiajun Chen. 2016. PRIMT: A pick-revise framework for interactive machine trans-lation. In NAACL HLT 2016, The 2016 Con-ference of the North American Chapter of the Association for Computational Linguistics: Hu-man Language Technologies, San Diego Califor-nia, USA, June 12-17, 2016. pages 1240\u20131249. http://aclweb.org/anthology/N/N16/N16-1148.pdf.\nSection Titles (if exists):  ['4 Experiments', '4.1 Pick-Revise for Interactive Post Editing']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: http://www.dh.uni-leipzig.de/wo/projects/open-greek-and-latin-project/\nCitation Context: Due to availability of digitised epigraphic corpora, P YTHIA has been trained on ancient Greek (hence-forth, \"AG\") inscriptions, written in the ancient Greek language between 7 th century BCE and 5 th century CE. We chose AG epigraphy as a case study for two reasons: a) the variability of contents and context of the AG epigraphic record makes it an excellent challenge for NLP; b) several digital AG textual corpora have been recently created, the largest ones being PHI (The Packard Humanities Institute, 2005; Gawlinski, 2017) for epigraphy; Perseus (Smith et al., 2000) and First1KGreek (Crane et al., 2014) [URL_CITE] for ancient literary texts.\nFootnote or Reference text (if exists): Gregory Ralph Crane, Monica Berti, Annette Ge\u00dfner, Matthew Munson, and Tabea Selle. 2014. Open greek and latin project. http://www.dh.uni-leipzig.de/wo/projects/open-greek-and-latin-project/. Ac-cessed on 2019-04-24.\nSection Titles (if exists): [\\'3 Generating PHI-ML\\']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://opennlp.apache.org/\nCitation Context: K E LP is a machine learning library completely written in Java. The Java language has been cho-sen in order to be compatible with many Java NLP/IR tools that are developed by the commu-nity, such as Stanford CoreNLP , OpenNLP [URL_CITE] or Lucene . K E LP is released as open source soft-ware under the Apache 2.0 license and the source code is available on github .\nFootnote or Reference text (if exists): 2 https://opennlp.apache.org/\nSection Titles (if exists):  ['2 Framework Overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Tool\nTYPE:  Tool\nFUNCTION: Introduce \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ybz79/AMR2text\nCitation Context: As for batch size, we use 80 for LDC2015E86 and 120 for LDC2017T10. [URL_CITE]\nFootnote or Reference text (if exists): 3 Our code is available at https://github.com/ybz79/AMR2text\nSection Titles (if exists):  ['4 Experiments', '4.1 Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/DeepLearnXMU/NSEG\nCitation Context: The recommended hyper-parameter configuration of the model on each dataset are presented in Table 3. To diminish the effects of randomness in training, the results of our model are averaged with [URL_CITE] random initializa-tions. For data preprocessing, we use the tok-enizer 6 from BERT to preprocess the sentences.\nFootnote or Reference text (if exists): 5 Code for metrics: https://github.com/DeepLearnXMU/NSEG\nSection Titles (if exists):  ['3 Experiments', '3.3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hub.microsofttranslator.com\nCitation Context: To improve the translation quality for terms like clutch, we used an interface provided by a third party machine translation service [URL_CITE] to train a cus-tom MT engine for English to French translations. To validate that the retrained MT systems were materially improved, we used a two step valida-tion process, first using crowd-sourced evaluations with Amazon\u2019s Mechanical Turk, and secondly us-ing A/B testing, a way of conducting randomized experiments on web sites, to measure the effect of the trained system on user behavior.\nFootnote or Reference text (if exists): 2 http://hub.microsofttranslator.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Tool\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The resource is a tool used in the research process (a machine translation service). \n* **TYPE:"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/WeimingWen/CCRV\nCitation Context: We published our code and dataset on GitHub [URL_CITE] .\nFootnote or Reference text (if exists): 1 https://github.com/WeimingWen/CCRV\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://search.cpan.org/~snowhare/Lingua-Stem-0.83\nCitation Context: \u2022 All above features and their stems. [URL_CITE] (All-Words-Stemmed)\nFootnote or Reference text (if exists): 7 To obtain stemmed words, we use the CPAN package: http://search.cpan.org/~snowhare/Lingua-Stem-0.83.\nSection Titles (if exists):  ['6 Local Lexical Context']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dcs.shef.ac.uk/nlp/meter\nCitation Context: A prototype browser-based demo of both the GST algorithm and alignment program, allow-ing users to test arbitrary text pairs for simi-larity, is now available [URL_CITE] and will continue to be enhanced. helpful comments on earlier drafts.\nFootnote or Reference text (if exists): 4 See http://www.dcs.shef.ac.uk/nlp/meter.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a demo and information about a tool (GST algorithm and alignment program). It's supplementary material"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.iptc.org\nCitation Context: We suggest the we adopt text categorization on top of topic detection and tracking, similar to Figure 3. There has been good results in text categorization (see, e.g., (Yang and Liu, 1999; Sebastiani, 2002)) The pre-defined categories would form the static hierarchy \u2013 the IPTC Subject Reference System [URL_CITE] , for example \u2013 on top of all event-based information organization, and the mod-els for the categories could be built on the basis of the test set.\nFootnote or Reference text (if exists): 2 International Press Telecommunications Council, http://www.iptc.org\nSection Titles (if exists):  ['5 Dynamic Hierarchies']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://amr.isi.edu/download.html\nCitation Context: Annotating natural language with AMR is a complex task and training datasets only exist for English [URL_CITE] , so previous work on AMR-to-text gen-eration has overwhelmingly focused on English. We create training data for multilingual AMR-to- Text models, by taking the EUROPARL multilin-gual corpus and automatically annotating the En-glish data with AMRs using the jamr semantic parser.\nFootnote or Reference text (if exists): 1 AMR datasets from the LDC can be found at https://amr.isi.edu/download.html\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: For experimental evaluation of the proposed method we use the publicly available Multi-Perspective Question Answering (MPQA) [URL_CITE] corpus (Wiebe et al., 2005) version 1.2, which contains 535 newswire documents that are manually annotated with phrase-level subjectivity and intensity. We use the expression-level boundary markings in MPQA to extract phrases.\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['3 Experimental Methodology']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.clg.ox.ac.uk/tedcorpus\nCitation Context: There are one or more such keywords asso-ciated with each talk but only the 15 most frequent keywords across all documents are considered as class labels. We used the same pre-processed splits [URL_CITE] as provided by (Hermann and Blunsom, 2014b). The training corpus consists of a total of 12,078 par-allel documents distributed across 12 language pairs.\nFootnote or Reference text (if exists): 1 http://www.clg.ox.ac.uk/tedcorpus\nSection Titles (if exists):  ['4 Datasets', '4.1 Multlingual TED corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/wmaier/rparse\nCitation Context: We run further experiments with rparse [URL_CITE] (Kallmeyer and Maier, 2013) to facilitate a com-parison with a grammar-based parser.\nFootnote or Reference text (if exists): 5 http://github.com/wmaier/rparse\nSection Titles (if exists):  ['3 Experiments', '3.2 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://zhidao.baidu.com/\nCitation Context: Community Question Answering (cQA) services like Yahoo! Answers , Baidu Zhidao [URL_CITE] , Quora , StackOverflow etc. provide a platform for interaction with experts and help users to obtain precise and accurate answers to their questions.\nFootnote or Reference text (if exists): 2 http://zhidao.baidu.com/\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mounicam/lexical_simplification\nCitation Context: Additionally, we also produce SimplePPDB++, a lexical resource of over 10 million simplifying paraphrase rules, by ap-plying our model to the Paraphrase Database (PPDB). [URL_CITE]\nFootnote or Reference text (if exists): 1 The code and data are publicly available on the au-thors\u2019 homepages and GitHub: https://github.com/mounicam/lexical_simplification.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlm.nih.gov/research/umls\nCitation Context: To evaluate the quality of terminology extrac-tion, we built a bilingual terminology reference list for each comparable corpus. We selected all French/English single words from the UMLS [URL_CITE] meta-thesaurus. We kept only i) the French sin-gle words which occur more than four times in the French part and ii) the English single words which occur more than four times in each English part i .\nFootnote or Reference text (if exists): 6 http://www.nlm.nih.gov/research/umls\nSection Titles (if exists):  ['3 Linguistic Resources', '3.3 Terminology Reference Lists']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://statnlp.org/tutorials/\nCitation Context: This tutorial consists of the following 3 main sections. [URL_CITE]\nFootnote or Reference text (if exists): 2 The material associated with this tutorial will be avail-able at http://statnlp.org/tutorials/.\nSection Titles (if exists):  ['-']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a website that provides supplementary material (tutorials) related to the main text. It's not"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/thunlp/CodRED\nCitation Context: We conduct comprehensive ex-periments to show that CodRED is challeng-ing to existing RE methods including strong BERT-based models. We make CodRED and the code for our baselines publicly available at [URL_CITE] https://github.com/thunlp/CodRED.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huashiyiqike/TMBP/tree/master/DocNADE\nCitation Context: \u2022 DocNADE (Larochelle and Lauly, 2012b). An unsupervised neural network topic model of documents and has shown that it is a com-petitive model both as a generative model and as a document representation learning algo-rithm [URL_CITE] . In DocNADE, the hidden size is 50, the learning rate is 0.0004 , the bath size is 64 and the max training number is 50000.\nFootnote or Reference text (if exists): 6 https://github.com/huashiyiqike/TMBP/tree/master/DocN ADE\nSection Titles (if exists):  ['4 Experiments', '4.1 Data and Setting']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf\nCitation Context: Soft attention has firstly been used for syntactic constituency parsing by Vinyals et al. (2015) [URL_CITE] but has been widely used for translation tasks ever since. One should note that it slightly differs from Bahdanau et al.\nFootnote or Reference text (if exists): Oriol Vinyals, \u0141 ukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. 2015. Gram-mar as a foreign language. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, Curran Associates, Inc., pages 2773\u2013 2781. http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf.\nSection Titles (if exists):  ['3 Attention-based Models', '3.1 Soft attention']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use \n\n\nLet me break down why:\n\n* **ROLE: Supplement** - The cited paper is directly referenced and discussed within the text, providing additional context and background information about soft attention.\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/bleurt\nCitation Context: We compare to BLEURT (Sellam et al., 2020) using the authors\u2019 recommended \u201cBLEURT-Base 128\u201d [URL_CITE] We compare to BERTscore F1 (Zhang et al., 2020) using the model and code provided by the authors.\nFootnote or Reference text (if exists): 12 https://github.com/google-research/bleurt\nSection Titles (if exists):  ['C.5 Baselines']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://peir.path.uab.edu/library/\nCitation Context: PEIR Gross The Pathology Education Informa-tional Resource (PEIR) digital library [URL_CITE] is a pub-lic medical image library for medical education. We collected the images together with their de-scriptions in the Gross sub-collection, resulting in the PEIR Gross dataset that contains 7,442 image-caption pairs from 21 different sub-categories.\nFootnote or Reference text (if exists): 3 PEIR is c University of Alabama at Birmingham, De-partment of Pathology. (http://peir.path.uab.edu/library/)\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PlusLabNLP/ee-wiki-bias\nCitation Context: To facilitate the study, we collect a corpus that contains demographic information, personal life de-scription, and career description from Wikipedia. [URL_CITE] We first detect events in the collected corpus using a state-of-the-art event extraction model (Han et al., 2019). Then, we extract gender-distinct events with a higher chance to occur for one group than the other.\nFootnote or Reference text (if exists): 2 https://github.com/PlusLabNLP/ ee-wiki-bias\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a corpus of Wikipedia data specifically collected for studying gender bias in events. This aligns with the \""
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://badaa.mngl.net/docs.php?p=trans_table\nCitation Context: We romanize all the Katakana words in the dictionary and index them using consecutive N 1 [URL_CITE] http://badaa.mngl.net/docs.php?p=trans_table (May, 2006) characters. We also romanize each candidate loanword when use as a query. We experimentally set N = 2, and use the Okapi BM25 (Robertson et al., 1995) for the retrieval model.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Methodology', '3.6 N-gram retrieval']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.wikidata.org\nCitation Context: There are custom solutions that can easily simplify the slot filling task. For instance, subject entities can be used for lookups by title in Wikipedia to retrieve knowledge (this heuristic will always work for zsRE), and structured human-curated resources (such as Wikidata [URL_CITE] ) could be used to get all an-swers right. Nevertheless, we are interested in test-ing if a general model can extract attributes about specific entities from a large body of text.\nFootnote or Reference text (if exists): 13 https://www.wikidata.org\nSection Titles (if exists):  ['8 Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www2.crl.go.jp/jt/a132/members/mutiyama/software.html\nCitation Context: When we use SVM, we have to choose a good linear kernel ( = 6 kernel for better performance &? [URL_CITE] C ? .)\nFootnote or Reference text (if exists): 6 http://www2.crl.go.jp/jt/a132/members/mutiyama/software. html\nSection Titles (if exists):  ['3 Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Tool\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Tool:** The citation refers to software related to SVM (Support Vector Machine), a machine learning algorithm. Tools are often used in"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://aclweb.org/anthology/D16-1264\nCitation Context: It has been hypothesized that difficult MRC problems re-quire some form of multi-step synthesis and rea-soning. For instance, the following example from the MRC dataset SQuAD (Rajpurkar et al., 2016) [URL_CITE] illustrates the need for synthesis of information across sentences and multiple steps of reasoning:\nFootnote or Reference text (if exists): Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text pages 2383\u20132392. https://aclweb.org/anthology/D16-1264.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/P16-1231\nCitation Context: Andor et al. (2016) [URL_CITE] developed a transition-based parser using feed-forward neural networks that performs global training approximated by beam search. The globally normalized objective ad-dresses the label bias problem and makes global training effective in the transition-based parsing setting.\nFootnote or Reference text (if exists): Daniel Andor, Chris Alberti, David Weiss, Aliak-sei Severyn, Alessandro Presta, Kuzman Ganchev, Slav Petrov, and Michael Collins. 2016. Glob-ally normalized transition-based neural networks. In ACL. Association for Computational Linguistics, Berlin, Germany, pages 2442\u20132452. http://www.aclweb.org/anthology/P16-1231.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/RishabhMaheshwary/query-attack\nCitation Context: Also, all the past works evaluate their search methods only on a single search space. In this paper [URL_CITE] , we address the above discussed drawbacks through following contributions:\nFootnote or Reference text (if exists): 1 Code and adversarial examples available at: https://github.com/RishabhMaheshwary/query-attack\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being used as a tool to implement and evaluate the search methods discussed in the paper. \n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://keras.io\nCitation Context: Our model was implemented in Keras [URL_CITE] . Although not common in most deep-learning approaches, we performed 10-fold cross-validation (CV) to obtain a more reliable estimation for our model\u2019s perfor-mance.\nFootnote or Reference text (if exists): 7 https://keras.io\nSection Titles (if exists):  ['5 Experimental Setup', '5.1 Model Implementation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/cookielee77/CLARE\nCitation Context: Our analysis further suggests that the CLARE can be used to improve the robustness of the down-stream models, and improve their accuracy when the available training data is limited. We release our code and models at [URL_CITE] https://github.com/cookielee77/CLARE.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/duyvuleo/Mantidae\nCitation Context: NMT Models. We implemented our continuous-optimisation based decoding method on top of the Mantidae toolkit [URL_CITE] (Cohn et al., 2016), and using the dynet deep learning library (Neubig et al., 2017). All neural network models were configured with 512 input embedding and hidden layer dimensions, and 256 alignment dimension, with 1 and 2 hidden layers in the source and target, respectively.\nFootnote or Reference text (if exists): 4 https://github.com/duyvuleo/Mantidae\nSection Titles (if exists):  ['5 Experiments', '5.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify! \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlm.nih.gov/mesh/meshhome.html\nCitation Context: The MeSH layer contains entities from the hier-archical medical ontology MeSH (Medical Subject Headings). [URL_CITE] The MeSH annotations on Figure 1 are overlapping (share the word cell) and hierarchical both ways: spanning, since blood cell (with MeSH id D001773) orthographically spans the word cell (id A11), and ontologically, since blood cell is a kind of cell and cell death (id D016923) is a kind of Bio-logical Phenomena.\nFootnote or Reference text (if exists): 8 http://www.nlm.nih.gov/mesh/meshhome.html\nSection Titles (if exists):  ['3 The Layered Query Language']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://scikit-learn.org/\nCitation Context: Each processing level is independent and can deal with the peculiarities of its type of feature. Machine learning Q U E ST ++ provides scripts to interface the Python toolkit scikit-learn [URL_CITE] (Pedregosa et al., ). This module is indepen-dent from the feature extraction code and uses the extracted feature sets to build and test QE models.\nFootnote or Reference text (if exists): 3 http://scikit-learn.org/\nSection Titles (if exists):  ['2 Architecture']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.w3.org/TR/pronunciation-lexicon/\nCitation Context: Once pronunciations for all terms in the vocab-ulary have been generated, the application outputs a pronunciation lexicon for the given terms as an XML file conforming to the Pronunciation Lexi-con Specification. [URL_CITE] This lexicon can then be di-rectly included in a speech recognition application built using the MSP API or a similar toolkit.\nFootnote or Reference text (if exists): 7 http://www.w3.org/TR/pronunciation-lexicon/\nSection Titles (if exists):  ['3 System overview']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE:  Supplement\nTYPE: Document\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://weiboscope.jmsc.hku.hk/datazip/\nCitation Context: Because no sophisticated tool for Chinese short text is available, we implement our own tool that is greedy for high precision. We train En-glish and Chinese monolingual word embedding respectively using word2vec\u2019s skip-gram method with a window size of [URL_CITE] (Mikolov et al., 2013b).\nFootnote or Reference text (if exists): 5 http://weiboscope.jmsc.hku.hk/datazip/\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://qwone.com/~jason/20Newsgroups/\nCitation Context: For both datasets we use 20 topics; which gives best NPMI out of 20, 50, 100 topics for Reuters, and is the ground truth number for 20NG. The NPMI scores presented in Table 1 are averaged across cluster centers initialized using [URL_CITE] random seeds.\nFootnote or Reference text (if exists): 5 http://qwone.com/\u02dcjason/20Newsgroups/ 6 https://www.nltk.org/book/ch02.html\nSection Titles (if exists):  ['4 Computational Complexity']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/allenai/label_rationale_association\nCitation Context: Via two tests, robustness equivalence and feature importance agreement, we find that state-of-the-art T5-based joint models exhibit desir-able properties for explaining commonsense question-answering and natural language infer-ence, indicating their potential for producing faithful free-text rationales. [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code is available at https://github.com/allenai/label_rationale_association.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being presented as a tool used in the research, specifically for implementing and evaluating the models.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://encarta.msn.com/default.asp\nCitation Context: For each of the words, we extracted about 200 sentences containing the word from the Encarta [URL_CITE] English corpus and labeled those sentences with Chinese translations ourselves. We used the labeled sentences as test data and the remaining sentences as unclassified data in English.\nFootnote or Reference text (if exists): 4 http://encarta.msn.com/default.asp\nSection Titles (if exists):  ['5 Word Translation Disambiguation', '6.2 Experiment 2: Yarowsky\u2019s Words']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/neural-dialogue-metrics/rouge\nCitation Context: In addition, we also use a ROUGE evaluation library [URL_CITE] https://github.com/neural-dialogue-metrics/rouge , which supports the evaluation of ROUGE series metrics (ROUGE-N, ROUGE-L and ROUGE-W).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['A Appendices', 'A.1 Hierarchical Fusion Decoder']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.babelnet.org/\nCitation Context: Throughout the paper, by a concept we mean a tuple b = (p, s) where p is a Wikipedia page and s is the corresponding WordNet synset. As a bridge between the two resources we use the synset-to-article mappings provided by BabelNet [URL_CITE] (Navigli and Ponzetto, 2012), a high coverage mul-tilingual encyclopedic dictionary and semantic net-work that merges, among other resources, Wikipedia and WordNet. Note that the concept b can also con-tain a Wikipedia page or a WordNet synset only, if a mapping is not provided by BabelNet.\nFootnote or Reference text (if exists): 1 http://www.babelnet.org/\nSection Titles (if exists):  ['2 Semantic Representation of Concepts']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - BabelNet is providing a structured knowledge base (mappings between Wikipedia and WordNet) that the authors are using in"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cs.umd.edu/miyyer/qblearn/\nCitation Context: LSTMs have re-cently achieved state-of-the-art results in a vari-ety of tasks due to their ability to model long-term context information as opposed to other neu-ral networks based techniques. (5) The fifth base-line (called QANTA) [URL_CITE] is taken from Iyyer et al. (2014).\nFootnote or Reference text (if exists): 6 http://cs.umd.edu/miyyer/qblearn/\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/Tom556/OrthogonalTransformerProbing\nCitation Context: This approach assumes that the representations are isomorphic across lan-guages; we examine this claim in our experiments. Our implementation is available at GitHub: [URL_CITE] https://github.com/Tom556/OrthogonalTransformerProbing.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Method']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.tensorflow.org/hub/modules/google/elmo/1\nCitation Context: ELMo embeddings are essen-tially the internal states of a deep LSTM-based language model, pre-trained on a large text cor-pus. We used the 1024-d pre-trained models [URL_CITE] for two configurations: ELMo 1 , the first LSTM hid-den state, and ELMo 3 , the weighted sum of the 3 layers of LSTM. A more recent contextualized model is BERT (Devlin et al., 2019).\nFootnote or Reference text (if exists): 8 https://www.tensorflow.org/hub/modules/google/elmo/1\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use \n\n\nLet me break down why:\n\n* **ROLE: Material** - ELMo embeddings are a pre-trained knowledge representation (the internal states of a language model). They are not a"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1145/3374217\nCitation Context: However, adversarial perturbations are considered worst-case scenarios that do not occur frequently in real-world situations, representing a very specific type of noise (Fawzi et al., 2016). In order to generate effective adversarial examples, most attack methods need to have access to the NLP model structure, internal weights, and hyperparameters, which may not be possible in every testing scenario (Zhang et al., 2020) [URL_CITE] . Furthermore, adversarial perturbations should not be perceived by humans (Liang et al., 2018).\nFootnote or Reference text (if exists): Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial Attacks on Deep-learning Models in Natural Language Processing: A Survey. ACM Trans. Intell. Syst. Technol., 11(3): Article 24. https://doi.org/10.1145/3374217. Max sequence length 64 64 Batch size 12 12 Learning rate 2e-5 1e-5 Num epochs 20 15 Classification, SA: Sentiment Analysis, QA: Question Answering, NER: Named Entity Recognition, SS: Semantic Similarity.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.youtube.com/watch?v=Efsl1ZMWFkE\nCitation Context: Next, we describe the salient MTTR features along with the underlying NLP & Speech tech-nologies, where appropriate. A video illustrating most of the user-facing features in action is cur-rently available at [URL_CITE] https://www.youtube.com/watch?v=Efsl1ZMWFkE.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 My Turn To Read App']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/machelreid/afromt\nCitation Context: All code and pre-trained models will be released as further steps towards larger reproducible benchmarks for African languages. [URL_CITE]\nFootnote or Reference text (if exists): 1 Source code, pretrained models, and data can be found at https://github.com/machelreid/afromt\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being presented as a tool or resource used in the research, likely for training or evaluating models.\n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/\nCitation Context: Training Details Word embeddings were pre-trained with the Gensim [URL_CITE] implementation of word2vec (Mikolov et al., 2013) on the English GigaWord corpus (with case left intact). The di-mensionality of the word embeddings was set to 50.\nFootnote or Reference text (if exists): 2 https://radimrehurek.com/gensim/\nSection Titles (if exists):  ['5 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/NLPIR-team/NLPIR\nCitation Context: Chinese texts are tokenized with Jieba (Jieba, 2017) or NLPIR (NLPIR, 2018) [URL_CITE] . 300-dimensional word vectors are trained on our insurance corpus.\nFootnote or Reference text (if exists): NLPIR. 2018. https://github.com/NLPIR-team/NLPIR. Accessed: 2018-05- 28.\nSection Titles (if exists):  ['5 Experiments', '5.2 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/qingsongma/percentage-refBias\nCitation Context: Table 2 shows proportions of all judge pairs with significant differences in Kappa point esti-mates (non-overlapping confidence intervals) for each combination of settings (Revelle, 2014). [URL_CITE] The number of significant differences in Kappa point estimates for pairs of judges in SAME and DIFF is only 13%, or, in other words, 87% of judge pairs across SAME and DIFF have no significant difference in agreement levels. Table 2 also in-cludes proportions of significant differences for Kappa point estimates resulting from judges be-longing to a single setting (significance testing all Kappa of SAME with respect to all other Kappa be-longing to SAME , for example), revealing that the proportion of significant differences within SAME (12%) to be very similar to that of SAME \u00d7 DIFF (13%), and similarly for DIFF (12%), with only a single percentage point difference in both cases in proportions of significant differences.\nFootnote or Reference text (if exists): 7 Our re-analysis code is available at https://github.com/qingsongma/percentage-refBias\nSection Titles (if exists):  ['2 Background', '2.1 Measures of Central Tendency']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The code is not the primary focus of the research, but it provides additional information and allows others to reproduce the analysis"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ChunchuanLv/Iterative_Inference\nCitation Context: Furthermore, we provide analysis on con-straint violations and errors on the English test set. [URL_CITE]\nFootnote or Reference text (if exists): 2 The code and experiment settings can be ac-cessed at https://github.com/ChunchuanLv/ Iterative_Inference\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.hlt.utdallas.edu/\u223cady\nCitation Context: However, the utilization of the ACE corpus for the task of solving event coreference is lim-ited because this resource provides only within-document event coreference annotations using a restricted set of event types such as LIFE , BUSI - NESS , CONFLICT , and JUSTICE . Therefore, as a second dataset, we created the EventCorefBank (ECB) corpus [URL_CITE] to increase the diversity of event types and to be able to evaluate our models for both within- and cross-document event corefer-ence resolution. One important step in the cre-ation process of this corpus consists in finding sets of related documents that describe the same semi-nal event such that the annotation of coreferential event mentions across documents is possible.\nFootnote or Reference text (if exists): 6 ECB is available at http://www.hlt.utdallas.edu/\u223cady.\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tensorflow/models/tree/master/official/nlp/bert\nCitation Context: (2019). [URL_CITE] Ta-ble 1 shows that using the official code to train BERT BASE could take almost 6 days under our hard-ware assumptions (Section 2), and a large model might require close to a month of non-stop compu-tation. In contrast, our recipe significantly speeds up training, allowing one to train BERT LARGE with the original number of steps (1M) in a third of the time (8 days), or converge in 2-3 days by enlarging the batch size.\nFootnote or Reference text (if exists): 3 https://github.com/tensorflow/models/tree/master/official/nlp/bert\nSection Titles (if exists):  ['3 Combining Efficient Training Methods', '3.2 Combined Speedup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being used as a tool to train BERT, making it a method in the research process.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hierplane.allenai.org/explain/stanford/\nCitation Context: For instance: [URL_CITE] http://hierplane.allenai.org/explain/stanford/ He%20ate%20pasta%20with% 20chopsticks\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 APIs', '4.1 Basic Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jhclark/ducttape\nCitation Context: The toolkit that seems to be most similar to our approach is Ducttape [URL_CITE] , the successor of LonnyBin (Clark and Lavie, 2010). It is well designed and covers many useful points.\nFootnote or Reference text (if exists): 2 https://github.com/jhclark/ducttape\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/DeepLearnXMU/NSEG\nCitation Context: The experiments are conducted on six public datasets in different domains: NIPS abstract, AAN abstract, NSF abstract, arXiv abstract: These datasets contain ab-stracts of research papers. NIPS abstract [URL_CITE] is from conference papers in NIPS, where pa-pers in years 2005-2013/2014/2015 for train-ing/validation/testing (Logeswaran et al., 2018). AAN abstract (Logeswaran et al., 2018) is col-lected from ACL Anthology Network corpus.\nFootnote or Reference text (if exists): 1 https://github.com/DeepLearnXMU/NSEG\nSection Titles (if exists):  ['3 Experiments', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a collection of abstracts, which falls under the category of datasets.\n* **TYPE: Dataset"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.ox.ac.uk/activities/CompDistMeaning/GS2011data.txt\nCitation Context: The dataset contains 2500 similarity judgements, provided by 25 participants, and is pub-licly available. [URL_CITE]\nFootnote or Reference text (if exists): 6 http://www.cs.ox.ac.uk/activities/CompDistMeaning/GS2011data.txt\nSection Titles (if exists):  ['5 Evaluation', '5.1 Methodology']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tingyaohsu/VIST-Edit\nCitation Context: We introduce the first dataset for human edits of machine-generated visual stories and ex-plore how these collected edits may be used for the visual story post-editing task. The dataset, VIST-Edit [URL_CITE] , includes 14,905 human-edited versions of 2,981 machine-generated visual stories. The stories were generated by two state-of-the-art visual storytelling models, each aligned to 5 human-edited versions.\nFootnote or Reference text (if exists): 1 VIST-Edit: https://github.com/tingyaohsu/VIST-Edit using human-written stories as references. All the au-tomatic evaluation metrics generate lower scores even when the editing was done by human.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ankara.lti.cs.cmu.edu/side/video.swf\nCitation Context: In this type-II demo, we introduce SIDE [URL_CITE] (the Summarization Integrated Development Envi-ronment), an infrastructure that facilitates construction of summaries tailored to the needs of the user. It aims to address the issue that there is no such thing as the perfect sum-mary for all purposes.\nFootnote or Reference text (if exists): 1 The working system can be downloaded from http://www.cs.cmu.edu/~cprose/SIDE.html, and a video of an example of SIDE use can be found at http://ankara.lti.cs.cmu.edu/side/video.swf. This project is supported by ONR Cognitive and Neural Sciences Division, Grant number N000140510043\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Media\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The video is supplementary material demonstrating the SIDE system. It's not a core component of the research itself, but"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf\nCitation Context: However, it cannot fully take advantage the training data if it comes from multiple source domains. MS,ST adaptation (Mansour et al., 2009 [URL_CITE] ; Zhao et al., 2017) can deal with multiple source domains but only transfers to a single target domain. Therefore, when multiple target domains exist, they need to treat them as independent prob-lems, which is more expensive and cannot utilize the additional unlabeled data in these domains.\nFootnote or Reference text (if exists): Yishay Mansour, Mehryar Mohri, and Afshin Ros-tamizadeh. 2009. Domain adaptation with multiple sources. In Advances in Neural Information Processing Systems 21, Curran Associates, Inc., pages 1041\u20131048. http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/malllabiisc/pra-oda\nCitation Context: Our experiments sug-gest that ODA provides better performance than (Gardner et al., 2013) and nearly the same pre-diction performance as provided by (Gardner et al., 2014), but in both cases with the added ad-vantage of faster running time and greater flex-ibility due to its online and on-demand nature. The code along with the results can be obtained at [URL_CITE] https://github.com/malllabiisc/pra-oda.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.ffzg.hr/resources/corpora/setimes/\nCitation Context: Much of our data comes from WikiMatrix (Schwenk et al., 2019), a large collection of parallel data extracted from Wikipedia, and for more domain variety, we added Global Voices, EuroParl (Koehn, 2005) (random subset of to 100k sentence pairs per language pair), SETimes, [URL_CITE] United Nations (Eisele and Chen, 2010) (random sample of 1M sentence pairs per language pair). We also included WMT Kazakh\u2013English and Kazakh\u2013Russian data from WMT, to be able to evaluate on Kazakh.\nFootnote or Reference text (if exists): 11 http://nlp.ffzg.hr/resources/corpora/setimes/\nSection Titles (if exists):  ['B Data Details for Replication']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.uexpress.com/dearabby/archives\nCitation Context: We use a situation to denote the one-sentence prompt given to a worker as the basis for writ-ing RoTs. We gather a total of 104k real life situations from four domains: scraped titles of posts in the subreddits r/confessions (32k) and r/amitheasshole (r/AITA, 30k), which largely focus on moral quandaries and interper-sonal conflicts; 30k sentences from the ROCSto-ries corpus (rocstories, Mostafazadeh et al., 2016); and scraped titles from the Dear Abby ad-vice column archives [URL_CITE] (dearabby, 12k).\nFootnote or Reference text (if exists): 3 https://www.uexpress.com/dearabby/archives\nSection Titles (if exists):  ['3 S OCIAL -C HEM -101 Dataset', '3.1 Situations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.chasen.org/~taku/software/TinySVM/\nCitation Context: One-versus-rest method is used for multi-class classification. To perform training and testing with SVMs, we use TinySVM [URL_CITE] with a linear-kernel, and one-versus-rest is used for multi-class classification. We used the cost of constraint vio-lation C = 1.\nFootnote or Reference text (if exists): 2 http://www.chasen.org/\u02dctaku/software/TinySVM/\nSection Titles (if exists):  ['4 Experiments', '4.2 Experimental settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://trec.nist.gov/tracks.html\nCitation Context: We rely on the widely-used 2009\u20132014 T REC Web Track ad-hoc task benchmarks [URL_CITE] . The benchmarks are based on the C LUE W EB 09 and C LUE W EB 12 datasets as document collections.\nFootnote or Reference text (if exists): 3 http://trec.nist.gov/tracks.html\nSection Titles (if exists):  ['3 Evaluation', '3.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://manikvarma.org/downloads/XC/XMLRepository.html\nCitation Context: Dataset. Our experiments are conducted on six extreme multi-label datasets and their character-istics are shown in Table 1, among which IMDb is crawled from online movie database and the rest five datasets are downloaded from the extreme classification repository [URL_CITE] . For datasets from the repository, we adopt the provided train/test split, and for IMDb we randomly choose 20% of the data as test set and the rest of 80% as training set.\nFootnote or Reference text (if exists): 3 http://manikvarma.org/downloads/XC/XMLRepository.html\nSection Titles (if exists):  ['3 Experiments & Analysis', '3.1 Dataset & Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/Elbria/utdsm_naacl2018\nCitation Context: We further per-form experiments on two NLP downstream tasks: text classification and paraphrase identification and demonstrate that our learned word represen-tations consistently provide higher performance than single-prototype word embedding models. The code of the present work is publicly avail-able [URL_CITE] .\nFootnote or Reference text (if exists): 1 https://github.com/Elbria/utdsm_ naacl2018\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.freedict.com\nCitation Context: \u2022 An English-French dictionary (a total of 34,808 entries, 4,021 of which are not one-to-one). [URL_CITE] It contains morphological variants but does not include character accents. Each n-to-m entry was processed by stoplisting and then extracting all word-pairs in the remaining cross-product as in section 4.1.\nFootnote or Reference text (if exists): 9 This dictionary was generated using a dictionary de-rived from one available at http://www.freedict.com.\nSection Titles (if exists):  ['5 Experiment: English-French', '5.1 Translation Lexicon']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The resource is a source of data (a dictionary) used in the research.\n* **TYPE: DataSource"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.globalWordnet.org/gwa/Wordnet_table.html\nCitation Context: It is also free. Wordnets in many languages are being constructed and developed [URL_CITE] . However, only a few of these Wordnets are of high quality and free for downloading.\nFootnote or Reference text (if exists): 2 http://www.globalWordnet.org/gwa/Wordnet_table.html\nSection Titles (if exists):  ['3 Experiments', '3.1 Publicly available Wordnets']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mastarpj.nict.go.jp/IWSLT2008/downloads/\nCitation Context: Examples include relocating or duplicating punctuation symbols to different positions of a sen-tence such that they appear closer to the indicative words (e.g., \u201chow much\u201d indicates a question sen-tence). One such technique was introduced by the organizers of the IWSLT evaluation campaign, who suggested duplicating the ending punctuation sym-bol to the beginning of each sentence before training the language model [URL_CITE] . Empirically, the technique has demonstrated its effectiveness in predicting question marks in English, since most of the indicative words for English question sentences appear at the begin-ning of a question.\nFootnote or Reference text (if exists): 1 http://mastarpj.nict.go.jp/IWSLT2008/downloads/ case+punc tool using SRILM.instructions.txt\nSection Titles (if exists):  ['3 Hidden Event Language Model']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk\nCitation Context: \u2022 ATIS (AT) (Hemphill et al., 1990) contains 4,978 utterances with 79 slots and 17 intents in the flights domain. [URL_CITE]\nFootnote or Reference text (if exists): 9 We used the ATIS data version from https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk.\nSection Titles (if exists):  ['5 Experiments', '5.1 Datasets and Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ns-moosavi/coval\nCitation Context: We measure coreference resolution performance with the MUC (Vilain et al., 1995), CEAF e (Luo, 2005), B 3 (Bagga and Baldwin, 1998), CoNLL F1 (Pradhan et al., 2012) and LEA (Moosavi and Strube, 2016) metrics. We use the scorer implementation from [URL_CITE] https://github.com/ns-moosavi/coval. Tables 12 to 16 report the full P/R/F1 scores of the coreference resolu-tion experiments reported in Section 4.1 for each of these metrics respectively.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['A.4 Full Experiment Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://abci.ai/\nCitation Context: All experiments were executed on a shared rt G.small instance on the ABCI compute cluster [URL_CITE] . An rt G.small node has 6 segregated CPU cores from a Xeon Gold 6148, a Tesla V100 GPU with 16GB VRAM, and 60GBs of memory.\nFootnote or Reference text (if exists): 1 https://abci.ai/\nSection Titles (if exists):  ['A Appendix', 'A.2 Environment']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://code.google.com/p/jacana/\nCitation Context: In the following we first provide background on the TED model, going on to evaluate our implemen-tation against prior work in the context of question answer sentence ranking (QASR), achieving state of the art in that task. We then describe how we cou-ple TED features to a linear-chain CRF for answer extraction, providing the set of features used, and fi-nally experimental results on an extraction dataset we make public (together with the software) to the community. [URL_CITE] Related prior work is interspersed throughout the paper.\nFootnote or Reference text (if exists): 3 http://code.google.com/p/jacana/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The citation refers to a software implementation (Jacana) used in the research. This suggests it's a tool"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/andreasvc/discodop\nCitation Context: For the evaluation, we use the corresponding module of discodop. [URL_CITE] We report several metrics (as implemented in discodop):\nFootnote or Reference text (if exists): 4 http://github.com/andreasvc/discodop\nSection Titles (if exists):  ['3 Experiments', '3.2 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.csai.tsinghua.edu.cn/~ly/systems/TsinghuaAligner/TsinghuaAligner.html\nCitation Context: For alignment evaluation, we used the Tsinghua Chinese-English word alignment evaluation data set. [URL_CITE] The evalu-ation metric is alignment error rate (AER) (Och and Ney, 2003). For translation evaluation, we used the NIST 2006 dataset as the development set and the NIST 2002, 2003, 2004, 2005, and 2008 datasets as the test sets.\nFootnote or Reference text (if exists): 1 http://nlp.csai.tsinghua.edu.cn/\u02dcly/systems/TsinghuaAligner/TsinghuaAligner.html\nSection Titles (if exists):  ['5 Experiments', '5.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/connorbrinton/polyai-models/releases/tag/v1.0\nCitation Context: (2020) showed that the \u201cUSE+ConveRT\u201d outperformed a BERT classifier on the CLINC150 dataset, while it was not evaluated along with the OOS detec-tion task. We modified their original code [URL_CITE] to apply the uncertainty-based OOS detection.\nFootnote or Reference text (if exists): 6 https://github.com/connorbrinton/polyai-models/releases/tag/v1.0.\nSection Titles (if exists):  ['4 Experimental Settings', '4.3 Model Training and Configurations']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Extend \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool within the research process to implement and modify a specific model.\n* **TYPE: Code"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/Summaryjudgment\nCitation Context: Summary Judgment is a le-gal term which means that a court has made a deter-mination (a judgment) without a full trial. [URL_CITE] Such a judgment may be issued as to the merits of an entire case, or of specific issues in that case. Typically, one of the parties (plaintiff or defendant) involved in the case moves a motion for summary judgment, (usu-ally) in an attempt to eliminate the risk of losing a trial.\nFootnote or Reference text (if exists): 1 See e.g., Wikipedia for more information: http://en.wikipedia.org/wiki/Summary judgment\nSection Titles (if exists):  ['2 Docket Entry Classification']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/Anna146/CHARM\nCitation Context: The salient contributions of this paper are: (1) a method for inferring both seen and previously un-seen (zero-shot) attribute values from a user\u2019s con-versational utterances; (2) a comprehensive evalua-tion for the profession and hobby attributes over a large dataset of Reddit discussions; and (3) labeled data and code as resources for later research. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/Anna146/CHARM\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nist.gov\nCitation Context: Our first experiment evaluates the models we have proposed on a corpus with traditional an-notation on a seven-point scale, namely the NIST OpenMT 2008 corpus. [URL_CITE] The corpus contains trans-lations of newswire text into English from three source languages (Arabic (Ar), Chinese (Ch), Urdu (Ur)). Each language consists of 1500\u20132800 sen-tence pairs produced by 7\u201315 MT systems.\nFootnote or Reference text (if exists): 4 Available from http://www.nist.gov.\nSection Titles (if exists):  ['5 Expt. 1: Predicting Absolute Scores']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Material** - The NIST OpenMT 2008 corpus is a dataset used in the research. \n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KNP\nCitation Context: We used JUMAN (Kurohashi and Kawahara, 2009a) for word segmentation and part-of-speech tagging, and we calculated idf over Mainichi newspaper articles from 1991 to 2005. For the de-pendency parsing, we used KNP (Kurohashi and Kawahara, 2009b) [URL_CITE] . Since KNP internally has a flag that indicates either an \u201cobligatory case\u201d or an \u201cadjacent case\u201d, we regarded dependency relations flagged by KNP as obligatory in the sentence com-pression.\nFootnote or Reference text (if exists): Sadao Kurohashi and Daisuke Kawahara, 2009b. KN parser (Kurohashi-Nagao parser) 3.0 Users Man-ual. http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KNP.\nSection Titles (if exists):  ['5 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/language/tree/master/language/realm\nCitation Context: All our models are developed and trained us-ing TensorFlow 1.15 (Abadi et al., 2016) and Tensor2Tensor (Vaswani et al., 2018). Our imple-mentations are based on the open-source codebases of REALM [URL_CITE] and the Routing Transformer. Similar to the REALM implementation, we use separate processes to run the retriever and generate training data (using a MIPS search).\nFootnote or Reference text (if exists): 19 https://github.com/google-research/language/tree/master/language/realm\nSection Titles (if exists):  ['7:453\u2013466.', 'A.1 Training & Model Details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/emorynlp/reading-comprehension\nCitation Context: For the future work, we will expand the annotation for more entity types and automatically link men-tions with respect to their entities using an entity linker. All our resources including the annotated corpus and source codes of the models are avail-able at: [URL_CITE] https://github.com/emorynlp/reading-comprehension.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Code\nFUNCTION:  Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The citation provides a link to the source code and annotated corpus, which are supplementary materials to the research paper."
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-ARNOR\nCitation Context: (2019), who publishes a manually labeled sentence-level test set. [URL_CITE] Besides, they also publish a test set for evaluating noise-filtering ability. Details of the adopted dataset are shown in Table 1.\nFootnote or Reference text (if exists): 4 https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-ARNOR\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://conceptnet.io/\nCitation Context: 2. Retrieval (RTRVL): We also experiment with a retrieval approach where we retrieve a VEHICLE from ConceptNet (Speer et al., 2017) having the highest HasProperty rela-tion w.r.t our input (i.e., an adjective or adverb at the end of literal sentence) [URL_CITE] . For the in-put The city was beautiful we query Concept-Net with beautiful, which returns sunset as the VEHICLE having the highest weight for HasProperty beautiful.\nFootnote or Reference text (if exists): 10 ConceptNet is a weighted graph with multiple relations as can be viewed here http://conceptnet.io/. We use \u2018has property\u201d for our work. There are multiple edges for objects with their properties. We choose the edge with the highest weight with the title Sunset and Car Accident. We replace the literal sentences with generated similes from SCOPE.\nSection Titles (if exists):  ['3 Experimental Setup', '3.1 Baseline Systems']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://pytorch.org/docs/master/index.html\nCitation Context: We use PyTorch [URL_CITE] to implement our models.\nFootnote or Reference text (if exists): 6 http://pytorch.org/docs/master/index.html\nSection Titles (if exists):  ['4 Experiments', '4.3 Implementation Detail']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://languagetool.org/\nCitation Context: We use (1) attack success rate \u2013 the ratio of the suc-cessful attacks to total number of attacks, (2) query count \u2013 the number of queries, (3) perturbation rate \u2013 the percentage of words substituted in an in-put and (4) grammatical correctness \u2013 the average grammatical error increase rate (calculated using Language-Tool [URL_CITE] ) to verify the quality of generated adversarial examples. For all the metrics except attack success rate, lower the value better the re-sult.\nFootnote or Reference text (if exists): 2 https://languagetool.org/\nSection Titles (if exists):  ['4 Experiments', '4.4 Evaluation Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://newsela.com\nCitation Context: Hence, we decided to create our own. Our dataset consists of a diverse set of 30 texts, from Simple English Wikipedia (10 articles), En-glish Wikipedia (8 articles), and online news ar-ticles (12 articles) [URL_CITE] . We did not wish to over-burden the readers, so we kept the size of texts to approximately 200 words each.\nFootnote or Reference text (if exists): 10 The sources for the articles were https://simple.wikipedia.org, https://en.wikipedia.org, and https://newsela.com\nSection Titles (if exists):  ['5 Experiment Details', 'Details of Texts']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.allenai.org/paper-appendix/emnlp2016-p3\nCitation Context: Code, data and supplementary material for this paper are available at: [URL_CITE] http://www.allenai.org/paper-appendix/emnlp2016-p3\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE:  Code\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The cited URL provides additional materials (code, data, supplementary information) related to the main paper. This aligns"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1007/978-3-540-30586-638\nCitation Context: The use of such metrics is, however, only sensible if they are known to be sufficiently correlated with human preferences. This is rarely the case, as shown by various studies in NLG (Stent et al., 2005 [URL_CITE] ; Belz and Reiter, 2006; Reiter and Belz, 2009), as well as in related fields, such as dialogue systems (Liu et al., 2016), machine translation (MT) (Callison-Burch et al., 2006), and image captioning (Elliott and Keller, 2014; Kilick-aya et al., 2017). This paper follows on from the above previous work and presents another evalu-ation study into automatic metrics with the aim to firmly establish the need for new metrics.\nFootnote or Reference text (if exists): Amanda Stent, Matthew Marge, and Mohit Singhai. 2005. Evaluating evaluation methods for gener-ation in the presence of variation. In Computa-tional Linguistics and Intelligent Text Processing: 6th International Conference, CICLing 2005, Mex-ico City, Mexico, February 13-19, 2005. Proceed-ings. Springer, Berlin/Heidelberg, pages 341\u2013351. https://doi.org/10.1007/978-3-540-30586-638.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.acronymsearch.com/\nCitation Context: We downloaded a list of acronyms in capital let-ters only from Wikipedia and filtered them by eliminating acronyms shorter than three letters. Then we obtained definitions for each acronym from [URL_CITE] http://www.acronymsearch.com/ and dis-carded acronyms that have less than five defini-tions. Finally, we randomly selected 20 acronyms.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Experiment', '3.1 Acronym and definition preparation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.geniaproject.org/genia-corpus/treebank\nCitation Context: In all our experiments, both the constituency and dependency parse trees are produced by Stan-ford Parser . Specially, we train the parser on the GENIA Treebank 1.0 [URL_CITE] (Tateisi et al., 2005), which contains Penn Treebank-style syntactic (phrase structure) annotation for the GENIA corpus. The parser achieves the performance of 87.12% in F1-score in terms of 10-fold cross-validation on GENIA TreeBank 1.0.\nFootnote or Reference text (if exists): 3 http://www.geniaproject.org/genia-corpus/treebank\nSection Titles (if exists):  ['4 Experimentation', '4.2 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Material** - The GENIA Treebank is a dataset of annotated text used for training and evaluating the Stanford Parser. \n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PKUnlp-icler/GAIN\nCitation Context: Experiments on the public dataset, DocRED, show GAIN achieves a significant performance improvement (2.85 on F1) over the previous state-of-the-art. Our code is available at [URL_CITE] https://github.com/PKUnlp-icler/GAIN.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.seas.upenn.edu/~nlp/resources/simple-ppdb.tgz\nCitation Context: Simple PPDB, along with the hu-man judgements collected as part of its creation, is freely available with the publication of this paper. [URL_CITE] rial is based in part on research sponsored by the NSF grant under IIS-1249516 and DARPA under number FA8750-13-2-0017 (the DEFT program). The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes.\nFootnote or Reference text (if exists): 6 http://www.seas.upenn.edu/\u02dcnlp/resources/simple-ppdb.tgz\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/adapt-sjtu/socvec\nCitation Context: Future di-rections include: 1) mining cross-cultural differ-ences in general concepts other than names and slang, 2) merging the mined knowledge into exist-ing knowledge bases, and 3) applying the SocVec in downstream tasks like machine translation. [URL_CITE]\nFootnote or Reference text (if exists): 14 We will make our code and data available at https: //github.com/adapt-sjtu/socvec.\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me break down why:\n\n* **ROLE: Method** - The citation refers to a code repository, indicating the resource is a tool used in the research process.\n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/uwnlp/taggerflow\nCitation Context: (2016) obtain their sil-ver data annotated with the high quality supertags. Since they make this data publicly available [URL_CITE] , we obtain our silver data by assigning dependency\nFootnote or Reference text (if exists): 5 https://github.com/uwnlp/taggerflow\nSection Titles (if exists):  ['5 Tri-training']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/datasets\nCitation Context: Sim-ilarly, the Rotten Tomatoes (RT) (Pang and Lee, 2005) dataset has 5331 positive and 5331 negative review sentences. We use the processed dataset made available by HuggingFace Dataset library [URL_CITE] (Wolf et al., 2020b).\nFootnote or Reference text (if exists): 3 https://github.com/huggingface/ datasets\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hierplane.allenai.org/explain\nCitation Context: In this section, we describe our key features for fa-cilitating a rapid understanding of linguistic struc-ture. As a companion to this section, we invite readers to use our web demonstration at [URL_CITE] http://hierplane.allenai.org/explain to in-teractively explore examples. 1\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Key Features']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning.pdf\nCitation Context: \u2022 Lang, SeqAE: Pretrained with the language model and autoencoder model proposed in (Dai and Le, 2015) [URL_CITE] . The language model is the de-coder part of the encoder-decoder model using a zero vector as the initial hidden layer value, and the autoencoder model is the same structure of the encoder-decoder model, where input and output are the same.\nFootnote or Reference text (if exists): Andrew M Dai and Quoc V Le. 2015. Semi-supervised Sequence Learning. In Advances in Neural Information Processing Systems 28 (NIPS 2015), Curran Associates, Inc., pages 3079\u20133087. http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning.pdf.\nSection Titles (if exists):  ['3 Experiments', '3.3 Compared Models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://i19pc5.ira.uka.de/rlat-dev\nCitation Context: CMUSphinx 3 ), they typically require many hours of training audio to produce effective models, data which is by definition not available for LRLs. In efforts to overcome this data scarcity problem, recent years have seen the development of techniques for rapidly adapt-ing multilingual or language-independent acoustic and language models to new languages from rela-tively small amounts of data (Schultz and Waibel, 2001; Kim and Khudanpur, 2003), methods for building resources such as pronunciation dictio-naries from web-crawled data (Schlippe et al., 2014), and even a web-based interface, the Rapid Language Adaptation Toolkit [URL_CITE] (RLAT), which al-lows non-expert users to exploit these techniques to create speech recognition and synthesis tools for new languages (Vu et al., 2010). While they greatly reduce the amount of data needed to build new recognizers, these approaches still require non-trivial amounts of speech and text in the target language, which may be an obstacle for very low-or zero-resource languages.\nFootnote or Reference text (if exists): 4 http://i19pc5.ira.uka.de/rlat-dev\nSection Titles (if exists):  ['2 Background and related work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/transformers\nCitation Context: Both the MRC and RCI training was carried out using the pytorch transformers toolkit made avail-able by Huggingface [URL_CITE] . Table 9 gives the number of parameters for each introduced model.\nFootnote or Reference text (if exists): 5 https://github.com/huggingface/ transformers\nSection Titles (if exists):  ['A Appendix']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/gyauney/domain-specific-lexical-grounding\nCitation Context: Our second contribution is a simple but per-formant clustering algorithm for this setting, EntSharp. [URL_CITE] We intend this method to learn from himage, wordi co-occurrences collected from multi-image, multi-sentence document collections.\nFootnote or Reference text (if exists): 3 Code is at https://github.com/gyauney/domain-specific-lexical-grounding.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/bert\nCitation Context: , p K independently selects a pair of answer positions (i k ,j k ), which are the begin and end of the answer from paragraph p k . In the case that p k does not support answering the question q, special NULL positions are selected (follow-ing the SQuAD 2.0 BERT implementation [URL_CITE] ). Thus, the set of possible outcomes \u2126 in the paragraph-level probability space is the set of lists of begin/end position pairs, one from each paragraph: {[(i 1 , j 1 ), .\nFootnote or Reference text (if exists): 3 https://github.com/google-research/bert\nSection Titles (if exists):  ['2 Probability Space']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ecdf.ed.ac.uk\nCitation Context: We would like to thank Phil Blunsom, Prachya Boonkwan, Christos Christodoulopoulos, Stephen Clark, Michael Collins, Chris Dyer, Timothy Fowler, Mark Granroth-Wilding, Philipp Koehn, Terry Koo, Tom Kwiatkowski, Andre\u0301 Martins, Matt Post, David Smith, David Sontag, Mark Steed-man, and Charles Sutton for helpful discussion re-lated to this work and comments on previous drafts, and the anonymous reviewers for helpful comments. We also acknowledge funding from EPSRC grant EP/P504171/1 (Auli); the EuroMatrixPlus project funded by the European Commission, 7th Frame-work Programme (Lopez); and the resources pro-vided by the Edinburgh Compute and Data Fa-cility ( [URL_CITE] http://www.ecdf.ed.ac.uk). The ECDF is partially supported by the eDIKT initiative (http://www.edikt.org.uk).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION:  Other \n\n\nLet me explain:\n\n* **ROLE: Material** - The Edinburgh Compute and Data Facility (ECDF) provides resources (likely computing power and data storage) which are essential for"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.fb9-ti.uni-duisburg.de/alert\nCitation Context: The European project IST A LERT : Alert sys-tem for selective dissemination ( [URL_CITE] http://www.fb9-ti.uni-duisburg.de/alert) aims to associate state-of-the-art speech recognition with audio and video segmentation and automatic topic index-ing to develop an automatic media monitoring demonstrator and evaluate it in the context of real world applications. The targeted languages are French, German and Portuguese. Major media-monitoring companies in Europe are participating in this project.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['8 Recent Research Projects']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://facebook.github.io/react\nCitation Context: The graphical user interface of our system is im-plemented as a single page Web application using the React framework. [URL_CITE] The application performs disambiguation of a text entered by a user. In par-ticular, the Web application features two modes:\nFootnote or Reference text (if exists): 8 https://facebook.github.io/react\nSection Titles (if exists):  ['3 Unsupervised Knowledge-Free Interpretable WSD', '3.3 User Interface for Interpretable WSD']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.mturk.com\nCitation Context: Once post-edits had been created, DA was em-ployed in two separate runs on Amazon Mechani-cal Turk, [URL_CITE] once for GEN - REF and once for POST - EDIT . Besides employing distinct reference trans-lations in the assessment, all other set-up crite-ria were identical for both evaluation settings, in-cluding the conventional segment-level DA set-ting, where a minimum of 15 human assessments are combined into a mean DA score for a given translation, after strict quality control measures and score standardization have been applied.\nFootnote or Reference text (if exists): 11 https://www.mturk.com\nSection Titles (if exists):  ['3 Alternate Reference Bias Investigation', '3.1 Reference Bias Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nHere's why:\n\n* **ROLE: Material** - Amazon Mechanical Turk (MTurk) is a platform where researchers can access human workers for tasks, essentially providing a source of"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wiktionary.org/Frequencylists/Telugu\nCitation Context: Initially, we create data lists for Hindi and Telugu. For this, we have extracted a corpus of most frequent Hindi words and most frequent Telugu words [URL_CITE] . We have also extracted Hindi movie names and Telugu movie names of the movies released between the years 1930 and 2018 from Wikipedia which constitute phrases in the data lists.\nFootnote or Reference text (if exists): 3 https://en.wiktionary.org/Frequencylists/Telugu\nSection Titles (if exists):  ['4 Experiments and Results', '4.1 Dataset details']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ictclas.org/\nCitation Context: We compare our method with three baseline methods. The first two are both famous Chinese word segmentation tools: ICTCLAS [URL_CITE] and Stan-ford Chinese word segmenter , which are widely used in NLP related to word segmentation. Stan-ford Chinese word segmenter is a CRF-based seg-mentation tool and its segmentation standard is chosen as the PKU standard, which is the same to ours.\nFootnote or Reference text (if exists): 3 http://ictclas.org/\nSection Titles (if exists):  ['3 Experiment', '3.1 Data set']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mlpc-ucsd/BERT_Convolutions\nCitation Context: Full pre-training and fine-tuning details are outlined in Appendix A.1. [URL_CITE] Evaluation Models were evaluated on the GLUE benchmark, a suite of sentence classification tasks including natural language inference (NLI), gram-maticality judgments, sentiment classification, and textual similarity (Wang et al., 2018). For each task, we ran ten fine-tuning runs and used the model with the best score on the development set.\nFootnote or Reference text (if exists): 2 Code is available at https://github.com/mlpc-ucsd/BERT_Convolutions, built upon the Huggingface Transformers library (Wolf et al., 2020).\nSection Titles (if exists):  ['3 Integrating lightweight convolutions', '3.2 Composite attention and lightweight convolution experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being used as part of the research process, specifically for fine-tuning and evaluating models.\n* **TYPE"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.toronto.edu/~aditya/g2p-tl-rr\nCitation Context: Our experiments aim at comprehensive evaluation of the reranking approach on both MTL and G2P tasks, employing various supplemental representa-tions. Relevant code and scripts associated with our experimental results are available online [URL_CITE] .\nFootnote or Reference text (if exists): 1 http://www.cs.toronto.edu/\u02dcaditya/ g2p-tl-rr\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: http://www.dh.uni-leipzig.de/wo/projects/open-greek-and-latin-project/\nCitation Context: Due to availability of digitised epigraphic corpora, P YTHIA has been trained on ancient Greek (hence-forth, \"AG\") inscriptions, written in the ancient Greek language between 7 th century BCE and 5 th century CE. We chose AG epigraphy as a case study for two reasons: a) the variability of contents and context of the AG epigraphic record makes it an excellent challenge for NLP; b) several digital AG textual corpora have been recently created, the largest ones being PHI (The Packard Humanities Institute, 2005; Gawlinski, 2017) for epigraphy; Perseus (Smith et al., 2000) and First1KGreek (Crane et al., 2014) [URL_CITE] for ancient literary texts.\nFootnote or Reference text (if exists): Gregory Ralph Crane, Monica Berti, Annette Ge\u00dfner, Matthew Munson, and Tabea Selle. 2014. Open greek and latin project. http://www.dh.uni-leipzig.de/wo/projects/open-greek-and-latin-project/. Ac-cessed on 2019-04-24.\nSection Titles (if exists): [\\'3 Generating PHI-ML\\']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ghpaetzold/questplusplus\nCitation Context: The source code for the framework, the datasets and extra resources can be downloaded from [URL_CITE] https://github.com/ghpaetzold/questplusplus.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Remarks']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is being presented as a tool used in the research, making it a method.\n* **TYPE: Code**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.seas.upenn.edu/~strctlrn/MSTParser/MSTParser.html\nCitation Context: We use the publicly available implementation of MSTParser [URL_CITE] (with modifications to the feature com-putation) and its default settings, so the feature weights of the projective and non-projective parsers are trained by the MIRA algorithm (Crammer and Singer, 2003; Crammer et al., 2006).\nFootnote or Reference text (if exists): 7 http://www.seas.upenn.edu/\u02dcstrctlrn/MSTParser/MSTParser.html\nSection Titles (if exists):  ['6 Experiment', '6.2 Baseline Models']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode\nCitation Context: This data is made available under the Creative Commons license, Attribution-Non Commercial-No Derivatives (or the CC BY-NC-ND 4.0 International, [URL_CITE] https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode), all credit for the content goes to the TED organization and the respective authors of the talks. The data it-self can be found at http://www.cs.cmu.edu/ \u223c pmichel1/sated/.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Speaker Annotated TED Talks Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Document\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/udapi/udapi-python/blob/master/udapi/block/eval/conll17.py\nCitation Context: For evaluation we use labeled attachment score (LAS). Significance testing is performed using a randomization test, with the script from the CoNLL 2017 Shared Task. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/udapi/udapi-python/blob/master/udapi/block/eval/conll17.py\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - The code is used as a tool within the research process for evaluation.\n* **TYPE: Code** - The URL points"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/nmrksic/attract-repel\nCitation Context: cialisation framework (Mrk\u0161ic\u0301 et al., 2017). [URL_CITE] The key idea of LEAR , illustrated by Figure 1, is to pull desirable ( ATTRACT ) examples described by the constraints closer together, while at the same time pushing undesirable ( REPEL ) word pairs away from each other. Concurrently, LEAR (re-)arranges vector norms so that norm values in the Euclidean space reflect the hierarchical organisation of con-cepts according to the given LE constraints: put simply, higher-level concepts are assigned larger norms.\nFootnote or Reference text (if exists): 2 https://github.com/nmrksic/attract-repel\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt19/translation-task.html\nCitation Context: V AR -S TREAM is substan-tially faster than Fixed and V AR -B ATCH under this setting. A.5 Dataset Details A.5.1 Machine Translation Evaluation datasets (newstest2018 and new-stest2017) are available at [URL_CITE] http://www.statmt.org/wmt19/translation-task.html. new-stest2018 contains 2998 and 3000 examples for De-En and Ru-En respectively, while newstest2017 contains 3004 and 3001.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['-', 'Hyperparameters']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/bert\nCitation Context: We also calculate the answer recall after document prun-ing, which indicates the performance upper bound. Model settings We initialize our model us-ing two publicly available uncased versions of BERT [URL_CITE] : BERT BASE and BERT LARGE , and refer readers to Devlin et al. (2018) for details on model sizes.\nFootnote or Reference text (if exists): 5 https://github.com/google-research/bert\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Code\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Code:** The artifact is a codebase (BERT) hosted on GitHub, making it a code artifact.\n* **TYPE: Code:**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://archive.org/download/\nCitation Context: ; \u03c6). All intermediate pre-training is done with input sequence length of 128, batch size of 2048, learning rate of 0.0001, up to a total num-ber of 100, 000 updates, using Wikipedia snapshot from December 20, 2018 [URL_CITE] .\nFootnote or Reference text (if exists): 1 The snapshot is available at https://archive.org/download/enwiki-20181220. Wikipedia is licensed under CC BY-SA 3.0.\nSection Titles (if exists):  ['3 Analysis Setup', '3.1 Experiment Procedure']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/brmson/dataset-factoid-webquestions\nCitation Context: WebQuestions [URL_CITE] (Berant et al., 2013b) is de-signed for answering questions from the Free-base knowledge base, which is built by crawl-ing questions through the Google Suggest API and the paragraphs are retrieved from the English Wikipedia using .\nFootnote or Reference text (if exists): 5 https://github.com/brmson/ dataset-factoid-webquestions\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets and Evaluation Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ai.stanford.edu/\nCitation Context: We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outper-forms competitive baselines and other neural language models. [URL_CITE]\nFootnote or Reference text (if exists): 1 The dataset and word vectors can be downloaded at http://ai.stanford.edu/ \u223c ehhuang/.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The resource is a dataset of human judgments on word pairs in context. This aligns with the \"Material\" role as"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.msn.com/en-us/news\nCitation Context: Online news platforms such as Google News and MSN [URL_CITE] News have gained huge popularity for on-line digital news reading (Das et al., 2007). Tens of thousands of news articles are streamed from various sources every day, making it very difficult for users to read all news to find their interested content (Phelan et al., 2011). Thus, personalized news recommendation is critical for online news platforms to target user interests and alleviate in-formation overload (IJntema et al., 2010).\nFootnote or Reference text (if exists): 2 https://www.msn.com/en-us/news SearchQueries whether\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/abisee/cnn-dailymail\nCitation Context: We used the CNN/Daily Mail dataset 1 (Her-mann et al., 2015), a summary corpus of En-glish news articles, consisting of 287,226 train-ing pairs, 13,368 validation pairs, and 11,490 test pairs. On average, the source documents and sum-mary sentences have 781 and 56 tokens, respec-tively. For data preprocessing, we followed the in-struction provided in the CNN/Daily Mail dataset [URL_CITE] and fairseq .\nFootnote or Reference text (if exists): 1 CNN/Daily Mail dataset: https://github.com/abisee/cnn-dailymail\nSection Titles (if exists):  ['4 Experiments', '4.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://ibm.biz/acl21-loa\nCitation Context: Our LOA also provides open-sourced implementation in Python for the reinforce-ment learning environment to facilitate an ex-periment for studying neuro-symbolic agents. Demo site: [URL_CITE] https://ibm.biz/acl21-loa, Code: https://github.com/ibm/loa\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Produce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a demo site and likely provides supplementary information about the research, rather than being a core tool or"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cmu.edu/~afm/projects/multilingual_embeddings.html\nCitation Context: On the TED corpus, we obtained general pur-pose multilingual embeddings for 11 target lan-guages, by considering the (auxiliary) task of reconstructing pre-trained English word vectors. The resulting embeddings led to cross-lingual multi-label classifiers that achieved the highest re-ported scores on 10 out of these 11 languages. [URL_CITE]\nFootnote or Reference text (if exists): 1 We provide the trained embeddings at http://www.cs.cmu.edu/~afm/projects/multilingual_embeddings.html.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pemistahl/lingua\nCitation Context: Currently, A CTIVE A NNO has three inbuilt an-notation generator implementations. The first one automatically detects the language of the generator input using the language detection library Lingua [URL_CITE] . This is an example of a statistical and rule-based annotation generator as compared to a machine learning-based generator.\nFootnote or Reference text (if exists): 6 https://github.com/pemistahl/lingua\nSection Titles (if exists):  ['4 Annotation Generator']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://wit3.fbk.eu/\nCitation Context: Datasets We evaluate our method on the IWSLT datasets which contain multiple languages from TED talks. We collect datasets from the IWSLT evaluation campaign [URL_CITE] from years 2011 to 2018, which consist of the translation pairs of 23 languages\u2194English. The detailed description of the training/validation/test set of the 23 transla-tion pairs can be found in Supplementary Mate-rials (Section 1).\nFootnote or Reference text (if exists): 6 https://wit3.fbk.eu/\nSection Titles (if exists):  ['4 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://openke.thunlp.org/\nCitation Context: Besides the toolkit, we also provide the pre-trained embeddings of several well-known large-scale KGs, which can be used directly for other relevant works without repeatedly spending much time for embedding KGs. In this paper, we mainly present the architecture design and implementa-tion of OpenKE, as well as the benchmark eval-uation results of some typical KE models im-plemented with OpenKE. Other related resources and details can be found on [URL_CITE] http://openke.thunlp.org/.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://groups.csail.mit.edu/sls/downloads/\nCitation Context: Table 1 shows the distribution over the stance labels, [URL_CITE] which turns out to be very similar to that for the FNC dataset. We can see that there are very few documents disagreeing with true claims (about 0.5%), which suggests that stance is pos-itively correlated with factuality. However, the number of documents agreeing with false docu-ments is larger than the number of documents dis-agreeing with them, which illustrates one of the main challenges when trying to predict the factu-ality of news based on stance.\nFootnote or Reference text (if exists): 7 The corpus is available at http://groups.csail.mit.edu/sls/downloads/ and also at http://alt.qcri.org/resources/\nSection Titles (if exists):  ['3 The Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://demos.explosion.ai/\nCitation Context: Figure 1 was generated from (Podgursky, 2015), which provides open-source code and a web interface for a static rendering of a con-stituency parse. There are a number of libraries (Stenetorp et al., 2012; Montani, 2016 [URL_CITE] ; Athar, 2010; Yimam et al., 2013) that provide static ren-derings of dependency parses similar to Figure 1 (bottom). Among these, Brat (Stenetorp et al., 2012) provides some interactive elements (like mouseover highlighting of subtrees, and the abil-ity to add dependencies via drag-and-drop).\nFootnote or Reference text (if exists): Ines Montani. 2016. Displacy dependency vi-sualizer. https://demos.explosion.ai/displacy. Accessed: 2017-04-27.\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Supplement** - The URL points to a web interface for visualizing dependency parses. This is a tool that helps understand and explore related"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://aws.amazon.com/lex/\nCitation Context: We also compare our proposed model C APSULE -NLU with existing commercial natural language understanding services, includ-ing api.ai (Now called DialogFlow) , Waston Assistant , Luis , wit.ai , snips.ai , recast.ai , and Amazon Lex [URL_CITE] .\nFootnote or Reference text (if exists): 8 https://aws.amazon.com/lex/\nSection Titles (if exists):  ['3 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/soskek/bookcorpus\nCitation Context: The original BookCorpus (Zhu et al., 2015) is no longer avail-able, so we collect similar data from Smashwords, the original source of BookCorpus. [URL_CITE]\nFootnote or Reference text (if exists): 5 We collect our data using the Wikipedia XML dump https://dumps.wikimedia.org/mirrors.html and data-processing code https://github.com/attardi/wikiextractor, and a Smashwords crawler https://github.com/soskek/bookcorpus.\nSection Titles (if exists):  ['4 Models, Pretraining, & Fine-Tuning', '4.1 Pretraining']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://slack.com\nCitation Context: Online conversations are increasingly significant for communication, e.g., Slack [URL_CITE] for work com-munication and Reddit for general discussion. To organize overwhelming information from these conversations, researchers have been working on summarizing online conversations (Bhatia et al., 2014; Carenini et al., 2007; Mehdad et al., 2013, 2014; Oya et al., 2014).\nFootnote or Reference text (if exists): 1 https://slack.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.ualberta.ca/~ab31/langid/\nCitation Context: We manually classified these names as being of ei-ther Indian or non-Indian origin, occasionally resort-ing to web searches to help disambiguate them. [URL_CITE] We discarded those names that fell into both categories (e.g. \u201cMaya\u201d) as well as those that we could not confidently classify.\nFootnote or Reference text (if exists): 1 Our tagged data are available online at http://www.cs.ualberta.ca/\u02dcab31/langid/.\nSection Titles (if exists):  ['5 Application to machine transliteration', '5.1 Data']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dbpedia.org/\nCitation Context: To help prevent a bias towards learning about prominent entities at the expense of generality, KELVIN refrains from mining facts from sources such as documents obtained through Web search, Wikipedia , or DBpedia. [URL_CITE] Only facts that are as-serted in and gleaned from the source documents are posited.\nFootnote or Reference text (if exists): 3 http://www.dbpedia.org/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.jhu.edu/~ozaidan/AOC\nCitation Context: We ran five experiments to test the effect of MSA to CEA conversion on POS tagging: (a) Standard, where we train the tagger on the ATB MSA data, (b) 3-gram LM, where for each MSA sentence we generate all transformed sentences (see Section 2.1 and Figure 1) and pick the most probable sentence according to a trigram language model built from an 11.5 million words of user contributed comments. [URL_CITE] This corpus is highly dialectal\nFootnote or Reference text (if exists): 1 Available from http://www.cs.jhu.edu/~ozaidan/AOC\nSection Titles (if exists):  ['3.2. Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The cited resource is a corpus of user-contributed comments, which falls under the category of datasets.\n* **"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://goo.gl/bFokI\nCitation Context: We lemmatized and POS-tagged the German G UR 350 dataset (Zesch et al., 2007), a set of 350 word pairs with human similarity judgments, created analo-gously to the well-known Rubenstein and Good-enough (1965) dataset for English. [URL_CITE] We predict semantic similarity as cosine similarity. We make a prediction for a word pair if both words are repre-sented in the semantic space and their vectors have a non-zero similarity.\nFootnote or Reference text (if exists): 2 Downloadable from: http://goo.gl/bFokI\nSection Titles (if exists):  ['5 Experimental Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ybz79/AMR2text\nCitation Context: As for batch size, we use 80 for LDC2015E86 and 120 for LDC2017T10. [URL_CITE]\nFootnote or Reference text (if exists): 3 Our code is available at https://github.com/ybz79/AMR2text\nSection Titles (if exists):  ['4 Experiments', '4.1 Settings']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.biography.com/search/index.jsp\nCitation Context: We download from infoplease.com and biogra-phy.com [URL_CITE] two corpora of people\u2019s biographies, which include 24,975 and 24,345 bios respectively. We scan each whole corpus and extract people having spouse information.\nFootnote or Reference text (if exists): 3 http://www.biography.com/search/index.jsp\nSection Titles (if exists):  ['4 Experiments and Results', '4.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: DataSource\nFUNCTION: Use \n\n\nLet me explain my reasoning:\n\n* **ROLE: Material** - The URL points to a website that serves as a source of data (biographies).  It's not a"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/RUC-WSM/WD-Match\nCitation Context: The source code of WD-Match is available at [URL_CITE] https://github.com/RUC-WSM/WD-Match\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/pytorch-pretrained-BERT\nCitation Context: We ex-periment with both type-level word embeddings (GloVe.6B.300d; Pennington et al., 2014) and contextual embeddings (BERT large; Devlin et al., 2019). [URL_CITE] In both cases, we keep the embeddings fixed, so the vast majority of the learnable pa-rameters are in the WFSAs. We train mod-els using GloVe embeddings on all datasets.\nFootnote or Reference text (if exists): 8 https://github.com/huggingface/ pytorch-pretrained-BERT\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tuhinjubcse/SimileGeneration-EMNLP2020\nCitation Context: To the best of our knowledge, this is the first work in attempting to generate simi-les. By framing the task as a style-transfer problem we make three contributions: [URL_CITE]\nFootnote or Reference text (if exists): 4 Code & Data at https://github.com/tuhinjubcse/SimileGeneration-EMNLP2020\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Produce \n\n\nLet me explain my reasoning:\n\n* **ROLE: Method** - The code is likely a tool used to implement the research described in the paper.  \n* **TYPE: Code"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/clab/lstm-parser\nCitation Context: Using the dimen-sions discussed in the next section, we required between 8 and 12 hours to reach convergence on a held-out dev set. [URL_CITE]\nFootnote or Reference text (if exists): 6 Software for replicating the experiments is available from https://github.com/clab/lstm-parser.\nSection Titles (if exists):  ['4 Training Procedure']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mounicam/lexical_simplification\nCitation Context: Additionally, we also produce SimplePPDB++, a lexical resource of over 10 million simplifying paraphrase rules, by ap-plying our model to the Paraphrase Database (PPDB). [URL_CITE]\nFootnote or Reference text (if exists): 1 The code and data are publicly available on the au-thors\u2019 homepages and GitHub: https://github.com/mounicam/lexical_simplification.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Mixed\nTYPE: Mixed\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/thunlp/Fast-TransX\nCitation Context: In fact, we often rely on simple personal computers for model validation. Hence, we enable OpenKE to adapt models for parallel learning on CPU [URL_CITE] be-sides employing GPU learning, which allow users to make full use of all available computing re-sources. The parallel learning method is shown in Algorithm 1.\nFootnote or Reference text (if exists): 2 https://github.com/thunlp/Fast-TransX\nSection Titles (if exists):  ['4 Implementations', '4.2 Parallel Learning']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet's break down why:\n\n* **ROLE: Method** - The citation refers to a tool (Fast-TransX) that enables a specific technique (parallel learning on CPU"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://bitbucket.org/melsner/browncoherence\nCitation Context: EGrid has been shown to give competitive re-sults on similar coherence tasks in other domains. Using the Brown Coherence Toolkit (Eisner and Charniak, 2011), [URL_CITE] we construct the entity transi-tion probabilities with length = 3 and salience = 2. The transition probabilities are then used as fea-tures that are fed as input to an SVM classifier with an RBF kernel and penalty parameter C = 1.5 to predict a coherence score.\nFootnote or Reference text (if exists): 13 https://bitbucket.org/melsner/browncoherence\nSection Titles (if exists):  ['5 Model Parameters and Baselines']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf\nCitation Context: However, it cannot fully take advantage the training data if it comes from multiple source domains. MS,ST adaptation (Mansour et al., 2009 [URL_CITE] ; Zhao et al., 2017) can deal with multiple source domains but only transfers to a single target domain. Therefore, when multiple target domains exist, they need to treat them as independent prob-lems, which is more expensive and cannot utilize the additional unlabeled data in these domains.\nFootnote or Reference text (if exists): Yishay Mansour, Mehryar Mohri, and Afshin Ros-tamizadeh. 2009. Domain adaptation with multiple sources. In Advances in Neural Information Processing Systems 21, Curran Associates, Inc., pages 1041\u20131048. http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources.pdf.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Paper\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://ifttt.com/\nCitation Context: If the condition is satisfied, the required processing con-sists of calling the execution of actions grounded in the effectors. Giving a conversational assistant the capacity to learn rules verbally opens the pos-sibility of teaching more complex and personal-ized rules, especially compared to visual program-ming tools such as IFTTT and Zapier [URL_CITE] . LIA can ask questions if it cannot parse specifics parts of a user-statement (e.g., if it cannot understand the if-condition, see Figure 2 for an example).\nFootnote or Reference text (if exists): 1 https://ifttt.com/, https://zapier.com/\nSection Titles (if exists):  ['2 Core competencies', '2.1 Learning Procedures']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Supplement\nTYPE: Website\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cl.cam.ac.uk/~ah433/mcrae-quantified-majority.txt\nCitation Context: In this work, we assume the existence of a mapping between language (distributional models) and world (set-theoretic models), or to be more precise, between language and a shared set of beliefs about the world, as negotiated by a group of speakers. To operationalise this mapping, we propose that set-theoretic models, like distributions, can be expressed in terms of vec-tors \u2013 giving us a common representation across for-malisms. Using a publicly available dataset of feature norms annotated with quantifiers [URL_CITE] (Herbelot and Vec-chi, 2015), we show that human-like intuitions about the quantification of simple subject/predicate pairs can be induced from standard distributional data.\nFootnote or Reference text (if exists): 1 Data available at http://www.cl.cam.ac.uk/\u02dcah433/mcrae-quantified-majority.txt\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the role that resources play in the research activities (ROLE), the type of artifact (TYPE) referred to the URL and the citation reason (FUNCTION). I will provide you with a URL, citation context and section titles.\n\n\nHere is the classification schema for the artifact role:\n1. Method: corresponding to the artifact type \"Tool\" and \"Code\"\n2. Material: corresponding to the artifact type \"Dataset\", \"Knowledge\" and \"DataSource\"\n3. Supplement: corresponding to the artifact type \"Document\", \"Paper\", \"Media\" and \"Webcite\"\n4. Mixed: corresponding to the artifact type \"Mixed\"\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n\nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: Introduced the resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://edition.cnn.com/specials/world/fast-facts\nCitation Context: Ground-Truth Timelines: We obtain ground-truth timelines from CNN Fast Facts [URL_CITE] , which has a collection of several hundred timelines grouped in categories, e.g., \u2018people\u2019 or \u2018disasters\u2019. We pick all timelines of the \u2018people\u2019 category and a small number from other categories.\nFootnote or Reference text (if exists): 6 http://edition.cnn.com/specials/world/fast-facts\nSection Titles (if exists):  ['4 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Material\nTYPE: Knowledge\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cornell.edu/~rs/sfour/\nCitation Context: \u2022 SFOUR: SFOUR is a structured prediction approach that trains an end-to-end system with a large-margin method to optimize a convex relaxation of ROUGE (Sipos et al., 2012). We use the publicly available imple-mentation. [URL_CITE]\nFootnote or Reference text (if exists): 6 http://www.cs.cornell.edu/\u02dcrs/sfour/\nSection Titles (if exists):  ['4 Evaluation', '4.3 End-to-End Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "ROLE: Method\nTYPE: Code\nFUNCTION: Use \n\n\nLet me explain:\n\n* **ROLE: Method** - SFOUR is a structured prediction approach, a method or algorithm used in the research.\n* **TYPE: Code** -"
                }
            ]
        }
    ]
]