[
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://scikit-learn.org\nCitation Context: There are many successful frameworks such as S TANFORD C ORE NLP (Manning et al., 2014), NLTK (Bird et al., 2009), and SPA C Y for NLP, L UCENE and S OLR for Information Retrieval, and SCIKIT - LEARN [URL_CITE] , P Y T ORCH and T ENSOR - F LOW (Abadi et al., 2015) for general Machine Learning (ML) with a special focus on Deep Learning (DL), among others. All of these frame-works touch upon several aspects of Machine Reading, but none of them offers dedicated sup-port for modern MR pipelines.\nFootnote or Reference text (if exists): 4 http://scikit-learn.org\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cs.stanford.edu/\nCitation Context: We see many opportunities for improvement, considering the poor performance of oracle training relative to the super-vised state-of-the-art, and in turn the poor perfor-mance of unsupervised state-of-the-art relative to the oracle models. [URL_CITE] To this end, it would be instructive to understand both the linguistic and statistical na-ture of the sweet spot, and to test its universality.\nFootnote or Reference text (if exists): 11 To facilitate future work, all of our models are publicly available at http://cs.stanford.edu/ \u223c valentin/.\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION:  Other \n\n\n\nLet me explain why:\n\n* **TYPE: Website** - The URL points to a general website (Stanford Computer Science Department). \n* **FUNCTION: Other** - While the website hosts the"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://132.70.6.148:at:8080/exploration\nCitation Context: The web application of our system is available [URL_CITE] http://132.70.6.148:at:8080/exploration\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Application to the Health-care Domain']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jialuli-luka/SyntaxVLN\nCitation Context: We also show that our agent is better at aligning instructions with the cur-rent visual information via qualitative visual-izations. [URL_CITE]\nFootnote or Reference text (if exists): 1 Code and models: https://github.com/jialuli-luka/SyntaxVLN\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.yelp.com/dataset\nCitation Context: We use one of the classic NLP tasks that commonly suffer profanity issues - text style transfer, to eval-uate the effectiveness of the proposed framework. Particularly, we conduct experiments on a subset of the widely used Yelp dataset [URL_CITE] . The dataset consists of product reviews aligned with sentiment ratings from 1 to 5.\nFootnote or Reference text (if exists): 2 https://www.yelp.com/dataset\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.msn.com/en-us/news\nCitation Context: We conducted experiments on a real-world news recommendation dataset collected from MSN News [URL_CITE] logs in one month (Dec. 13, 2018 to Jan. 12, 2019). The detailed statistics are shown in Ta-ble 1.\nFootnote or Reference text (if exists): 3 https://www.msn.com/en-us/news\nSection Titles (if exists):  ['3 Experiments', '3.1 Datasets and Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: DataSource\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hdl.handle.net/11234/1-1983xxx\nCitation Context: We evaluate the proposed framework on the Stan-ford Dependency (SD) conversion of the English Penn Treebank (PTB 3.0) and the Universal De-pendencies (UD 2.2) (Nivre et al., 2018) [URL_CITE] tree-banks used in CoNLL 2018 shared task(Zeman et al., 2018). For English, we use the standard train/dev/test splits of PTB (train=\u00a72-21, dev=\u00a722, test=\u00a723), POS tags were assigned using the Stan-ford tagger with 10-way jackknifing of the training corpus (accuracy \u2248 97.3%). For 12 languages se-lected from UD 2.2, we use CoNLL 2018 shared task\u2019s official train/dev/test splits, POS tags were assigned by the UDPipe (Straka et al., 2016).\nFootnote or Reference text (if exists): Joakim Nivre et al. 2018. Universal Dependencies 2.2. LINDAT/CLARIN digital library at the Insti-tute of Formal and Applied Linguistics, Charles Uni-versity, Prague, http://hdl.handle.net/11234/1-1983xxx.\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.texar.io.1\nCitation Context: The versatile toolkit also fosters technique sharing across different text generation tasks. Texar supports both TensorFlow and PyTorch, and is released under Apache License 2.0 at [URL_CITE] https: //www.texar.io. 1\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://bigml.cs.tsinghua.edu.cn/jun/stc.shtml/\nCitation Context: It is a sparsity-enhanced non-probabilistic topic model. We use the code released by the authors [URL_CITE] . We set the regularization constants as \u03bb = 0.3, \u03c1 = 0.0001 and the maximum number of itera-tions of hierarchical sparse coding, dictionary learning as 100.\nFootnote or Reference text (if exists): 5 http://bigml.cs.tsinghua.edu.cn/jun/stc.shtml/\nSection Titles (if exists):  ['4 Experiments', '4.1 Data and Setting']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wikitravel.org/en/Wikitravel:Articletemplates/Sections\nCitation Context: Each article describes a city or a larger geo-graphic area that is of interest to tourists. In addition, all articles contain sections [URL_CITE] describing different as-pects of a city from a tourism point of view (e.g., places to see, transportation, shopping and eating). For our proof of concept, we performed IE only on the \u2018places to see\u2019 sections.\nFootnote or Reference text (if exists): 7 http://wikitravel.org/en/Wikitravel:Articletemplates/Sections\nSection Titles (if exists):  ['4 Human Subject Evaluations']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ntu.edu.au/education/langs/ielex/IE-DATA1\nCitation Context: Since we used automatic tools for preparing our corpus rather than careful linguistic analysis, our cognate list is much noiser in terms of the pres-ence of borrowed words and phonemeic transcrip-tion errors compared to the ones used by previous approaches (Swadesh, 1955; Dyen et al., 1997 [URL_CITE] ). The benefit of our mechanical preprocessing is that more cognate data can easily be made available, allowing us to effectively train richer models.\nFootnote or Reference text (if exists): I. Dyen, J.B. Kruskal, and P. Black. 1997. FILE IE-DATA1. Available at http://www.ntu.edu.au/education/langs/ielex/IE-DATA1.\nSection Titles (if exists):  ['4 Experiments', '4.1 Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.seas.upenn.edu/\u223cpdtb/tools.shtml#annotator\nCitation Context: The source of these files is Xinhua newswire. The annotation is carried out on the PDTB annotation tool [URL_CITE] .\nFootnote or Reference text (if exists): 3 http://www.seas.upenn.edu/\u223cpdtb/tools.shtml#annotator\nSection Titles (if exists):  ['4 Annotation experiment', '4.1 Set-up']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://casmacat.eu/corpus/global-voices.html\nCitation Context: Much of our data comes from WikiMatrix (Schwenk et al., 2019), a large collection of parallel data extracted from Wikipedia, and for more domain variety, we added Global Voices, [URL_CITE] EuroParl (Koehn, 2005) (random subset of to 100k sentence pairs per language pair), SETimes, United Nations (Eisele and Chen, 2010) (random sample of 1M sentence pairs per language pair). We also included WMT Kazakh\u2013English and Kazakh\u2013Russian data from WMT, to be able to evaluate on Kazakh.\nFootnote or Reference text (if exists): 10 http://casmacat.eu/corpus/global-voices.html\nSection Titles (if exists):  ['B Data Details for Replication']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1109/ICDM.2015.68\nCitation Context: Domain-Specific Models Only LS 77.80 77.88 81.63 84.33 80.41 SVM 78.56 78.66 83.03 84.74 81.25 LR 79.73 80.14 84.54 86.10 82.63 MLP 81.70 81.65 85.45 85.95 83.69 Shared Model Only LS 78.40 79.76 84.67 85.73 82.14 SVM 79.16 80.97 85.15 86.06 82.83 LR 80.05 81.88 85.19 86.56 83.42 MLP 82.40 82.15 85.90 88.20 84.66 MAN-L2-MLP 82.05 83.45 86.45 88.85 85.20 MAN-NLL-MLP 81.85 83.10 85.75 89.10 84.95 Shared-Private Models RMTL 1 81.33 82.18 85.49 87.02 84.01 MTLGraph 2 79.66 81.84 83.69 87.06 83.06 CMSC-LS 3 82.10 82.40 86.12 87.56 84.55 CMSC-SVM 3 82.26 83.48 86.76 88.20 85.18 CMSC-LR 3 81.81 83.73 86.67 88.23 85.11 SP-MLP 82.00 84.05 86.85 87.30 85.05 MAN-L2-SP-MLP ( 82 \u00b10 .46 83.98 87.22* 88.53 85.55* .25) (\u00b10.17) (\u00b10.04) (\u00b10.19) (\u00b10.07) MAN-NLL-SP-MLP 82.98* 84.03 87.06 88.57* 85.66* (\u00b10.28) (\u00b10.16) (\u00b10.23) (\u00b10.15) (\u00b10.14) 1 Evgeniou and Pontil (2004) 2 Zhou et al. (2011) 3 Wu and Huang (2015) [URL_CITE] 3 Zhao et al. (2017)\nFootnote or Reference text (if exists): Fangzhao Wu and Yongfeng Huang. 2015. Collabora-tive multi-domain sentiment classification. In 2015 IEEE International Conference on Data Mining. pages 459\u2013468. https://doi.org/10.1109/ICDM.2015.68.\nSection Titles (if exists):  ['3 Theories of Multinomial Adversarial Networks']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ling.upenn.edu/hist-corpora/PPCEME-RELEASE-2/index.html\nCitation Context: 1 The other treebanks in the series cover Early Modern En-glish (Kroch et al., 2004) [URL_CITE] (1.8 million words), Middle Eng-lish (Kroch and Taylor, 2000) (1.2 million words), and Early English Correspondence (Taylor et al., 2006) (2.2 million words).\nFootnote or Reference text (if exists): Anthony Kroch, Beatrice Santorini, and Ariel Diertani. 2004. Penn-Helsinki Parsed Cor-pus of Early Modern English. http: //www.ling.upenn.edu/hist-corpora/ PPCEME-RELEASE-2/index.html.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aclweb.org/anthology/P96-1011\nCitation Context: For our models, we adopt the pruning strate-gies in Lewis and Steedman (2014) and allow at most 50 categories per word, use a variable-width beam with \u03b2 = 0.00001, and utilize a tag dictio-nary, which maps frequent words to the possible supertags 7 . Unless otherwise stated, we only al-low normal form parses (Eisner, 1996 [URL_CITE] ; Hocken-maier and Bisk, 2010), choosing the same subset of the constraints as Lewis and Steedman (2014).\nFootnote or Reference text (if exists): Jason Eisner. 1996. Efficient Normal-Form Parsing for Combinatory Categorial Grammar. In 34th Annual Meeting of the Association for Computational Lin-guistics. http://aclweb.org/anthology/P96-1011.\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\nCitation Context: ResNeXt WSL We first experiment with im-age representations obtained from pre-training a ResNeXt 32x48d model on nearly 1 billion pub-lic images (Mahajan et al., 2018), with subse-quent fine-tuning on the ImageNet1K dataset (Rus-sakovsky et al., 2015) [URL_CITE] . The output of this model is a 2048-dimensional vector, and we refer to these representations as \u201cResNeXt WSL\" features.\nFootnote or Reference text (if exists): 4 https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\nSection Titles (if exists): [\\'References\\']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code \nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf\nCitation Context: In this paper, we thus propose Multinomial Ad-versarial Networks (henceforth, MANs) for the task of multi-domain text classification. In contrast to standard adversarial networks (Goodfellow et al., 2014) [URL_CITE] , which serve as a tool for minimizing the divergence between two distributions (Nowozin et al., 2016), MANs represent a family of theoret-ically sound adversarial networks that, in contrast, leverage a multinomial discriminator to directly minimize the divergence among multiple proba-bility distributions. And just as binomial adversar-ial networks have been applied to numerous tasks (e.g.\nFootnote or Reference text (if exists): Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in Neural Information Processing Systems 27, Curran Associates, Inc., pages 2672\u20132680. http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/artetxem/monoses\nCitation Context: We thus conclude that, contrary to recent trend, future work in BLI should not focus exclusively in direct retrieval approaches, nor should BLI be the only evaluation task for cross-lingual embeddings. Our code is available at [URL_CITE] https://github.com/artetxem/monoses.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['6 Conclusions and future work']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/rycolab/info-theoretic-probing\nCitation Context: We evaluate on a set of ten typologically diverse languages often under-represented in NLP research\u2014plus English\u2014 totalling eleven languages. Our implementa-tion is available in [URL_CITE] https://github.com/rycolab/info-theoretic-probing.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://workshop2016.iwslt.org/\nCitation Context: We have evaluated these systems over three publicly-available datasets from the 2016 ACL Conference on Machine Translation (WMT16) and the 2016 International Workshop on Spoken Language Translation (IWSLT16) [URL_CITE] . Table 1 lists the datasets and their main features.\nFootnote or Reference text (if exists): 5 IWSLT16: https://workshop2016.iwslt.org/\nSection Titles (if exists):  ['4 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.speech.sri.com/projects/srilm/\nCitation Context: \u2022 language models: Akamon can make use of one or many n-gram language models trained by using SRILM [URL_CITE] (Stolcke, 2002) or the Berke-ley language model toolkit, berkeleylm-1.0b3 (Pauls and Klein, 2011). The weights of multi-ple language models are tuned under minimum error rate training (MERT) (Och, 2003).\nFootnote or Reference text (if exists): 5 http://www.speech.sri.com/projects/srilm/\nSection Titles (if exists):  ['2 Akamon Toolkit Features']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/kaushalshetty/Structured-Self-Attention\nCitation Context: Through the channel-attention network, we can observe the attention matrix A for each input doc-ument. By summing up the attention weights of each word embedding vector, we can visualize the overall attention for that word with the visualiza-tion tool [URL_CITE] . We randomly select three movies from IMDb testing set (See Figure 5).\nFootnote or Reference text (if exists): 5 The visualization tool is provided by https://github.com/kaushalshetty/ Structured-Self-Attention\nSection Titles (if exists):  ['3 Experiments & Analysis', '3.4 More Analysis in Rank-AE']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://blogs.bing.com/search/2013/03/21/understand-your-world-with-bing/\nCitation Context: To identify the replaceable entities, we apply named entity recognition (NER) and POS tag-ging using the Stanford CoreNLP toolkit (Man-ning et al., 2014). We allow for replacement of only those entities that are well-known, according to the Microsoft Knowledge Base [URL_CITE] . This improves the likelihood that the terms are familiar to both headline editors and humor judges.\nFootnote or Reference text (if exists): 1 http://blogs.bing.com/search/2013/03/21/understand-your-world-with-bing/\nSection Titles (if exists):  ['2 The Humor Dataset', '2.1 Task Description']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  DataSource \nFUNCTION: Use \n\n\nLet me explain:\n\n* **TYPE: DataSource**  The URL points to a blog post discussing the Microsoft Knowledge Base. While not the Knowledge Base itself, the blog post provides context and likely"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ilk.uvt.nl/sabine/chunklink/\nCitation Context: 1 Software available at [URL_CITE] http://ilk.uvt.nl/sabine/chunklink/\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['2 Unsupervised Relation Extraction Problem', '2.1 Context Vector and Feature Design']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://youtu.be/bcEysXmR09c\nCitation Context: Ecco is available at https: //www.eccox.io/ . [URL_CITE]\nFootnote or Reference text (if exists): 2 Video demo available at https://youtu.be/ bcEysXmR09c\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Media\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://web.stanford.edu/~jurafsky/ws97/manual.august1.html\nCitation Context: The SwDA cor-pus conforms to the damsl tag schema. [URL_CITE] We as-sembled the tag sets referring to easy damsl (Iso-mura et al., 2009) into 9 tags (Table 2) in order to consolidate tags with a significantly low fre-quency. The SwDA corpus provides transcriptions of 1, 155 conversations with 219, 297 utterances.\nFootnote or Reference text (if exists): 1 https://web.stanford.edu/\u02dcjurafsky/ws97/manual.august1.html\nSection Titles (if exists):  ['4 Experiment', '4.1 Switch Board Dialogue Act Corpus (SwDA)']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aspell.net/\nCitation Context: (2010)). We use the Aspell dictionary (v6.06) [URL_CITE] to determine whether a word is IV, and only include in our normalisation dictionary OOV tokens with at least 64 occurrences in the corpus and character length \u2265 4, both of which were determined through empirical observation. For each OOV word type in the corpus, we select the most similar IV type to form (OOV, IV) pairs.\nFootnote or Reference text (if exists): 2 http://aspell.net/\nSection Titles (if exists):  ['4 Contextually-similar Pair Generation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hohocode.github.io/textSimilarityConvNet/\nCitation Context: Everything necessary to replicate our experimen-tal results can be found in our open-source code repository. [URL_CITE]\nFootnote or Reference text (if exists): 4 http://hohocode.github.io/textSimilarityConvNet/\nSection Titles (if exists):  ['6 Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://nlp.stanford.edu/projects/glove/\nCitation Context: In addition, if the vocabulary for BoW is available, e.g. IMDb and Wiki10, the Word Embedding component is initialized by Glove [URL_CITE] , a pre-trained word embed-dings of 100 dimensions; if it is not, e.g. Medi-amill, Delicious and RCV, a random initialization is employed.\nFootnote or Reference text (if exists): 4 https://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['3 Experiments & Analysis', '3.1 Dataset & Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/hanxiao/bert-as-service\nCitation Context: For experiments with the con-textualized representation, we adopt the pre-trained language model BERT (Devlin et al., 2019) for the four datasets. Specifically, we use bert-as-service (Xiao, 2018) [URL_CITE] to generate the contextualized word representation without fine-tuning. Following Luo et al.\nFootnote or Reference text (if exists): Han Xiao. 2018. bert-as-service. https://github.com/hanxiao/bert-as-service.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.statmt.org/wmt14/translation-task\nCitation Context: We evaluate our method on five widely used benchmark tasks: IWSLT14 German\u2192English translation (IWSLT14 De-En) , WMT16 English\u2194Romanian translation (WMT16 En-Ro/Ro-En) , and WMT14 English\u2194German translation (WMT14 En-De/De-En) [URL_CITE] . We strictly follow the dataset configurations of previous works.\nFootnote or Reference text (if exists): 3 https://www.statmt.org/wmt14/ translation-task\nSection Titles (if exists):  ['5 Experiments', '5.1 Experimental Setup 5.1.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/SussexCompSem/learninghypernyms\nCitation Context: For our evaluation on hyponymy detection, we replicate the experimental setup of Weeds et al. (2014), using their selection of word pairs [URL_CITE] from the BLESS dataset (Baroni and Lenci, 2011). These noun-noun word pairs include positive hy-ponymy pairs, plus negative pairs consisting of some other hyponymy pairs reversed, some pairs in other semantic relations, and some random pairs.\nFootnote or Reference text (if exists): 2 https://github.com/SussexCompSem/ learninghypernyms\nSection Titles (if exists):  ['5 Evaluation', '5.1 Hyponymy with Word2Vec Vectors']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.18653/v1/K17-3014\nCitation Context: Nguyen et al. (2017) [URL_CITE] incorporated a graph-based dependency parser (Kiperwasser and Goldberg, 2016) with POS tagging. Our work followed these lines of effort and improved TAG parsing perfor-mance.\nFootnote or Reference text (if exists): Dat Quoc Nguyen, Mark Dras, and Mark John-son. 2017. A novel neural network model for joint pos tagging and graph-based dependency pars-ing. In CoNLL 2017 Shared Task: Multilin-gual Parsing from Raw Text to Universal Depen-dencies. Association for Computational Linguis-tics, pages 134\u2013142. https://doi.org/10.18653/v1/K17-3014.\nSection Titles (if exists):  ['6 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.ownthink.com\nCitation Context: There are four types of personal information in a Chinese loan application form: \u201cSchool\u201d, \u201cCom-pany\u201d, \u201cResidence\u201d and \u201cBirthPlace\u201d. To generate derived questions, we link all personal information entities to nodes in an existing Chinese KG [URL_CITE] and crawl triplets that are directly related to them. How-ever, owing to the fact that the KG is largely sparse, nearly a half of entities cannot be linked.\nFootnote or Reference text (if exists): 3 https://www.ownthink.com\nSection Titles (if exists):  ['2 Knowledge Graph Constructor']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  DataSource \nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dblp.uni-trier.de/db/journals/corr/corr1805.html#abs-1805-06826\nCitation Context: Propensity score based matching aims to control for most confounding variables by using an ex-ternal method for estimating and controlling for the likelihood of outcomes (Olteanu et al., 2017). More recently, (Wang and Blei, 2018) [URL_CITE] showed that with multiple causal factors, it is possible to lever-age the correlation of those multiple causal fac-tors and deconfound using a latent variable model. This setting is similar to the one we consider, and is guaranteed to be truly causal if there is no con-founder which links a single cause and the out-come.\nFootnote or Reference text (if exists): Yixin Wang and David M. Blei. 2018. The Blessings of Multiple Causes. CoRR abs/1805.06826. http: //dblp.uni-trier.de/db/journals/ corr/corr1805.html#abs-1805-06826\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/nlpyang/PreSumm\nCitation Context: Parameters: We employ pre-trained \u2018albert-xxlarge-v2\u2019 2 and reuse the implementation of PreSumm [URL_CITE] . We train our model (with about 400M parameters) one day for 100,000 steps on GPUs(Nvidia Tesla V100, 32G) with gradient accumulation every two steps.\nFootnote or Reference text (if exists): 3 https://github.com/nlpyang/PreSumm\nSection Titles (if exists):  ['4 Experiments Setting', '4.2 Evaluation Metric & Parameter Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://creativecommons.org/licenses/by-nc-sa/4.0/\nCitation Context: Copyright Act and ensured that our collection action fell under fair use category. We release our dataset under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License [URL_CITE] .\nFootnote or Reference text (if exists): 10 https://creativecommons.org/licenses/by-nc-sa/4.0/\nSection Titles (if exists):  ['8 Ethical Considerations', '8.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  Document \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://pc-erato2.iei.pi.cnr.it/echo\nCitation Context: In particular the project addresses the development of generic speech recognition technology and methods to rapidly port technology to new domains and languages with limited supervision, and to produce en-riched symbolic speech transcriptions. The E CHO project ( [URL_CITE] http://pc-erato2.iei.pi.cnr.it/echo) aims to develop an infrastructure for access to histori-cal films belonging to large national audiovisual archives. The project will integrate state-of-the-art language technologies for indexing, searching and retrieval, cross-language retrieval capabilities and automatic film summary creation.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['8 Recent Research Projects']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cs229.stanford.edu/proj2017/final-reports/5242471.pdf\nCitation Context: As an emerging research problem, text-based per-sonality detection has attracted the attention of both NLP and psychological researchers (Cui and Qi, 2017 [URL_CITE] ; Xue et al., 2018; Keh et al., 2019; Jiang et al., 2020; Tadesse et al., 2018; Lynn et al., 2020).\nFootnote or Reference text (if exists): Brandon Cui and Calvin Qi. 2017. Survey analysis of machine learning methods for natural language processing for mbti per-sonality type prediction. Available on-line: http://cs229.stanford.edu/proj2017/final-reports/5242471.pdf (accessed on 26 May 2021).\nSection Titles (if exists):  ['2 Related Work', '2.1 Personality Detection']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION:  Compare \n\n\nLet me explain:\n\n* **TYPE: Document** - The URL points to a PDF file, which is a common format for research reports and documents.\n* **FUNCTION: Compare** -"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/Friends\nCitation Context: Data Collection For the dyadic Speaker-Addressee Model we used scripts from the American television comedies Friends [URL_CITE] and The Big Bang Theory, available from Internet Movie Script Database (IMSDb). We collected 13 main characters from the two series in a corpus of 69,565 turns. We split the corpus into train-ing/development/testing sets, with development and testing sets each of about 2,000 turns.\nFootnote or Reference text (if exists): 2 https://en.wikipedia.org/wiki/Friends\nSection Titles (if exists):  ['5 Datasets', '5.3 Television Series Transcripts']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://azure.microsoft.com/en-us/services/cognitive-services/spell-check/\nCitation Context: We resolve spelling errors with a public spell checker [URL_CITE] as preprocessing, as Xie et al. (2016) and Sakaguchi et al. (2017) do.\nFootnote or Reference text (if exists): 4 https://azure.microsoft.com/en-us/services/cognitive-services/spell-check/\nSection Titles (if exists):  ['5 Experiments', '5.2 Experimental setting']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dolphin-zs/Doc2EDAG\nCitation Context: Ex-tensive experiments with comprehensive anal-yses illustrate the superiority of Doc2EDAG over state-of-the-art methods. Data and codes can be found at [URL_CITE] https://github.com/dolphin-zs/Doc2EDAG.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ljain2/libsvm-openset\nCitation Context: All documents use tf-idf term weighting scheme with no feature selection. Source code for different baselines (1-vs-Set Machine , W-SVM and P I - SVM [URL_CITE] , and Exploratory learning ) was provided by the authors of their original papers.\nFootnote or Reference text (if exists): 3 https://github.com/ljain2/libsvm-openset\nSection Titles (if exists):  ['4 Experiments', '4.1 Baselines']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.bingiton.com/\nCitation Context: Most notably is a continued study sponsored by Pepsi, known as the Pepsi Challenge , where Pepsi demonstrates how even though people preferred the taste of Pepsi, Coca-Cola\u2019s branding has made it more popular. Even now, Microsoft uses similar blind taste tests [URL_CITE] to compare search en-gines, Bing and Google, showing that although par-ticipants prefer Bing\u2019s results, Google\u2019s brand might have strengthened over the years. These studies all suggest that brand and its associations play impor-tant roles in the customers\u2019 perceptions and deci-sions.\nFootnote or Reference text (if exists): 2 http://www.bingiton.com/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/NP-NET-research/Recursive-Semi-Markov-Model\nCitation Context: Our code is released at [URL_CITE] https://github.com/NP-NET-research/Recursive-Semi-Markov-Model, which is developed on the base of the open-source Berkekey parser (Kitaev and Klein, 2018; Kitaev et al., 2019).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://joshua-decoder.com/language-packs/paraphrase/\nCitation Context: This tool can be used to demonstrate and test a model or to hand-tune the model in order to de-termine the parameters for a configuration file to paraphrase a large batch of sentences. Detailed instructions for using the tool and shell scripts, as well as a detailed description of the config-uration file, are available at the language pack home page: [URL_CITE] http://joshua-decoder.com/language-packs/paraphrase/\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Interactive tool']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://mashable.com/article/snopes-stops-fact-checking-for-facebook/\nCitation Context: On the one hand, it is un-likely fact-checkers are able to check every social media post, due to limited resources and the sheer volume of data. [URL_CITE] On the other hand, a large num-ber of false claims, likely much more than those in traditional media, are being spread through so-cial media. This can be due to the compounded effect of several factors: social media platforms have become increasingly important to public fig-ures and organizations in engaging with voters and citizens; mobile devices have brought an age in which sharing and disseminating information is easy for anyone, including both malicious and un-intentional creators of falsehoods; the falsehoods are further replicated and amplified by social me-dia bots and clickbait articles.\nFootnote or Reference text (if exists): 1 https://mashable.com/article/snopes-stops-fact-checking-for-facebook/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION:  Compare \n\n\nLet me explain:\n\n* **TYPE: Document** - The URL points to a news article, which is a type of document.\n\n* **FUNCTION: Compare** - While the article discusses"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6214\nCitation Context: For example, syntactic knowledge alone tells us that the sentence John, who loves Mary, saw a squirrel entails John saw a squirrel and John loves Mary but not, for in-stance, that John knows Mary or John saw an animal. Prior work found the best performance was achieved with parsers using grammatical frameworks that provided rich linguistic descrip-tions, including CCG (Rimell and Clark, 2010; Ng et al., 2010), Minimal Recursion Semantics (MRS) (Lien, 2014), and TAG (Xu et al., 2017) [URL_CITE] . Xu et al.\nFootnote or Reference text (if exists): Pauli Xu, Robert Frank, Jungo Kasai, and Owen Rambow. 2017. TAG parser evaluation us-ing textual entailments. In TAG+. Association for Computational Linguistics, Umea\u030a, Sweden, pages 132\u2013141. http://www.aclweb.org/anthology/W17-6214.\nSection Titles (if exists):  ['5 Downstream Tasks', '5.1 PETE']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://yjernite.github.io/lfqa.html\nCitation Context: This objective is based on contrastive learning, a method that has been used effectively for semi-supervised learning (Chen et al., 2020) and dense retriever training (Karpukhin et al., 2020). Scaling up from Jernite (2020) [URL_CITE] , who used a mini-batch size of 512 and initialized their retriever with BERT, we use much large mini-batches of size 12,288 (and hence, many more negative examples) and initial-ize our retriever with a strong pretrained retriever, the REALM model (Guu et al., 2020) trained on the Common Crawl News (CC-News) corpus. These design decisions greatly improve retriever qual-ity, as we observe in an ablation study (see Ap-pendix A.2).\nFootnote or Reference text (if exists): Yacine Jernite. 2020. Explain anything like i\u2019m five: A model for open domain long form question answer-ing. https://yjernite.github.io/lfqa.html.\nSection Titles (if exists):  ['2 A state-of-the-art LFQA system', '2.1 Retriever']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  Paper\nFUNCTION: Compare \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/nyu-dl/dl4mt-tutorial\nCitation Context: \u2022 RNNSearchtentional NMT: a re-implementationsystem (Bahdanauof theet alat-., 2015) with slight changes taken from dl4mt tutorial. [URL_CITE] For the activation function f of an RNN, RNNSearch uses the gated recurrent unit (GRU) recently proposed by (Cho et al., 2014b). It incorporates dropout (Hinton et al., 2012) on the output layer and improves the attention model by feeding the lastly gen-erated word.\nFootnote or Reference text (if exists): 8 https://github.com/nyu-dl/ dl4mt-tutorial\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://aka.ms/WikiQA\nCitation Context: We select WikiQA [URL_CITE] as the evaluation data, as it is precisely constructed based on natural language questions and Wikipedia documents, which con-tains 2,118 \u2018question-document\u2019 pairs in the train-ing set, 296 \u2018question-document\u2019 pairs in devel-opment set, and 633 \u2018question-document\u2019 pairs in testing set. Each sentence in the document of a given question is labeled as 1 or 0, where 1 de-notes the current sentence is a correct answer sen-tence, and 0 denotes the opposite meaning.\nFootnote or Reference text (if exists): 6 http://aka.ms/WikiQA\nSection Titles (if exists):  ['7 Experiments', '7.1 Evaluation on QA (English)', '7.1.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://pypi.python.org/pypi/newspaper\nCitation Context: We deduplicated the 16,000 extracted URLs into 6,003 unique addressed, then extracted and preprocessed their contents. The newspaper package [URL_CITE] was used to extract article text and the title from the web page. Since we are interested in text articles that can serve as the source text for summarization algorithms, we needed to re-move photos and video links such as those from Instagram and YouTube.\nFootnote or Reference text (if exists): 2 https://pypi.python.org/pypi/newspaper\nSection Titles (if exists):  ['3 Data Extraction and Preprocessing', '3.2 Extracting Data']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6213\nCitation Context: (2017) and Friedman et al. (2017) [URL_CITE] . For the transition-based parser, it is beneficial to share statistics among the input supertags that differ only by a certain operation or property (Kasai et al., 2017) during the training phase, yielding the success in the analogy task.\nFootnote or Reference text (if exists): Dan Friedman, Jungo Kasai, R. Thomas McCoy, Robert Frank, Forrest Davis, and Owen Rambow. 2017. Linguistically rich vector representations of supertags for TAG parsing. In TAG+. Associa-tion for Computational Linguistics, Umea\u030a, Sweden, pages 122\u2013131. http://www.aclweb.org/anthology/W17-6213.\nSection Titles (if exists):  ['4 Joint Modeling and Network Representations', '4.2 Syntactic Analogies']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION:  Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.lsi.upc.edu/~nlp/IQMT\nCitation Context: This approach has proven very effective in recent eval-uation campaigns. Metric computation has been carried out using the IQ MT Framework for Auto-matic MT Evaluation (Gime\u0301nez, 2007) [URL_CITE] . The sim-plicity of this approach (with no training of the metric weighting scheme) ensures that the poten-tial advantages detected in our experiments are not due to overfitting effects.\nFootnote or Reference text (if exists): 1 http://www.lsi.upc.edu/\u02dcnlp/IQMT\nSection Titles (if exists):  ['3 Metrics and Test Beds', '3.1 Metric Set']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PhilipMay/stsb-multi-mt\nCitation Context: Training Data Table 3 presents statistics on the training data used for supervised and unsuper-vised models across the ST evaluation aspects. For datasets that are only available for EN , we use the already available machine translated re-sources for STS [URL_CITE] and formality datasets (Briakou et al., 2021b). The former employs the DeepL service (no information of translation quality is available) while the latter uses the AWS translation service (with reported BLEU scores of 37.16 ( BR -\nFootnote or Reference text (if exists): 10 https://github.com/PhilipMay/ stsb-multi-mt\nSection Titles (if exists):  ['4 Experiment Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/marian-nmt/marian-examples/blob/master/transformer\nCitation Context: Transformer We used the same training, dev and test sets as in the big RNN model, and the exam-ple configuration for a transformer model from Marian [URL_CITE] adapted to our needs as shown in Table 1. This configuration utilises a six-layer deep encoder and decoder, learning rate warm-up and tied em-beddings for source, target and output layer.\nFootnote or Reference text (if exists): 2 https://github.com/marian-nmt/marian-examples/blob/master/transformer\nSection Titles (if exists):  ['4 Experiment setup', '4.3 Training setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.3115/1118905.1118906\nCitation Context: Computational Linguistics, Stroudsburg, PA, USA, HLT-NAACL-PARALLEL \u201903, pages 1\u201310. [URL_CITE] https://doi.org/10.3115/1118905.1118906.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://crisislex.org/data-collections.html\nCitation Context: To prepare our large multilingual dataset, we ag-gregated several resources from CrisisNLP, to-gether with two resources from CrisisLex. [URL_CITE] Specif-ically, we used Resource #1 (Imran et al., 2016a), Resource #4 (Nguyen et al., 2017), Resource #5 (Alam et al., 2018c), and Resource #7 (Alam et al., 2018a) from CrisisNLP, and CrisisLexT6 (Olteanu et al., 2014) and CrisisLexT26 (Olteanu et al., 2015) from CrisisLex. The original classes in each resource, together with the mapping to the new classes included in our data set, can be seen in Table 1.\nFootnote or Reference text (if exists): 3 https://crisislex.org/data-collections.html\nSection Titles (if exists):  ['3 Aggregated Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/TemporalKGTeam/TANGO\nCitation Context: We evaluate our model by performing future link prediction on five tKG datasets [URL_CITE] . We compare TANGO\u2019s performance with several existing meth-ods and evaluate its potential with inductive link prediction and long horizontal link forecasting.\nFootnote or Reference text (if exists): 1 Code and datasets are available at https://github.com/TemporalKGTeam/TANGO. filtered MRR (%) on ICEWS05-15 with regard to dif-ferent \u2206t. preprint arXiv:2012.08492.\nSection Titles (if exists):  ['4 Experiments', '4.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://spacy.io/\nCitation Context: To tackle this challenge, we propose to use a label projection method based on word alignment. Specifically, we first leverage an exist-ing English POS tagger in the spaCy [URL_CITE] library to annotate the English source sentences. We then use the fast_align tool (Dyer et al., 2013) to train a word alignment model on the training data for the En-XX language pair, and use the alignment model to obtain the word-level alignment for the test data.\nFootnote or Reference text (if exists): 14 https://spacy.io/\nSection Titles (if exists):  ['5 Results and Discussion', '5.3 Fine-grained Language Analysis']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/jiachenwestlake/Entity_BERT\nCitation Context: Results on the three datasets show that our method outperforms these methods and achieves the best results, which demonstrates the effec-tiveness of the proposed Char-Entity-Transformer structure for integrating entity information in LM pre-training for Chinese NER. To our knowl-edge, we are the first to investigate how to make use of the scale of the input document text for enhancing NER. Our code and NER datasets are released at [URL_CITE] https://github.com/jiachenwestlake/Entity_BERT.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.d.umn.edu/~tpederse/WSDTutorial.html\nCitation Context: Our proposal is a kind of word-sense disam-biguation (Pedersen and Mihalcea, 2005) [URL_CITE] . The hit pages can provide us with training data for disam-biguating the acronym in question, and the snip-pets in the pages are fed into the learner of a classifier. Features used in classification will be explained in the latter half of this subsection.\nFootnote or Reference text (if exists): Ted Pedersen and Rada. F. Mihalcea, \u201cAdvances in Word Sense Disambiguation,\u201d tutorial at ACL 2005. http://www.d.umn.edu/~tpederse/WSDTutorial.html.\nSection Titles (if exists):  ['2 The proposal']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION: Introduce \n\n\nLet me explain why:\n\n* **TYPE: Document**  The URL points to a tutorial webpage, which is a type of document providing instructions or explanations. \n\n* **FUNCTION: Introduce**"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/complementizer/news-tls\nCitation Context: For a more robust evaluation, we also present a new TLS dataset, which is larger and spans longer time periods than previous datasets. The dataset will be made available at [URL_CITE] https://github.com/complementizer/news-tls.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cogcomp.cs.illinois.edu\nCitation Context: We evaluate the models using a corpus of ESL es-says, annotated [URL_CITE] by native English speakers (Ro-zovskaya and Roth, 2010a). For each preposition (article) used incorrectly, the annotator indicated the correct choice.\nFootnote or Reference text (if exists): 7 The annotation of the ESL corpus can be downloaded from http://cogcomp.cs.illinois.edu.\nSection Titles (if exists):  ['3 Comparison of Algorithms', '3.1 Evaluation Data']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.natcorp.ox.ac.uk/\nCitation Context: Our source corpus is the concatenation of the ukWaC corpus , a mid-2009 dump of the English Wikipedia and the British National Corpus [URL_CITE] . The corpus is tokenized, POS-tagged and lemmatized with TreeTagger (Schmid, 1995) and contains about 2.8 billion tokens. We extracted all statistics at the lemma level, ignoring inflectional information.\nFootnote or Reference text (if exists): 4 http://www.natcorp.ox.ac.uk/\nSection Titles (if exists):  ['3 Method', '3.1 Semantic space', '3.1.1 Source corpus']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/datasets\nCitation Context: Sim-ilarly, the Rotten Tomatoes (RT) (Pang and Lee, 2005) dataset has 5331 positive and 5331 negative review sentences. We use the processed dataset made available by HuggingFace Dataset library 3 (Wolf et al., 2020b) [URL_CITE] .\nFootnote or Reference text (if exists): Thomas Wolf, Quentin Lhoest, Patrick von Platen, Yacine Jernite, Mariama Drame, Julien Plu, Julien Chaumond, Clement Delangue, Clara Ma, Abhishek Thakur, Suraj Patil, Joe Davison, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angie McMillan-Major, Simon Brandeis, Sylvain Gugger, Fran\u00e7ois Lagunas, Lysandre Debut, Morgan Funtow-icz, Anthony Moi, Sasha Rush, Philipp Schmidd, Pierric Cistac, Victor Mu\u0161tar, Jeff Boudier, and Anna Tordjmann. 2020b. Datasets. GitHub. Note: https://github.com/huggingface/datasets.\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mpqa.cs.pitt.edu/lexicons/effectlexicon/\nCitation Context: +E FFECT (x) and -E FFECT (x): We use the +/-effect sense-level lexicon (Choi and Wiebe, 2014) [URL_CITE] to extract the +/-effect events in each sen-tence. The score of +E FFECT (x) is the fraction of that word\u2019s senses that are +effect senses accord-ing to the lexicon, and the score of -E FFECT (x) is the fraction of that word\u2019s senses that are -effect senses according to the lexicon. If a word does not appear in the lexicon, we do not treat it as a +/-effect event, and thus assign 0 to both +E FFECT (x) and -E FFECT (x).\nFootnote or Reference text (if exists): 7 Available at: http://mpqa.cs.pitt.edu/lexicons/effectlexicon/\nSection Titles (if exists):  ['4 PSL for Sentiment Analysis', '4.4 PSL Augmented with +/-Effect Events (PSL3)']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Knowledge\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://towcenter.org/research/lies-damn-lies-and-viral-content/\nCitation Context: It consists of 50K labelled claim-article pairs, com-bining 300 claims with 2,582 articles. The claims and the articles were curated and labeled by jour-nalists in the context of the Emergent Project (Sil-verman, 2015) [URL_CITE] , and the dataset was first proposed by Ferreira and Vlachos (2016), who only classi-fied the claim w.r.t. the article headline instead of the whole article.\nFootnote or Reference text (if exists): Craig Silverman. 2015. Lies, Damn Lies and Viral Content. http: //towcenter.org/research/ lies-damn-lies-and-viral-content/.\nSection Titles (if exists):  ['2 Related Works']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION: Introduce \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/pytorch-pretrained-BERT\nCitation Context: We implement our models using the jiant toolkit, which is in turn built on AllenNLP (Gard-ner et al., 2017) and on a public PyTorch imple-mentation of BERT. [URL_CITE] Appendix A presents addi-tional details.\nFootnote or Reference text (if exists): 4 https://github.com/huggingface/ pytorch-pretrained-BERT\nSection Titles (if exists):  ['5 Models and Experimental Details']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/bert\nCitation Context: As a text encoder, we employed BERT and a Hi-erarchical Attention Network (HAN) (Yang et al., 2016) for generating sentence and document rep-resentation, respectively. For BERT, we used the pre-trained BERT-base [URL_CITE] (d = 768). We imple-mented the HAN following Yang et al.\nFootnote or Reference text (if exists): 7 https://github.com/google-research/bert\nSection Titles (if exists):  ['3 Experiments', '3.3 Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hltfbk.github.io/Excitement-Open-Platform/\nCitation Context: For this base-line, MCTest is again re-casted as an RTE task by converting each question-answer pair into a statement (using Cucerzan and Agichtein (2005)) and then selecting the answer whose statement has the highest likelihood of being entailed by the story. [URL_CITE] (4) The fourth baseline (called LSTM) is taken from Weston et al. (2015).\nFootnote or Reference text (if exists): 5 The BIUTEE system (Stern and Dagan, 2012) available under the Excitement Open Platform http://hltfbk.github.io/Excitement-Open-Platform/ was used for recognizing textual entailment.\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://research.facebook.com/research/-babi/\nCitation Context: Bordes et al. (2015) released the SimpleQuestions data set [URL_CITE] , which consists of 108,442 English questions. Each ques-tion (e.g., What does Jimmy Neutron do?)\nFootnote or Reference text (if exists): 11 https://research.facebook.com/research/-babi/\nSection Titles (if exists):  ['7 Experiments', '7.1 Evaluation on QA (English)', '7.1.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.tau-nlp.org/commonsenseqa\nCitation Context: Resource Copyright This work presents three new resources: MickeyCorpus, X-CODAH, and X-CSQA, which are multilingual extension of the OMCS (Singh et al., 2002) , CSQA (Talmor et al., 2019) [URL_CITE] , and CODAH (Chen et al., 2019) 5 re-spectively. All these three original sources of the data are publicly available for free, and we do not add any additional requirement for accessing our resources.\nFootnote or Reference text (if exists): 4 https://www.tau-nlp.org/commonsenseqa 5 https://github.com/Websail-NU/CODAH\nSection Titles (if exists):  ['* Ethical Considerations']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://answers.yahoo.com/\nCitation Context: Yahoo! An-swers, [URL_CITE] Answers.com, etc. ), which became very popular resources for question answering.\nFootnote or Reference text (if exists): 1 http://answers.yahoo.com/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/Wikipedia:Translation\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles [URL_CITE] (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks.\nFootnote or Reference text (if exists): 4 http://en.wikipedia.org/wiki/Wikipedia:Translation\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/OnlpLab/morphodetection\nCitation Context: We conclude that bootstrapping datasets for in-flectional morphology in low-resourced languages, is a viable strategy to be adopted and explored. [URL_CITE]\nFootnote or Reference text (if exists): 3 Our code is available on https://github.com/OnlpLab/morphodetection.\nSection Titles (if exists):  ['table, given a few forms of the same lexeme. 2']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/stanfordnlp/treelstm\nCitation Context: Our experiments show that Tree-LSTMs outper-form existing systems and sequential LSTM base-lines on both tasks. Implementations of our mod-els and experiments are available at [URL_CITE] https://github.com/stanfordnlp/treelstm.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://L2R.cs.uiuc.edu/~cogcomp/software.php\nCitation Context: We used the state-of-the-art coreference resolution system of (Bengtson and Roth, 2008) to identify the canonical entities for pronouns and extract features accordingly. For word deletion, we use only the POS tags of the corresponding tokens (generated by the LBJ POS tagger [URL_CITE] ) to generate features. For edge the entailment and paraphrase identification tasks.\nFootnote or Reference text (if exists): 3 http://L2R.cs.uiuc.edu/\u02dccogcomp/software.php\nSection Titles (if exists):  ['5 Experiments', '5.2 Textual Entailment']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.ldc.upenn.edu/collaborations/past-projects/ace\nCitation Context: Besides employing active learning to create spe-cific data set with nested, overlapping, discontinu-ous entity mentions, we notice that there are some off-the-shelf corpora in biomedical domain that we can use to evaluate our proposed methods, al-though, to our knowledge, none of these data sets contains all three kinds of complex mentions, e.g., GENIA (Kim et al., 2003) only contains nested en-tity mentions, and CADEC (Karimi et al., 2015) and SemEval2014 (Pradhan et al., 2014) contain overlapping and discontinuous mentions. In ad-dition, ACE [URL_CITE] and NNE (Ringland, 2016) are newswire corpora with nested entity mentions.\nFootnote or Reference text (if exists): 1 https://www.ldc.upenn.edu/collaborations/past-projects/ace\nSection Titles (if exists):  ['4 Research Plan']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://crowdflower.com\nCitation Context: To answer these questions, we also conduct a human judges study on Crowdflower [URL_CITE] . We se-lect 200 items at random (100 real reviews and 100 from the conditional model, half of each with meta-information), and ask annotators to rate them as real or fake.\nFootnote or Reference text (if exists): 6 https://crowdflower.com\nSection Titles (if exists):  ['4 Experiments', '4.2 Human Judges']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lair.cse.msu.edu/lair/projects/actioneffect.html\nCitation Context: This opens up the possibility for humans to teach robots new tasks through language communication with a small number of examples. Third, we have cre-ated a dataset for this task, which is available to the community [URL_CITE] . Our bootstrapping approach can serve as a baseline for future work on this topic.\nFootnote or Reference text (if exists): 1 This dataset is available at http://lair.cse.msu.edu/lair/projects/actioneffect.html\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://u.cs.biu.ac.il/~nlp/resources/downloads/\nCitation Context: We ob-serve similar trends to previously published results, and make the dataset splits available for replication. [URL_CITE]\nFootnote or Reference text (if exists): 1 http://u.cs.biu.ac.il/~nlp/resources/downloads/\nSection Titles (if exists):  ['2 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/clab/dynet\nCitation Context: NMT Models. We implemented our continuous-optimisation based decoding method on top of the Mantidae toolkit (Cohn et al., 2016), and using the dynet deep learning library [URL_CITE] (Neubig et al., 2017). All neural network models were configured with 512 input embedding and hidden layer dimensions, and 256 alignment dimension, with 1 and 2 hidden layers in the source and target, respectively.\nFootnote or Reference text (if exists): 5 https://github.com/clab/dynet\nSection Titles (if exists):  ['5 Experiments', '5.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google/flax\nCitation Context: We have used Flax, an open-source library [URL_CITE] to train neural networks, as the code base for the model training. Our H-Transformer-1D model uses the standard Transformer decoder implemen-tation in Flax as the backbone.\nFootnote or Reference text (if exists): 8 https://github.com/google/flax\nSection Titles (if exists):  ['8 Experiments And Results', '8.2 Language Models Trained on One-Billion Words']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/moses/giza/GIZA++.html\nCitation Context: As seen from Table 2, the translation based methods outperforms the baseline signifi-cantly. The models are trained using GIZA++ [URL_CITE] tool with the question and best answer pair as the parallel corpus. For the topic based Q-A topic model and Q-A topic model(s), we implemented the models QATM -PR (Question-Answer Topic Model) Ji et al.\nFootnote or Reference text (if exists): 12 http://www.statmt.org/moses/giza/GIZA++.html\nSection Titles (if exists):  ['8 Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dianping.com\nCitation Context: Besides, experts\u2019 prior knowledge or de-velopers\u2019 ingenuity is not always reliable with the variations of domains and languages. For exam-ple, based on the datasets from Dianping site [URL_CITE] , Li et al. (2015) find that the real users tend to review the restaurants nearby, but the spammers are not re-stricted to the geographical location, they may come from anywhere.\nFootnote or Reference text (if exists): 4 http://www.dianping.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION:  Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mstparser.sourceforge.net\nCitation Context: The parser is basically based on the MSTParser [URL_CITE] using all the features presented by (McDonald et al., 2006) with projective parsing. Moreover, we exploit three types of additional features to im-prove the parser.\nFootnote or Reference text (if exists): 8 It\u2019s freely available at http://mstparser.sourceforge.net.\nSection Titles (if exists):  ['5 Evaluation Results', '5.1 Syntactic Dependency Parsers']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tuzhaopeng/NMT-Coverage\nCitation Context: Experiments show that the proposed approach significantly im-proves both translation quality and align-ment quality over standard attention-based NMT. [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code is publicly available at https://github.com/tuzhaopeng/NMT-Coverage.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://academicworks.cuny.edu/gc\nCitation Context: A survey of recent work of several researchers on producing animations of sign language with fa-cial expressions appears in (Kacorri, 2015) [URL_CITE] . There is recent interest in data-driven approaches using facial motion-capture of human performances to generate sign language animations: For example, (Schmidt et al., 2013) used clustering techniques to select facial expressions that co-occur with indi-vidual lexical items, and (Gibet et al., 2011) stud-ied how to map facial motion-capture data to ani-mation controls.\nFootnote or Reference text (if exists): Hernisa Kacorri. 2015. Tr-2015001: A sur-vey and critique of facial expression syn-thesis in sign language animation. Tech-nical report, The Graduate Center, CUNY. http://academicworks.cuny.edu/gc cs tr/403.\nSection Titles (if exists):  ['1 Introduction and Motivation', '1.2 Prior Work']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.mat.unical.it/OlexSuite/Datasets/SampleDataSets-about.htm\nCitation Context: : Computer, Recreation, Science, Pol-itics, Religion. The corresponding five down-stream tasks are text classification over the 3\u2013 [URL_CITE] fine-grained classes under each top-level class. Train, test, dev splits were 50%, 40%, 10%.\nFootnote or Reference text (if exists): 5 https://www.mat.unical.it/OlexSuite/Datasets/SampleDataSets-about.htm\nSection Titles (if exists):  ['Topics and tasks']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt17/\nCitation Context: Following recent unconditional long text genera-tion work (Caccia et al., 2018), we perform exper-iments on EMNLP2017 WMT News dataset [URL_CITE] . All sentences are longer than 20, making the dataset appropriate for testing the exposure bias problem.\nFootnote or Reference text (if exists): 3 http://www.statmt.org/wmt17/\nSection Titles (if exists):  ['4 Experiments', '4.3 Neural Language Generation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://en.wikipedia.org/wiki/English_grammar#Semantic_gradability\nCitation Context: \u2022 Notgood,quantifiablebetter, best etcgradable. usually [URL_CITE] wordsmake sucha claimas bald, as there is no qualified definition of being good or better.\nFootnote or Reference text (if exists): 3 http://en.wikipedia.org/wiki/English_ grammar#Semantic_gradability\nSection Titles (if exists):  ['3 Annotation Scheme']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/YerevaNN/WARP\nCitation Context: In this paper, we introduce a novel technique to find optimal prompts. We call our method WARP: Word-level Adversarial RePrograming [URL_CITE] . The method is inspired by adversarial reprogramming (Elsayed et al., 2019) \u2014 a method of adding ad-versarial perturbations to an input image that re-programs a pretrained neural network to perform classification on a task other than the one it was originally trained for.\nFootnote or Reference text (if exists): 1 Our implementation is publicly available at: https: //github.com/YerevaNN/WARP\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/swift-coreml-transformers\nCitation Context: Models can use adapters to convert models to CoreML weights that are suit-able to be embedded inside a iOS application, to enable on-the-edge machine learning. Code is also made available [URL_CITE] . Similar methods can be used for Android devices.\nFootnote or Reference text (if exists): 3 https://github.com/huggingface/ swift-coreml-transformers\nSection Titles (if exists):  ['5 Deployment']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.lsi.upc.edu/asiya/\nCitation Context: While standard algorithms can be used to build prediction models, key to this task is work of feature engineering. Two open source feature extraction toolkits are available for that: A SIYA [URL_CITE] and Q U E ST (Specia et al., 2013). The latter has been used as the official baseline for the WMT shared tasks and extended by a number of partic-ipants, leading to improved results over the years (Callison-Burch et al., 2012; Bojar et al., 2013; Bojar et al., 2014).\nFootnote or Reference text (if exists): 1 http://nlp.lsi.upc.edu/asiya/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.waikato.ac.nz/ml/weka/\nCitation Context: Given these features, as well as actual F-scores computed for the development data, we use supervised learning to set the feature weights. To this end, we use SVM-Regression [URL_CITE] (Smola and Schoelkopf, 1998) with an RBF kernel, to learn the feature weights and build our predictor system. We validate the accuracy of the predictor trained in this fashion on both WSJ (Section 4) and the Brown cor-pus (Section 5).\nFootnote or Reference text (if exists): 2 Weka software (http://www.cs.waikato.ac.nz/ml/weka/)\nSection Titles (if exists):  ['2 Related Work and Experimental Framework']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/saffsd/langid.py\nCitation Context: We extract texts written by learners who learn only English from Lang-8. A language identification tool langid.py [URL_CITE] (Lui and Baldwin, 2011) is then used to obtain purely English sentences. In addition, we remove noisy source-target sentence pairs in Lang8 where the ratio of the lengths of the source and target sentences is outside [0.5, 2.0], or their word overlap ratio is less than 0.2.\nFootnote or Reference text (if exists): 1 https://github.com/saffsd/langid.py\nSection Titles (if exists):  ['6 Data and Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.macmillandictionary.com/dictionary/american/\nCitation Context: In con-trast, the meaning to experience something bad of to go through [a situation] (ibid., (7)), or the sense to do/conduct of to get [something] done (ibid., (5)), are strongly conventionalized, as indicated by their inclusion in dictionaries. [URL_CITE]\nFootnote or Reference text (if exists): 4 e.g., https://www.macmillandictionary.com/dictionary/american/go-through#go-through 7, https://www.macmillandictionary.com/dictionary/american/ get#get 60\nSection Titles (if exists):  ['3 Corpus', '3.3 Analysis']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  Website \nFUNCTION:  Compare \n\n\nLet me explain:\n\n* **TYPE: Website:** The URL points to a dictionary website (Macmillan Dictionary).\n* **FUNCTION: Compare:** The citation is used to support the claim"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.statmt.org/wmt15/\nCitation Context: (2016) demonstrated that bpe boosts NMT, so sim-ilar to CDNMT we also preprocess the source side of our corpora using bpe. We use WMT-15 corpora [URL_CITE] to train the models, newstest-2013 for tuning and newstest-2015 as the test sets. For English\u2013Turkish (En\u2013Tr) we use the OpenSubtitle2016 collection (Lison and Tiedemann, 2016).\nFootnote or Reference text (if exists): 1 http://www.statmt.org/wmt15/\nSection Titles (if exists):  ['4 Experimental Study', '4.1 Experimental Setting']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://verbs.colorado.edu/semlink/\nCitation Context: The wide coverage of VN in SimVerb-3500 assures the wide coverage of distinct verb groups/classes and their related linguistic phenom-ena. Finally, VerbNet enables further connections of SimVerb-3500 to other important lexical resources such as FrameNet (Baker et al., 1998), WordNet (Miller, 1995), and PropBank (Palmer et al., 2005) through the sets of mappings created by the SemLink project initiative (Loper et al., 2007). [URL_CITE]\nFootnote or Reference text (if exists): 7 https://verbs.colorado.edu/semlink/\nSection Titles (if exists):  ['3 The SimVerb-3500 Data Set', '3.2 Choice of Verb Pairs and Coverage']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  Knowledge \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2012T21\nCitation Context: To unsupervisedly pre-train our document model H IBERT (see Section 3.2 for details), we created the GIGA-CM dataset (totally 6,626,842 documents and 2,854 million words), which in-cludes 6,339,616 documents sampled from the En-glish Gigaword [URL_CITE] dataset and the training split of the CNNDM dataset. We used the validation set of CNNDM as the validation set of GIGA-CM as well.\nFootnote or Reference text (if exists): 4 https://catalog.ldc.upenn.edu/LDC2012T21\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://casmacat.eu/corpus/\nCitation Context: Our data comes primarily from WikiMatrix (Schwenk et al., 2019), Global Voices, [URL_CITE] EuroParl\nFootnote or Reference text (if exists): 5 http://casmacat.eu/corpus/ Bootstrap resampling (Koehn, 2004; Graham et al., global-voices.html 2014) is used to estimate confidence intervals for\nSection Titles (if exists):  ['1 Introduction', '4.2 Model Training']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://readium.org\nCitation Context: Mobile versions of MTTR are built using Apache Cordova \u2013 a cross-platform toolkit \u2013 with platform-specific modifications where nec-essary. The reading and listening components in all versions are built on top of Readium [URL_CITE] , a robust, standards-compliant, and open-source e-reader. Figure 1 shows a screenshot of the iOS version of MTTR.\nFootnote or Reference text (if exists): 4 https://readium.org\nSection Titles (if exists):  ['3 My Turn To Read App']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://visionandlanguage.net/VIST/dataset.html\nCitation Context: SIND, ROCStory: SIND is a visual storytelling dataset [URL_CITE] (Huang et al., 2016), which is re-leased as training/validation/testing following the 8:1:1 split. ROCStory is a commonsense story dataset (Wang and Wan, 2019; Mostafazadeh et al., 2016).\nFootnote or Reference text (if exists): 3 http://visionandlanguage.net/VIST/dataset.html\nSection Titles (if exists):  ['3 Experiments', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.aclweb.org/anthology/D17-1180\nCitation Context: Indeed, Kasai et al. (2017) [URL_CITE] and Friedman et al. (2017) demonstrated that their unlexicalized neural network TAG parsers that only get as in-put predicted supertags can achieve state-of-the-art performance, with lexical inputs providing no improvement in performance.\nFootnote or Reference text (if exists): Jungo Kasai, Robert Frank, Tom McCoy, Owen Rambow, and Alexis Nasr. 2017. TAG pars-ing with neural networks and vector representa-tions of supertags. In EMNLP. Association for Computational Linguistics, Copenhagen, Denmark, pages 1713\u20131723. https://www.aclweb.org/anthology/D17-1180.\nSection Titles (if exists):  ['2 Our Models', '2.2 Parsing Model', '2.2.1 Input Representations']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://kkma.snu.ac.kr/\nCitation Context: The Domain of this corpus cov-ers typical news articles such as health, entertain-ment, technology, politics, world and others. We ran Kokoma Korean morpheme analyzer [URL_CITE] on each sentence of the Donga corpus to divide words into morphemes to build latent morpheme representa-tions.\nFootnote or Reference text (if exists): 4 http://kkma.snu.ac.kr/\nSection Titles (if exists):  ['6 Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://gun-violence.org/\nCitation Context: We also thank the students of the University of Pennsylvania\u2019s crowdsourcing class (NETS 213) for their involvement in building and testing a useful crowdsourcing pipeline for in-formation extraction. Finally, we thank the devel-opers at 10clouds for the excellent engineering and design of [URL_CITE] http://gun-violence.org/. Amit Singhal.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Acknowledgement \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/andy194673/nlg-sclstm-multiwoz\nCitation Context: The best model for both datasets was found through a grid search over a set of hyper-parameters such as the size of embeddings, learn-ing rate, and number of LSTM layers. [URL_CITE]\nFootnote or Reference text (if exists): 6 The model is publicly available at https://github.com/andy194673/ nlg-sclstm-multiwoz\nSection Titles (if exists):  ['5 MultiWOZ as a New Benchmark', '5.3 Dialogue-Act-to-Text Generation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION:  Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.psychpark.org\nCitation Context: Then, the CIP randomly selects one seed pattern per run without replacement from the seed set, and iteratively induces relevant patterns from the psychiatry web corpora. The psychiatry web corpora used here include some professional mental health web sites, such as PsychPark ( [URL_CITE] http://www.psychpark.org) (Bai, 2001) and John Tung Foundation (http://www.jtf.org.tw).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Experimental Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.sogou.com/labs/dl/c.html\nCitation Context: Data preparation The data is composed of two parts: source documents and background knowl-edge. For source documents, we use a publicly available Chinese corpus which consists of 17,199 documents and 13,719,428 tokens extracted from Internet news [URL_CITE] including 9 topics: Finance, IT, Health, Sports, Travel, Education, Jobs, Art, Mil-itary. We then randomly but equally select 600 articles as the set of source documents from 9 top-ics without data bias.\nFootnote or Reference text (if exists): 2 http://www.sogou.com/labs/dl/c.html\nSection Titles (if exists):  ['5 Experiments', '5.1 Evaluation as a ranking problem']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.aclweb.org/anthology/D17-1180\nCitation Context: This concatenation af-ter each layer differs from Kasai et al. (2017) [URL_CITE] and Lewis et al. (2016), where concatenation happens only after the final BiLSTM layer.\nFootnote or Reference text (if exists): Jungo Kasai, Robert Frank, Tom McCoy, Owen Rambow, and Alexis Nasr. 2017. TAG pars-ing with neural networks and vector representa-tions of supertags. In EMNLP. Association for Computational Linguistics, Copenhagen, Denmark, pages 1713\u20131723. https://www.aclweb.org/anthology/D17-1180.\nSection Titles (if exists):  ['2 Our Models', '2.1 Supertagging Model', '2.1.2 Deep Highway BiLSTM']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/andreasvc/disco-dop\nCitation Context: We evaluate our parser on the test sets of the three treebanks. We report F-measure and discontinuous F-measure as computed using the disco-dop tool [URL_CITE] with standard parameters in Table 2. ants of our parsers produced exactly the same re-sults in all settings. This may be expected as their cover of the original treebanks are almost similar.\nFootnote or Reference text (if exists): 11 https://github.com/andreasvc/ disco-dop\nSection Titles (if exists):  ['4 Experiments', '4.3 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL: http://www.cs.jhu.edu/~mdredze/datasets/sentiment/\nCitation Context: Sentiment analysis. The sentiment analysis datasets we examined include movie reviews (Pang and Lee, 2004; Zaidan and Eisner, 2008) , floor speeches by U.S. Congressmen deciding \u201cyea\"/\u201cnay\" votes on the bill under discussion (Thomas et al., 2006) 3 and product reviews from Amazon (Blitzer et al., 2007) [URL_CITE] .\nFootnote or Reference text (if exists): 4 http://www.cs.jhu.edu/~mdredze/datasets/sentiment/\nSection Titles (if exists): [\\'4 Experiments\\', \\'4.1 Datasets\\']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1016/j.knosys.2019.105210\nCitation Context: CheckList enabled generating new (perturbed) test samples through abstracting different test types aimed at testing linguistic capabilities. Other studies focused on evaluating robustness to perturbed inputs for machine translation (Belinkov and Bisk, 2018; Niu et al., 2020), perturbation sensitivity analysis for detecting unintended model biases (Prabhakaran et al., 2019), or robustness to adversarial perturbations (Alshemali and Kalita, 2020 [URL_CITE] ; Ebrahimi et al., 2018; Liang et al., 2018). However, a comprehensive methodology for evaluating the performance of NLP models under real-world conditions is still missing.\nFootnote or Reference text (if exists): Basemah Alshemali, and Jugal Kalita. 2020. Improving the Reliability of Deep Neural Networks in NLP: A Review. Knowledge-Based Systems, 191: 105210. https://doi.org/10.1016/j.knosys.2019.105210.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/domluna/memn2n\nCitation Context: For MemN2N, we use the publicly available im-plementation [URL_CITE] and train it exactly as all other mod-els (same optimizer, total epochs, and early stop-ping criteria) for fairness. While the reported best result for MemN2N is on the version with posi-tion encoding, linear start training, and random-injection of time index noise (Sukhbaatar et al., 2015), the version we use has only position encod-ing. Note that the comparison is still meaningful because linear start training and time index noise are not used in DMN+ (and as a result, neither in our proposed DSMN).\nFootnote or Reference text (if exists): 2 https://github.com/domluna/memn2n\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/clab/lstm-parser/tree/easy-to-use\nCitation Context: DeepCx is implemented using a refactored version of the LSTM parser codebase that performs iden-tically to the original. [URL_CITE] The neural network frame-work, which also underlies the LSTM parser, is an early version of DyNet (Neubig et al., 2017). The LSTM parser model is pretrained on the usual Penn Treebank (Marcus et al., 1994) sections (training: 02\u201321; development: 22).\nFootnote or Reference text (if exists): 2 https://github.com/clab/lstm-parser/tree/easy-to-use.\nSection Titles (if exists):  ['5 DeepCx neural network architecture', '5.3 Implementation details']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/anjalief/unsupervised_gender_bias\nCitation Context: Ulti-mately, our work offers a way to capture subtle biases in various domains without relying on subjective human judgements. [URL_CITE]\nFootnote or Reference text (if exists): 1 Code and pre-trained models are available at https: //github.com/anjalief/unsupervised_ gender_bias\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/quankiquanki/\nCitation Context: Product Review Domains (Websis-CLS-10,(Prettenhofer and Stein, 2010)), CLCD English-German S-T D-B M-B B-D M-D B-M D-M English-French All D-B M-B B-D M-D B-M D-M All PBLM Models P+BE 78.7 78.6 80.6 79.2 81.7 78.5 PBLM 70.9 62.9 74.5 66.5 75.0 75.5 Lazy 74.8 74.0 75.1 72.8 73.3 73.7 79.5 81.1 74.7 76.3 75.0 75.1 76.8 76.5 71.0 76.0 67.9 70.3 69.9 67.3 70.4 70.3 73.9 74.2 73.1 75.3 74.4 74.1 72.4 73.9 Autoencoder+pivot Models A-S-SR 68.3 62.5 69.4 69.9 70.2 69 A-SCL 67.9 63.7 68.7 63.8 69.0 70.1 67.4 69.3 68.9 70.9 70.7 67 71.4 69.7 67.2 68.6 66.1 69.2 69.4 66.7 68.1 68.0 Pivot-based (no DNN) Models C-SCL 65.9 62.5 65.1 65.2 71.2 69.8 DCI 67.1 60.6 66.9 66.7 68.9 68.2 66.7 70.3 63.8 68.8 66.8 66.0 70.1 67.6 66.4 71.2 65.4 69.1 67.5 66.7 71.4 68.6 CLCD without CD Learning CNN 62.8 63.8 65.3 68.7 71.6 72.0 67.3 69.5 59.7 63.7 65.7 65.9 67.0 65.2 Airline (English, (Nguyen, 2015) [URL_CITE] ) to Product Review Domains (German or French), CLCD English-German English-French Source-Target A-B A-D A-M All A-B A-D A-M All PBLM Models P+BE 64 6. 65.167.9 62.5 63.6 63.5 66.9 64.8 PBLM 60.9 59.6 60.1 .60 2 60.9 61.9 58.9 60.5 Lazy 66.3 65.0 66.6 66 0.\nFootnote or Reference text (if exists): Quang Nguyen. 2015. The airline review dataset. https://github.com/quankiquanki/skytrax-reviews-dataset. Scraped from www.airlinequality.com.\nSection Titles (if exists):  ['6 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/SapienzaNLP/sgl\nCitation Context: Furthermore, we find that mod-els trained under this configuration scale re-markably well to tasks such as cross-lingual AMR parsing: SGL outperforms all its com-petitors by a large margin without even explic-itly seeing non-English to AMR examples at training time and, once these examples are in-cluded as well, sets an unprecedented state of the art in this task. We release our code and our models for research purposes at [URL_CITE] https: //github.com/SapienzaNLP/sgl.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We initialized our word representations using publicly available 300-dimensional Glove vec-tors [URL_CITE] (Pennington et al., 2014). For the sentiment classification task, word representations were up-dated during training with a learning rate of 0.1. For the semantic relatedness task, word represen-tations were held fixed as we did not observe any significant improvement when the representations were tuned.\nFootnote or Reference text (if exists): 5 Trained on 840 billion tokens of Common Crawl data, http://nlp.stanford.edu/projects/glove/.\nSection Titles (if exists):  ['5 Experiments', '5.3 Hyperparameters and Training Details']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tuetschek/e2e-cleaning\nCitation Context: It uses modified regu-lar expressions from the e2e-cleaning repos-itory. [URL_CITE] https://github.com/tuetschek/ e2e-cleaning\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/JasperGuo/Unimer\nCitation Context: We plan to cover more domains and more MRs in U NIMER . We have made U NIMER along with the execution engines publicly available. [URL_CITE] We be-lieve that U NIMER can provide fertile soil for ex-ploring MRs and addressing challenges in semantic parsing.\nFootnote or Reference text (if exists): 3 Our benchmark, execution engines and and our im-plementation can be found on: https://github.com/JasperGuo/Unimer\nSection Titles (if exists):  ['3 Benchmark']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.sapere.it/sapere/dizionari\nCitation Context: We identify cognate pairs be-tween Romanian and six other languages: Ital-ian, French, Spanish, Portuguese, Turkish and En-glish. We use electronic dictionaries [URL_CITE] to extract etymology-related information and Google Trans-late to translate Romanian words. We are re-stricted in our investigation by the available re-sources, but we plan to extend our method to other related languages as well.\nFootnote or Reference text (if exists): 4 Italian: http://www.sapere.it/sapere/dizionari\nSection Titles (if exists):  ['2 Methodology and Algorithm', '2.2 Algorithm', '2.2.2 Relationships Identification']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.bbc.com/news/technology-24299742\nCitation Context: However, the question remains: is every online review trustful? It has been reported that up to 25% of the reviews on Yelp.com could be fraudu-lent [URL_CITE] . Due to the great profit or reputation, impostors or spammers energetically post fake reviews on the web to promote or defame targeted products (Jindal and Liu, 2008).\nFootnote or Reference text (if exists): 1 http://www.bbc.com/news/technology-24299742\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ai.mit.edu/people/jrennie/20_newsgroups/\nCitation Context: All methods are initialized by a ran-dom choice of 10 document labels and 10 word la-bels. For simplicity, we follow the widely used cost model (Raghavan and Allan, 2007; Druck et al., 2008; Sindhwani et al., 2009) where features are roughly 5 times cheaper to label than examples, so we assume the cost is [URL_CITE] for a word query and is 5 for a document query. We set \u03b1 = \u03b2 = 5, \u03b3 = 1 for all the following experiments 2 .\nFootnote or Reference text (if exists): 1 http://www.ai.mit.edu/people/jrennie/20_newsgroups/\nSection Titles (if exists):  ['6 Experiments', '6.1 Experiments Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/duyvuleo/Transformer-DyNet\nCitation Context: The dropout rate for the output layer is set to 0.2. For the Transformer, we use Transformer-DyNet [URL_CITE] implementation and extend it for our context-aware NMT model. The hidden dimensions and feed-forward layer size is set to 512 and 2048 respectively.\nFootnote or Reference text (if exists): 7 https://github.com/duyvuleo/Transformer-DyNet\nSection Titles (if exists):  ['4 Experiments', '4.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://spacy.io\nCitation Context: Implementation details: The spaCy tool [URL_CITE] is used to tokenize the both passages and questions, and generate lemma, part-of-speech and named entity tags. We use 2-layer BiLSTM with d = 128 hidden units for both passage and question encod-ing.\nFootnote or Reference text (if exists): 2 https://spacy.io\nSection Titles (if exists):  ['3 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.delph-in.net/crawler/\nCitation Context: All numbers reported here reflect this frozen system. [URL_CITE]\nFootnote or Reference text (if exists): 10 The code and data are available from http://www.delph-in.net/crawler/ , for replicability (Fokkens et al., 2013).\nSection Titles (if exists):  ['4 Experiments', '4.1 Data Sets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool \nFUNCTION: Produce \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/awslabs/fever\nCitation Context: We also conducted oracle experiments in which com-ponents of the pipeline were replaced by the gold standard annotations, and observed that the most challenging part of the task is selecting the sen-tences containing the evidence. In addition to pub-lishing the data via our website , we also publish the annotation interfaces [URL_CITE] and the baseline system to stimulate further research on verification.\nFootnote or Reference text (if exists): 2 https://github.com/awslabs/fever\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/cosmozhang/Modular_Neural_CRF\nCitation Context: All of our models beat the state-of-the-art results by a large margin. The source code and experimental setup are avail-able online [URL_CITE] .\nFootnote or Reference text (if exists): 4 https://github.com/cosmozhang/ Modular_Neural_CRF\nSection Titles (if exists):  ['6 Experimental Evaluation', '6.2 Q1: Monolithic vs. Modular Learning']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://diamt.limsi.fr/eval.html\nCitation Context: We created two contrastive test sets to help com-pare how well different contextual MT mod-els handle (i) anaphoric pronoun translation and (ii) coherence and cohesion. [URL_CITE] For each test set, models are assessed on their ability to rank the cor-rect translation of an ambiguous sentence higher than the incorrect translation, using the disam-biguating context provided in the previous source and/or target sentence. All examples in the test sets are hand-crafted but inspired by real examples from OpenSubtitles2016 (Lison and Tiedemann, 2016) to ensure that they are credible and that vo-cabulary and syntactic structures are varied.\nFootnote or Reference text (if exists): 2 The test sets are freely available at https://diamt.limsi.fr/eval.html.\nSection Titles (if exists):  ['2 Evaluating contextual phenomena', '2.1 Our contrastive discursive test sets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/neukg/GRTE\nCitation Context: Ex-perimental results show our model is effective and it achieves state-of-the-art results on all of these datasets. The source code of our work is available at: [URL_CITE] https://github.com/neukg/GRTE.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.englishbaby.com/lessons/4349/slang/fruitcake\nCitation Context: She is a total fruitcake. [URL_CITE]\nFootnote or Reference text (if exists): 12 http://www.englishbaby.com/lessons/4349/slang/ fruitcake\nSection Titles (if exists):  ['5 Task 2: Finding most similar words for slang across languages', '5.2 Baseline and Our Methods']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\nLet me explain why:\n\n* **TYPE: Website:** The URL points to a website (englishbaby.com), a platform that provides English language learning resources.\n* **FUNCTION: Introduce:** The"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://wapiti.limsi.fr\nCitation Context: De-spite the reduced set of features, training error rate at both token and sentence level is under 1%. We didn\u2019t carry out optimization for parameters \u03c1 1 and \u03c1 [URL_CITE] of the elastic net (see section 3.1), default values lead in most cases to very accurate models.\nFootnote or Reference text (if exists): 2 available at http://wapiti.limsi.fr\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool \nFUNCTION:  Introduce \n\n\nLet me explain:\n\n* **Tool:** The URL points to a website for the Wapiti system, which is a machine learning toolkit. \n* **Introduce:** The citation mentions the Wap"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://plata.ar.media.kyoto-u.ac.jp/tool/EDA\nCitation Context: (2011), as implemented in the Eda toolkit. [URL_CITE] In order to convert dependencies into phrase-structure trees typically used in T2S translation, we use the head rules implemented in the Travatar toolkit. In addition, we also train a latent variable CFG using the Berkeley Parser and use Egret for parsing.\nFootnote or Reference text (if exists): 5 http://plata.ar.media.kyoto-u.ac.jp/tool/EDA\nSection Titles (if exists):  ['3 Parsing', '3.1 Parsing Overview']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/\nCitation Context: For the synthetic dataset training method, we con-sider two QA models: finetuning BERT (Devlin et al., 2018) and BiDAF + Self Attention (Clark and Gardner, 2017). [URL_CITE] For the posterior maximisa-tion method, we extract cloze questions from both sentences and sub-clauses, and use the NMT mod-els to estimate p(q|c,a). We evaluate using the standard Exact Match (EM) and F1 metrics.\nFootnote or Reference text (if exists): 5 We use the HuggingFace implementation of BERT, available at https://github.com/huggingface/ pytorch-pretrained-BERT, and the documentQA implementation of BiDAF+SA, available at https://github.com/allenai/document-qa\nSection Titles (if exists):  ['3 Experiments', '3.1 Unsupervised QA Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs and citations you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dzonesoftware.com/products/open-source-question-answer-software/\nCitation Context: On a different line of research, several Textual-based Question Answering (QA) systems (Qanda , QANUS , QSQA [URL_CITE] etc.) are developed that retrieve answers from the Web and other tex-tual sources.\nFootnote or Reference text (if exists): 7 http://www.dzonesoftware.com/products/open-source-question-answer-software/\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://t.co/XExWwxmjnk#travel\nCitation Context: Tweet Are #Airlines doing enough with #Ebola? [URL_CITE] http://t.co/XExWwxmjnk #travel\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Analysis']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Media \nFUNCTION: Introduce \n\n\nLet me explain:\n\n* **TYPE: Media** -  The URL points to a tweet, which is a form of social media content. \n* **FUNCTION: Introduce** - The citation"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mallet.cs.umass.edu/\nCitation Context: (2009) we use asymmetric \u03b1 and symmetric \u03b2; rather than using fixed values for these hyperparameters we es-timate them from data in the course of LDA train-ing using an EM-like method. [URL_CITE] We use standard set-tings for the number of training iterations (1000), the length of the burnin period before hyperparameter estimation begins (200 iterations) and the frequency of hyperparameter estimation (50 iterations).\nFootnote or Reference text (if exists): 2 We use the estimation methods provided by the MAL-LET toolkit, available from http://mallet.cs.umass.edu/.\nSection Titles (if exists):  ['3 Models', '3.1 Latent variable context models']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.freebase.com/\nCitation Context: Given a structured knowledge base, such as Free-base [URL_CITE] , a single relation question Q (in natural language) with its answer can be first parsed into a fact formatted as he sbj ,rel,e obj i, where e sbj denotes a subject entity detected from the question, rel denotes the relationship expressed by the question, e obj denotes an object entity found from the knowledge base based on e sbj and rel. Then we can get hQ,reli pairs.\nFootnote or Reference text (if exists): 5 http://www.freebase.com/\nSection Titles (if exists):  ['4 Response Ranking', '4.5 Relation-level Feature']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Knowledge\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://alpage.inria.fr/~sagot/lefff-en.html\nCitation Context: The continuous word representations are used to train a logis-tic regression classifier 2 for each morphological feature: gender and number for noun and adjec-tives; tense for verbs (with labels: present, fu-ture, imperfect, or simple past). Word labels are taken from the Lefff French morphological lexicon (Sagot, 2010) [URL_CITE] . To ensure a fair comparison be-tween context-independent and context-dependent embedding classification, words that are ambigu-ous with respect to a given feature are excluded from the respective classifier\u2019s training and test data.\nFootnote or Reference text (if exists): 3 Lexique des Formes Fle\u0301chies du Franc\u0327ais: http://alpage.inria.fr/\u02dcsagot/lefff-en.html\nSection Titles (if exists):  ['2 Methods']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Knowledge\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2007T03\nCitation Context: The experiments were carried out on a Chinese corpus, which consists of one year (2004) of the Xinhua news corpus from LDC [URL_CITE] , containing about 28 millions of Chinese words. Since punc-tuations are rarely used to construct collocations, they were removed from the corpora. To auto-matically estimate the precision of extracted col-locations on the Chinese corpus, we built a gold set by collecting Chinese collocations from handcrafted collocation dictionaries, containing 56,888 collocations.\nFootnote or Reference text (if exists): 2 Available at: http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2007T03\nSection Titles (if exists):  ['3 Initial Experiments', '3.1 Data']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://naudio.codeplex.com/\nCitation Context: The recorder, built using the open-source library NAudio, [URL_CITE] takes the default audio input device as its source and records one channel with a sampling rate of 8 kHz, as the recognition engine we employ is designed for low-quality audio (see Section 4.1).\nFootnote or Reference text (if exists): 8 http://naudio.codeplex.com/\nSection Titles (if exists):  ['5 User interface', '5.1 Audio input and recording']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/natashamjaques/neural_chat/tree/master/BatchRL\nCitation Context: After chatting, users were asked to provide a Likert scale rating of the bot\u2019s conversation quality, fluency, diversity, contingency/relatedness, and empathy. The code for the RL models is available in open-source at [URL_CITE] https://github.com/natashamjaques/neural_chat/tree/master/BatchRL. Using the server, we collected a batch of human interaction data containing 46,061 pairs of user input and agent response.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['4 Learning from talking to humans', '4.2 Hosting real-time conversations online']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://compprag.christopherpotts.net/swda.html\nCitation Context: We use the Switch-board Dialogue Act (SwDA) corpus (Calhoun et al., 2010) in our experiments [URL_CITE] . SwDA contains the transcripts of several people discussing a given topic on the telephone. There are 42 dialogue act tags in SwDA, and we list the 10 most frequent tags in Table 3.\nFootnote or Reference text (if exists): 5 http://compprag.christopherpotts.net/swda.html.\nSection Titles (if exists):  ['4 Experiments', '4.2 Dialogue Act Analysis', '4.2.1 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.jtf.org.tw\nCitation Context: Then, the CIP randomly selects one seed pattern per run without replacement from the seed set, and iteratively induces relevant patterns from the psychiatry web corpora. The psychiatry web corpora used here include some professional mental health web sites, such as PsychPark (http://www.psychpark.org) (Bai, 2001) and John Tung Foundation ( [URL_CITE] http://www.jtf.org.tw).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Experimental Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/lipiji/SongNet\nCitation Context: Extensive experiments conducted on two collected corpora demonstrate that our pro-posed framework generates significantly better results in terms of both automatic metrics and the human evaluation. [URL_CITE]\nFootnote or Reference text (if exists): 1 Code: http://github.com/lipiji/SongNet\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cmu.edu/~yww/data/emnlp2013.zip\nCitation Context: The coffee shop dataset is freely available [URL_CITE] for re-search purposes.\nFootnote or Reference text (if exists): 6 http://www.cs.cmu.edu/\u02dcyww/data/emnlp2013.zip\nSection Titles (if exists):  ['Coffee Shops Reviews']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.5281/zenodo.4064408\nCitation Context: We hope that our public release of data will encourage others to further improve models for this task. [URL_CITE]\nFootnote or Reference text (if exists): 6 Our dataset can be downloaded from https://doi.org/10.5281/zenodo.4064408 and code is available at https://github.com/dgaddy/silent_speech. Samples of predicted outputs can be found in the supplementary material.\nSection Titles (if exists):  ['5 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://azure.microsoft.com/en-us/services/cognitive-services/translator-text-api/\nCitation Context: On the other hand, the test-on-trans(lation) method trains an English sequence tagger, and utilizes MT to translate the test set of each target language into English in order to make predictions. In this work, we adopt the Mi-crosoft Translator [URL_CITE] , a strong commercial MT sys-tem. Note that for a MT system to work for se-quence tagging tasks, word alignment informa-tion must be available, in order to project word-level annotations across languages.\nFootnote or Reference text (if exists): 4 https://azure.microsoft.com/en-us/services/cognitive-services/translator-text-api/\nSection Titles (if exists):  ['4 Experiments', '4.1 Cross-Lingual Semantic Slot Filling', '4.1.1 Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://projectile.sv.cmu.edu/research/public/tools/bootStrap/tutorial.htm\nCitation Context: We calculated statistical significance for the main results on the development section using bootstrap random sampling. [URL_CITE] After re-sampling 1000 times, significance was calculated using a paired t-test (999 d.f.). The results indicated that lp-only exceeded the baseline, lp-ngram and lp-syn exceeded lp-only, and the full model exceeded lp-syn, with p < 0.0001 in each case.\nFootnote or Reference text (if exists): 6 Scripts for running these tests are available at http://projectile.sv.cmu.edu/research/public/tools/bootStrap/tutorial.htm\nSection Titles (if exists):  ['4 Evaluation', '4.2 Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://help.twitter.com/en/rules-and-policies/twitter-limits\nCitation Context: User tweets are simply all the tweets from that user\u2019s Twitter account, and measure perhaps in the thousands. Indeed, the number of tweets per user per day is limited to 2400 per day by current Twitter policy ( [URL_CITE] https://help.twitter.com/en/rules-and-policies/twitter-limits). The negative exam-ples consist of all tweets written by other Twitter users, a total of approximately 500 million per day (https://business.twitter.com).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['2 Problem Formulation', '2.1 Methodology']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document\nFUNCTION:  Introduce \n\n\nLet me explain:\n\n* **TYPE: Document** - The URL points to Twitter's official help page outlining their usage limits. This is a type of document that provides guidelines and information.\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.metaversum.com/\nCitation Context: The KomParse system, described in this paper, provides NPCs for a virtual online world named Twinity, a product of the Berlin startup company Metaversum [URL_CITE] . The KomParse NPCs offer vari-ous services through conversation with game users using question-answering and dialog functional-ity. The utilization of Semantic Web technology with RDF-encoded generic and domain-specific ontologies furthermore enables semantic search and inference.\nFootnote or Reference text (if exists): 1 http://www.metaversum.com/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.itl.nist.gov/iad/mig/tests/mt/\nCitation Context: We choose NIST MT 06 dataset (1664 sentence pairs) as our develop-ment set, and NIST MT 02, 03, 04, and 05 datasets (878, 919, 1788 and 1082 sentence pairs, respec-tively) as our test sets. [URL_CITE] To get the source syn-tax for sentences on the source-side, we parse the Chinese sentences with Berkeley Parser (Petrov and Klein, 2007) trained on Chinese TreeBank 7.0 (Xue et al., 2005). We use the case insensitive 4-gram NIST BLEU score (Papineni et al., 2002) for the translation task.\nFootnote or Reference text (if exists): 5 http://www.itl.nist.gov/iad/mig/tests/mt/\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/moses-smt/mosesdecoder/blob/master/scripts/analysis/boots\nCitation Context: For evaluation, we train all the mod-els with maximum 150k/300k/300k steps for NIST Zh-En, WMT En-De and WMT Zh-En, respec-tively, and we select the model which performs the best on the validation set and report its per-formance on the test sets. We measure the case-insensitive/case-sensitive BLEU scores using multi-bleu.perl with the statistical significance test (Koehn, 2004) [URL_CITE] for NIST Zh-En and WMT\u201914 En-De, respectively. For WMT\u201918 Zh-En, we use case sensitive BLEU scores calculated by Moses mteval-v13a.pl script .\nFootnote or Reference text (if exists): 5 https://github.com/moses-smt/mosesdecoder/blob/master/scripts/analysis/bootstrap-hypothesis-difference-significance. pl\nSection Titles (if exists):  ['4 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.natcorp.ox.ac.uk\nCitation Context: First, we build a co-occurrence based space (DS cooc ), in which a word is represented by co-occurrence counts with content words (nouns, verbs, adjectives and adverbs). As a source corpus, we use a concatenation of the ukWaC, a 2009 dump of the English Wikipedia and the BNC [URL_CITE] , which consists of about 2.8 billion tokens. We select the top 10K content words for the contexts, using a bag-of-words approach and counting co-occurrences within a sentence.\nFootnote or Reference text (if exists): 4 http://wacky.sslmit.unibo.it, http://www.natcorp.ox.ac.uk\nSection Titles (if exists):  ['4 Semantic spaces', '4.1 The distributional semantic space']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://cocolab.stanford.edu/datasets/colors.html\nCitation Context: Our contribution includes a new dataset of hu-man utterances in a color reference game in Man-darin Chinese, which we release to the public [URL_CITE] with our code and trained model parameters. setting up the data collection platform, and mem-bers of the Stanford NLP group\u2014particularly Reid Pryzant, Sebastian Schuster, and Reuben Cohn-Gordon\u2014for valuable feedback on earlier drafts.\nFootnote or Reference text (if exists): 7 https://cocolab.stanford.edu/datasets/colors.html\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://bit.ly/9rs6pa\nCitation Context: (rumor) \u201cRT @johnnyA99 Ann Coulter Tells Larry King Why People Think Obama Is A Muslim [URL_CITE] http://bit.ly/9rs6pa #Hussein via @NewsBusters #tcot ..\u201d\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Problem Definition']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Media \nFUNCTION: Introduce \n\n\nLet me explain:\n\n* **TYPE: Media** - The URL points to a shortened link, likely leading to a tweet containing a statement about Ann Coulter and Barack Obama. This strongly suggests a media"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6214\nCitation Context: We apply three types of transformation from Xu et al. (2017) [URL_CITE] to interpret the TAG parses.\nFootnote or Reference text (if exists): Pauli Xu, Robert Frank, Jungo Kasai, and Owen Rambow. 2017. TAG parser evaluation us-ing textual entailments. In TAG+. Association for Computational Linguistics, Umea\u030a, Sweden, pages 132\u2013141. http://www.aclweb.org/anthology/W17-6214.\nSection Titles (if exists):  ['A.1 Transformations from PETE']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.kaggle.com/c/asap-aes/\nCitation Context: At the outset, our goal is to develop a framework that strengthens the validity of state-of-the-art neu-ral AES approaches with respect to adversarial in-put related to local aspects of coherence. For our experiments, we use the Automated Student As-sessment Prize (ASAP) dataset, [URL_CITE] which contains essays written by students ranging from Grade 7 to Grade 10 in response to a number of different prompts (see Section 4).\nFootnote or Reference text (if exists): 3 https://www.kaggle.com/c/asap-aes/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://demo.patrickpantel.com/\nCitation Context: Consider the set of seed terms S and an errone-ous expanded instance e. In the SIM method of Section 3.1 all set elements that have a feature vec-tor (i.e., context vector) similar to e are removed. The Feature Modification Method (FMM) instead tries to identify the subset of features of the error e which represent the unintended sense of the seed terms S. For example, let S = {Minerva, Neptune, Baccus, Juno, Apollo}. Looking at the contexts of these words in a large corpus, we construct a cen-troid context vector for S by taking a weighted av-erage of the contexts of the seeds in S. In Wikipedia articles we see contexts (i.e., features) such as [URL_CITE] :\nFootnote or Reference text (if exists): 4 The full feature vector for these and all other terms in Wiki-pedia can be found at http://demo.patrickpantel.com/..\nSection Titles (if exists):  ['3 Dynamic Similarity Modeling', '3.2 Feature Modification Method (FMM)']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION:  Introduce \n\n\nThe website provides access to the feature vectors used in the research.  \n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/atschneid/DebugSL\nCitation Context: In this paper we have presented the system DebugSL and described its usage. The project source code is available at [URL_CITE] https://github.com/atschneid/DebugSL and a screencast can be viewed at https://cis.temple.edu/\u02dcedragut/DebugSL.webm. The sys-tem will be deployed online for use by the public.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.imdb.com/\nCitation Context: Thus, our models include movie genre as an additional feature. Genres for each movie were obtained from IMDb [URL_CITE] and transformed into a multi-hot encoding.\nFootnote or Reference text (if exists): 3 https://www.imdb.com/\nSection Titles (if exists):  ['3 Method', '3.3 Role of Movie Genre']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/lancopku/SGM\nCitation Context: We include it as a baseline by using its publicly released code. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/lancopku/SGM\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/\nCitation Context: For all experiments, we use the Word2Vec imple-mentation in Gensim [URL_CITE] to learn the skip-gram model with dimensionality 500 for each language. The CCA code for projecting mono-lingual embeddings is from Faruqui and Dyer (2014) in which the ratio parameter is set to 0.5 (i.e., the resulting multilingual embeddings have dimensionality 250).\nFootnote or Reference text (if exists): 2 https://radimrehurek.com/gensim/\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://youtu.be/-hGd2399dnA\nCitation Context: Nor do they enable iteration; a user cannot revise earlier sen-tences and have the system update later genera-tions. We develop a system [URL_CITE] that allows a user to interact in all of these ways that were limita-tions in previous systems; it enables involvement in planning, editing, iterative revising, and control of novelty. We conduct experiments to understand which types of interaction are most effective for improving stories and for making users satisfied and engaged.\nFootnote or Reference text (if exists): 1 The live demo is at http://cwc-story.isi.edu, with a video at https://youtu.be/-hGd2399dnA. Code and models are available at https://github.com/seraphinatarrant/plan-write-revise.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Media\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ShyamSubramanian/HESM\nCitation Context: Our ex-perimental results show that HESM outper-forms 7 state-of-the-art methods for fact ex-traction and claim verification. Our source code is available at [URL_CITE] https://github.com/ShyamSubramanian/HESM.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.python.org/\nCitation Context: \u2022 Minimal requirements on the underlying server structure: Sisyphus only requires Python 3 [URL_CITE] with a few basic packages and a Unix-type operating system.\nFootnote or Reference text (if exists): 1 https://www.python.org/\nSection Titles (if exists):  ['1 Introduction', '1.2 Design Goals']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/zhanghainan/TailoredSeq2Seq2DifferentConversationScenarios\nCitation Context: We randomly split the data to training, validation, and testing sets, which contains 3,000,000, 388,571 and 400,000 pairs, respectively. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/zhanghainan/TailoredSeq2Seq2 DifferentConversationScenarios\nSection Titles (if exists):  ['5 Experiments', '5.1 Experimental Settings', '5.1.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs and citations you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.yelp.com/dataset/download\nCitation Context: Author profiling (Age dataset ) is to predict the age range of the user by giving their tweets. Sentiment analysis (Yelp dataset [URL_CITE] ) is to predict the number of stars the user assigned to by analysis their reviews. Tex-tual entailment (SNLI dataset 3 ) is to tell whether the semantics in the two sentences are entailment or contradiction or neutral.\nFootnote or Reference text (if exists): 2 https://www.yelp.com/dataset/download\nSection Titles (if exists):  ['B Additional Experimental Details', 'B.1 Self-attentive Sentence Classification']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/xiaochang13/AMR-generation\nCitation Context: Since incorporating unaligned words will introduce noise, we rank the translation candi-dates for each AMR fragment by their counts in the training data, and select the top N candidates. [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code for grammar induction can be downloaded from https://github.com/xiaochang13/AMR-generation\nSection Titles (if exists):  ['2 Method', '2.3 Rule Acquisition']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dmoz.org/\nCitation Context: We set up a spider to download roughly 70 million web pages from the Internet. Initially, we use the links from Open Directory project [URL_CITE] as seed links for our spider. Each webpage is stripped of HTML tags, tokenized, and sentence segmented.\nFootnote or Reference text (if exists): 3 http://www.dmoz.org/\nSection Titles (if exists):  ['4 Building Noun Similarity Lists', '4.1 Web Corpus']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/utils.html\nCitation Context: 20% of randomly selected training instances are used to form development set. We preprocess our English datasets, i.e., Snippets, TagMyNews, and Twit-ter, with gensim tokenizer [URL_CITE] for tokenization. As to the Chinese Weibo dataset, we use FudanNLP toolkit (Qiu et al., 2013) for word segmentation.\nFootnote or Reference text (if exists): 8 https://radimrehurek.com/gensim/utils.html\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlpado.de/~sebastian/data.shtml\nCitation Context: Our projection on the English side results in 53K V and 35K T sentences, of which 731 are labeled as both T and V. Finally, from the English labeled sentences we ex-tracted a training set with 72 novels (63K sentences) and a test set with 21 novels (15K sentences). [URL_CITE]\nFootnote or Reference text (if exists): 4 The corpus can be downloaded for research purposes from http://www.nlpado.de/~sebastian/data.shtml.\nSection Titles (if exists):  ['2 A Parallel Corpus of Literary Texts', '2.3 T/V Gold Labels for English Utterances']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://scikit-learn.org/stable/\nCitation Context: \u2022 Logistic regression classifier: [URL_CITE] http://scikit-learn.org/stable/\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.statmt.org/wmt14/translation-task.html\nCitation Context: 4 We use WMT14 EN-DE translation dataset as the EN-DE sentence-level parallel dataset which consists of 4.4M sentence pairs. [URL_CITE]\nFootnote or Reference text (if exists): 5 https://www.statmt.org/wmt14/translation-task.html\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://fakenewschallenge.org/\nCitation Context: The Fake News challenge (Pomerleau and Rao, 2017) [URL_CITE] modelled verification as stance classifica-tion: given a claim and an article, predict whether the article supports, refutes, observes (neutrally states the claim) or is irrelevant to the claim. It consists of 50K labelled claim-article pairs, com-bining 300 claims with 2,582 articles.\nFootnote or Reference text (if exists): Dean Pomerleau and Delip Rao. 2017. Fake news chal-lenge. http://fakenewschallenge.org/.\nSection Titles (if exists):  ['2 Related Works']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://yjernite.github.io/lfqa.html\nCitation Context: In this section, we describe our proposed LFQA system, which conditions answer generation on Wikipedia articles identified by a pretrained re-triever. We use a dense retriever trained by scaling up a distantly supervised algorithm from Jernite (2020) [URL_CITE] . Since retrieved articles can be quite long and often exceed the maximum sequence length of pretrained models like BERT (Devlin et al., 2019), we use a sparse-attention variant of the Transformer to allow modeling over longer sequences.\nFootnote or Reference text (if exists): Yacine Jernite. 2020. Explain anything like i\u2019m five: A model for open domain long form question answer-ing. https://yjernite.github.io/lfqa.html.\nSection Titles (if exists):  ['2 A state-of-the-art LFQA system']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website \nFUNCTION:  Use \n\n\nLet me know if you have any other URLs you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://tac.nist.gov/2009/Summarization/\nCitation Context: Datasets We use two multi-document summa-rization datasets from the Text Analysis Confer-ence (TAC) shared task: TAC-2008 and TAC-2009. [URL_CITE] TAC-2008 and TAC-2009 contain 48 and 44 topics, respectively. Each topic consists of 10 news articles to be summarized in a maximum of 100 words.\nFootnote or Reference text (if exists): 1 http://tac.nist.gov/2009/Summarization/, http://tac.nist.gov/2008/Summarization/\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://archive.ics.uci.edu/ml\nCitation Context: Since the constraint type is determined by syntactic and dependency parse features, this component does not need to be retrained for new domains. In this work, we trained this classifier based on a manually annotated set of 80 sentences describing classes in the small UCI Zoo dataset (Lichman, 2013) [URL_CITE] , and used this model for all experiments.\nFootnote or Reference text (if exists): M. Lichman. 2013. UCI machine learning repository. http://archive.ics.uci.edu/ml.\nSection Titles (if exists):  ['3 Learning Classifiers from Language', '3.1 Mapping language to constraints', '3.1.1 Semantic Parser components']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.microsoft.com/en-us/download/details.aspx?id=52419\nCitation Context: WikiQA [URL_CITE] is a retrieval-based question answer-ing dataset based on Wikipedia. We follow the data split of original paper.\nFootnote or Reference text (if exists): 6 https://www.microsoft.com/en-us/download/details.aspx?id=52419\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets and Metrics']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://kheafield.com/code/kenlm/\nCitation Context: This pruning is done efficiently through a varia-tion of cube-pruning (Chiang, 2007). We use KenLM [URL_CITE] (Heafield, 2011) for computing the target language model score. Decoding is made more efficient by using some of the more advanced features of KenLM such as state-reduction ((Li and Khudanpur, 2008), (Heafield et al., 2011)) and rest-cost estima-tions(Heafield et al., 2012).\nFootnote or Reference text (if exists): 3 http://kheafield.com/code/kenlm/\nSection Titles (if exists):  ['4 Decoding']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mmihaltz/word2vec-GoogleNews-vectors\nCitation Context: We use the open-domain word embeddings [URL_CITE] for the initialization of word vectors. We initialize other model parameters from a uniform distribu-tion U(-0.05, 0.05).\nFootnote or Reference text (if exists): 1 https://github.com/mmihaltz/word2vec-GoogleNews-vectors\nSection Titles (if exists):  ['6 Experiments', '6.3 Training Details']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/liushulinle/event\nCitation Context: We publish our code for further study by the NLP community. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://github.com/liushulinle/event detection without triggers\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.systransoft.com\nCitation Context: MT systems We test six widely used MT mod-els, representing the state of the art in both commercial and academic research: (1) Google Translate, (2) Microsoft Translator, (3) Amazon Translate, (4) SYSTRAN, [URL_CITE] (5) the model of Ott et al. (2018), which recently achieved the best per-formance on English-to-French translation on the WMT\u201914 test set, and (6) the model of Edunov et al.\nFootnote or Reference text (if exists): 4 http://www.systransoft.com\nSection Titles (if exists):  ['3 Evaluation', '3.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nlm.nih.gov/mesh/meshhome.html\nCitation Context: These nodes have children, for example, Abdomen (A01.047) and Back (A01.176) are level [URL_CITE] children of Body Regions. The longer the ID of the MeSH term, the longer the path from the root and the more precise the description. For example migraine is C10.228.140.546.800.525, that is, C (a disease), C10 (Nervous System Diseases), C10.228 (Central Nervous\nFootnote or Reference text (if exists): 1 http://www.nlm.nih.gov/mesh/meshhome.html; the work reported in this paper uses MeSH 2001.\nSection Titles (if exists):  ['3 The Lexical Hierarchy: MeSH']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-entities-guidelines-v5.6.6.pdf\nCitation Context: We present in this work a new dataset of en-tity annotations for a wide sample of 210,532 to-kens from 100 literary texts to help address these issues and help advance computational work on literature. These annotations follow the guide-lines set forth by the ACE 2005 entity tagging task (LDC, 2005) [URL_CITE] in labeling all nominal entities (named and common alike), including those with nested structure. In evaluating the stylistic dif-ference between the texts in ACE 2005 (primar-ily news) and the literary texts in our new dataset, we find considerably more attention dedicated to people and settings in literature; this attention di-rectly translates into substantially improved accu-racies for those classes when models are trained on them.\nFootnote or Reference text (if exists): LDC. 2005. Ace (automatic content extrac-tion) English annotation guidelines for enti-ties. https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-entities-guidelines-v5.6.6.pdf.\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lpsolve.sourceforge.net/\nCitation Context: We used lp solve [URL_CITE] to solve our ILP optimization problems. We ran experiments on two datasets.\nFootnote or Reference text (if exists): 3 From http://lpsolve.sourceforge.net/\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1145/2700406\nCitation Context: It seems unclear that this is a good simulation of the kind of shift in distribution that one is likely to en-counter in practice. An exception to this is Esuli and Sebastiani (2015) [URL_CITE] , who test their method on the RCV1-v2 corpus, also splitting by time. They perform a large number of experiments, but un-fortunately, nearly all of their experiments involve only a very small difference in label proportions between the source and target (with the vast ma-jority < 0.01), which limits the generalizability of their findings.\nFootnote or Reference text (if exists): Andrea Esuli and Fabrizio Sebastiani. 2015. Optimiz-ing text quantifiers for multivariate loss functions. ACM Trans. Knowl. Discov. Data 9(4). https: //doi.org/10.1145/2700406.\nSection Titles (if exists):  ['5 Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://joshua-decoder.com/language-packs/paraphrase/\nCitation Context: Several different size language packs are available for download. [URL_CITE] The components of the language packs are described below. Grammar Our approach to sentential paraphras-ing is analogous to machine translation.\nFootnote or Reference text (if exists): 1 http://joshua-decoder.com/language-packs/paraphrase/\nSection Titles (if exists):  ['2 Language pack description']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ldc.upenn.edu/Projects/TIDES/Translation/TransAssess02.pdf\nCitation Context: The 769 sentences were translated by using five commercial MT systems to investigate the relation-ship between subjective evaluation based on yes/no questions and conventional subjective evaluation based on fluency and adequacy. The instruction for the subjective evaluation based on fluency and ad-equacy followed that given in the TIDES specifi-cation (TIDES, 2002) [URL_CITE] . The subjective evaluation based on yes/no questions was done by manually answering each question for each translation.\nFootnote or Reference text (if exists): TIDES. 2002. Linguistic Data Annotation Specifi-cation: Assessment of Fluency and Adequacy in Arabic-English and Chinese-English Translations. http://www.ldc.upenn.edu/Projects/TIDES/Translation/TransAssess02.pdf.\nSection Titles (if exists):  ['2 Test Set for Evaluating Machine Translation Quality', '2.1 Test Set']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/XinnuoXu/\nCitation Context: For further analysis and studies, we re-domains. However, GPT-2 is pre-trained on Open- lease the data from all intermediate steps for WebText and the language style and topics thereof each domain at [URL_CITE] https://github.com/XinnuoXu/ are quite different from those of daily conversa- AugNLG/tree/master/augmented_data .\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://chasen.org/~taku/software/TinySVM/\nCitation Context: The features described in the previous section give us a way to provide the learning algorithm with the necessary information to make a classi-fication decision. The next step is to convert our training data into sets of features, and feed these classification instances to the learning algorithm. For the learning task, we use the TinySVM [URL_CITE] sup-port vector machine (SVM) implementation in conjunction with YamCha 7 (Kudo & Matsumoto, 2001), a suite for general-purpose chunking.\nFootnote or Reference text (if exists): 6 http://chasen.org/~taku/software/TinySVM/ 7 http://chasen.org/~taku/software/yamcha/\nSection Titles (if exists):  ['6 Classifier Parameters']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://cqa.iyas.qcri.org/cQA-Arabic-Demo\nCitation Context: A second example is a cQA demo [URL_CITE] in Arabic, which retrieves data from multiple medical forums from middle-east. In this case physicians answer to patients\u2019 questions: the left panel shows a ques-tion from a user and the right panel similar ques-tions with the answers from the expert. In general there is only one (good) answer from the doctor, so this is mostly a question re-ranking task.\nFootnote or Reference text (if exists): 4 http://cqa.iyas.qcri.org/ cQA-Arabic-Demo\nSection Titles (if exists):  ['5 Software Package']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.elra.info/\nCitation Context: The bilingual dictionary used in our experiments is the French/English dictionary ELRA-M0033 available from the ELRA catalogue [URL_CITE] . This re-source is a general language dictionary which con-tains only a few terms related to the medical do-main.\nFootnote or Reference text (if exists): 5 http://www.elra.info/\nSection Titles (if exists):  ['3 Linguistic Resources', '3.2 Bilingual Dictionary']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl\nCitation Context: Both with the IMDB and BBC corpora, we did not do any preprocessing other than tokenization. [URL_CITE] Penn Treebank We evaluate a normal recurrent language model, count-based n-gram language model as well as the proposed RLM-BoW-EF-n and RLM-BoW-LF-n with varying n = 1, 2, 4, 8 on the Penn Treebank Corpus. We preprocess the corpus according to (Mikolov et al., 2011) and use a vocabulary of 10k words from the training cor-pus.\nFootnote or Reference text (if exists): 3 https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl\nSection Titles (if exists):  ['5 Experimental Settings', '5.2 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/cookielee77/CLARE\nCitation Context: Human eval-uation shows significant advantages of CLARE in terms of textual similarity, fluency and gram-maticality. We release our code and models at [URL_CITE] https://github.com/cookielee77/CLARE.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['6 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://jobimtext.org\nCitation Context: The domain-specific corpora consist of web pages, selected by using a combination of BootCat (Baroni and Bernardini, 2004) and focused crawling (Remus and Biemann, 2016). Noisy IS-A relations are extracted with lexical-syntactic patterns from all corpora by applying PattaMaika [URL_CITE] , PatternSim (Panchenko et al., 2012), and WebISA (Seitner et al., 2016), following (Panchenko et al., 2016).\nFootnote or Reference text (if exists): 2 http://jobimtext.org: The PattaMaika compo-nent is based on UIMA RUTA (Kluegl et al., 2016).\nSection Titles (if exists):  ['3 Taxonomy Refinement using Hyperbolic Word Embeddings', '3.1 Domain-specific Poincare\u0301 Embedding']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.imdb.com/\nCitation Context: Dataset. Our experiments are conducted on six extreme multi-label datasets and their character-istics are shown in Table 1, among which IMDb is crawled from online movie database [URL_CITE] and the rest five datasets are downloaded from the extreme classification repository . For datasets from the repository, we adopt the provided train/test split, and for IMDb we randomly choose 20% of the data as test set and the rest of 80% as training set.\nFootnote or Reference text (if exists): 2 https://www.imdb.com/\nSection Titles (if exists):  ['3 Experiments & Analysis', '3.1 Dataset & Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: DataSource\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/adhigunasurya/distillation_parser.git\nCitation Context: The code to reproduce our results is pub-licly available. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/adhigunasurya/distillation_parser.git\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.google.com/apis\nCitation Context: Here, we give an example illustrating the prin-ciple of clustering web search results in the FGS. In submitting TREC 2004 test question 1.1 \u201dwhen was the first Crip gang started?\u201d to Google ( [URL_CITE] http://www.google.com/apis), we extract n(= 8) different candidates from the top m(= 30) Google snippets. The Google snippets containing the same candidates are aligned snippets, and thus the 12 re-tained snippets are grouped into 8 clusters, as listed in Table 2.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 The U-SVM', '3.1 Clustering Web Search Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.mcs.anl.gov/petsc/\nCitation Context: The part-of-speech tagger used to extract POS features was lgtagger (Constant and Sigogne, 2011). To train the reranker, we used a MaxEnt al-gorithm [URL_CITE] as in (Charniak and Johnson, 2005).\nFootnote or Reference text (if exists): 8 We used the following mathematical libraries PETSc et TAO, freely available at http://www.mcs.anl.gov/petsc/ and http://www.mcs.anl.gov/research/projects/tao/\nSection Titles (if exists):  ['6 Evaluation', '6.1 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\nLet me know if you have any other URLs and citations you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.natcorp.ox.ac.uk\nCitation Context: The Italian language vectors for the cross-lingual ex-periments of Section 6 were trained on 1.6 bil-lion tokens from itWaC. [URL_CITE] A word token is a word-form + POS-tag string. We extract both word vec-tors and the observed phrase vectors which are required for the training procedures.\nFootnote or Reference text (if exists): 5 Corpus sources: http://wacky.sslmit.unibo. it, http://www.natcorp.ox.ac.uk\nSection Titles (if exists):  ['4 Evaluation setting']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: DataSource \nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.usna.edu/Users/cs/\nCitation Context: We compare Rel-grams schemas against the state-of-the-art narrative schemas released by Cham-bers (Chambers and Jurafsky, 2009). [URL_CITE] Chambers\u2019 schemas are less expressive than ours \u2013 they do not associate types with actors and each schema has a constant pre-specified number of relations. For a fair comparison we use a similarly expressive ver-sion of our schemas that strips off argument types and has the same number of relations per schema (six) as their highest quality output set.\nFootnote or Reference text (if exists): 8 Available at http://www.usna.edu/Users/cs/\nSection Titles (if exists):  ['5 Evaluation', '5.2 Schemas Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://lucene.apache.org/\nCitation Context: K E LP is a machine learning library completely written in Java. The Java language has been cho-sen in order to be compatible with many Java NLP/IR tools that are developed by the commu-nity, such as Stanford CoreNLP , OpenNLP or Lucene [URL_CITE] . K E LP is released as open source soft-ware under the Apache 2.0 license and the source code is available on github .\nFootnote or Reference text (if exists): 3 http://lucene.apache.org/\nSection Titles (if exists):  ['2 Framework Overview']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool \nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.reddit.com\nCitation Context: Our experiments are based on Reddit [URL_CITE] , one of the world\u2019s largest public discussion forums. On Red-dit, registered users initiate a post and people re-spond with comments, either to the original post or one of its associated comments.\nFootnote or Reference text (if exists): 2 http://www.reddit.com\nSection Titles (if exists):  ['2 Popularity Prediction and Tracking']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dblp.uni-trier.de/db/journals/corr/corr1412.html\nCitation Context: Network parameters for CNN, LSTM & GRU: In the fully connected layers we use 50 and 10 neurons , respectively for the two hidden layers. We use Relu activations (Glorot et al., 2011) for intermediate layers and tanh activation in the final layer. We employ 20% Dropout (Srivastava et al., 2014) in the fully connected layers as a measure of regularization and Adam optimizer (Kingma and Ba, 2014) [URL_CITE] for optimization.\nFootnote or Reference text (if exists): Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimiza-tion. CoRR abs/1412.6980. http://dblp.uni-trier.de/db/journals/corr/corr1412.html.\nSection Titles (if exists):  ['2 Proposed Methodology']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://radimrehurek.com/gensim/\nCitation Context: \u2022 DSobtainedwordviaembeddingsLatent Semantic: DS embeddingsAnalysis (LSAare) and via retraining word2vec on the test data sets using the implementation in gensim [URL_CITE] . DS embeddings via LSA are denoted by LSA and DS embeddings via word2vec are de-noted by DSw2v.\nFootnote or Reference text (if exists): 3 https://radimrehurek.com/gensim/\nSection Titles (if exists):  ['3 Domain Adapted Word Embeddings for Improved Sentiment Classification', '3.2 Experimental evaluation and results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://catalog.ldc.upenn.edu/LDC2013T19\nCitation Context: It is worth noting that to attain our best perfor-mance, we require the use of both an NER system, indirectly using labelled data from OntoNotes 5, and a constituency parser for extracting sub-clauses, trained on the Penn Treebank (Marcus et al., 1994). [URL_CITE] Moreover, a language-specific wh* heuristic was used for training the best perform-ing NMT models. This limits the applicability and flexibility of our best-performing approach to do-mains and languages that already enjoy extensive linguistic resources (named entity recognition and treebank datasets), as well as requiring some hu-man engineering to define new heuristics.\nFootnote or Reference text (if exists): 7 Ontonotes 5: https://catalog.ldc.upenn.edu/LDC2013T19\nSection Titles (if exists):  ['5 Discussion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/castorini/birch\nCitation Context: The final score used by Birch for re-reranking is: \u03b3\u00b7S BM25 +(1\u2212\u03b3)\u00b7P i \u03ba i \u00b7S(x q , x i ) where S BM25 is the baseline BM25 score and \u03b3, \u03ba i are weight coefficients. We use the published mod-els [URL_CITE] and coefficient values for evaluation.\nFootnote or Reference text (if exists): 3 https://github.com/castorini/birch\nSection Titles (if exists):  ['5 Experiments', '5.1 Tasks and Models']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.aclweb.org/anthology/W17-6213\nCitation Context: (2017) and Friedman et al. (2017) [URL_CITE] achieved state-of-the-art TAG parsing performance using an unlexicalized shift-reduce parser with feed-forward neural networks that was trained on a version of the Penn Treebank that had been annotated with TAG derivations. Here, we pursue this data-driven approach, applying a graph-based parser with deep biaffine attention (Dozat and Manning, 2017) that allows for global training and inference.\nFootnote or Reference text (if exists): Dan Friedman, Jungo Kasai, R. Thomas McCoy, Robert Frank, Forrest Davis, and Owen Rambow. 2017. Linguistically rich vector representations of supertags for TAG parsing. In TAG+. Associa-tion for Computational Linguistics, Umea\u030a, Sweden, pages 122\u2013131. http://www.aclweb.org/anthology/W17-6213.\nSection Titles (if exists):  ['2 Our Models', '2.2 Parsing Model']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/e-bug/nmt-difficulty\nCitation Context: We then present the first systematic and con-trolled study of cross-lingual translation dif-ficulties using modern neural translation sys-tems. Code for replicating our experiments is available online at [URL_CITE] https://github.com/e-bug/nmt-difficulty.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.galaxyforums.net/\nCitation Context: StackOverflow 1 , a popular discussion forum for programmers is among the top-100 most vis-ited sites globally 2 . Now, there are discussion fo-rums for almost every major product ranging from automobiles to gadgets such as those of Mac or Samsung [URL_CITE] . These typically start with a registered user posting a question/problem to which other users respond.\nFootnote or Reference text (if exists): 5 http://www.galaxyforums.net/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.isca-speech.org/archive/\nCitation Context: approx 32 0.6 ( Neighbors ( 1024 9998 Corpus 100 2 Particular 32 9998 Nearest 1024 0.4 Training 200 in 2 Words 32 of in 1024 # 0.2 % Frequency 800 99982 32 1024 max 9998 0 20 40 60 80 100 % Stability Figure 6: Stability of word2vec on the PTB. Stability is measured across ten randomized embedding spaces trained on the training data of the PTB (determined us-ing language modeling splits (Mikolov et al., 2010) [URL_CITE] ). Each word is placed in a frequency bucket (left y-axis) and stability is determined using a varying number of\nFootnote or Reference text (if exists): Tomas Mikolov, Martin Karafia\u0301t, Lukas Burget, Jan Cernocky\u0300, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Interspeech. volume 2, page 3. https: //www.isca-speech.org/archive/ interspeech 2010/i10 1045.html.\nSection Titles (if exists):  ['5 Lessons Learned: What Contributes to the Stability of an Embedding']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce \n\n\nLet me explain why:\n\n* **Dataset:** The URL points to the Interspeech 2010 archive, which likely contains datasets used in research, including the PTB (Penn Treebank)"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1017/CBO9780511809071.007\nCitation Context: Only a small percentage of the words appearing in news can be used for meaningful information extraction and analysis (Manning et al., 1999; Ho-vold, 2005). Specifically, we eliminated too fre-quent (at least once in more than 50% of the days) or too rare (appearing in less than 100 articles) (Manning et al., 2008) [URL_CITE] . Many common English nouns, adjectives and verbs, whose contribution to semantics is minimal (Forman, 2003) were also removed from the vocabulary.\nFootnote or Reference text (if exists): Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schtze. 2008. Scoring, term weighting, and the vector space model. Cambridge University Press, 100123. https://doi.org/10.1017/CBO9780511809071.007\nSection Titles (if exists):  ['3 Predictive Causal Graph', '3.1 Selecting Informative Words:']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/electra\nCitation Context: We compare the number of train-ing steps per second. For direct comparison, we modify the ELECTRA reference code [URL_CITE] . For TPU v3 with 8 TPU cores, ELECTRA and SCRIPT achieve 31.3 and 22.7 training iterations per sec-ond with a mean MXU utilization of 14.93% and 17.91% for small models, respectively.\nFootnote or Reference text (if exists): 2 https://github.com/google-research/ electra\nSection Titles (if exists):  ['3 Experiments', '3.3 Computational Efficiency']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://mat-annotation.sourceforge.net/\nCitation Context: This process can then be repeated until the ma-chine learning model is performing well enough to be partly or fully automated. This is similar to the \u201ctag-a-little, learn-a-little loop\u201d from MAT (Bayer, 2015) [URL_CITE] . If combined with enabling pre-annotations, it is also very similar to the annotation process of RapTAT (Gobbel et al., 2014).\nFootnote or Reference text (if exists): Samuel Bayer. 2015. MITRE Annotation Toolkit (MAT). http://mat-annotation.sourceforge.net/.\nSection Titles (if exists):  ['4 Annotation Generator', '4.2 Active Learning Process']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.efset.org/research/~/media/centralefcom/efset/pdf/\nCitation Context: First, as mentioned previously, in our dataset the MET and reported TOEFL scores have a Pearson\u2019s r correlation of 0.74. We further note an external study conducted by the testing com-pany Education First (EF) which measured the correlation of their flagship standardized English proficiency test EFSET-PLUS with TOEFL-iBT (Luecht, 2015) [URL_CITE] . Using 384 participants who took both tests, the study found a Pearson\u2019s r of 0.63 for the reading comprehension and 0.69 for the listen-ing comprehension sections of these tests.\nFootnote or Reference text (if exists): Richard M Luecht. 2015. EFSET PLUS - TOEFL iBT correlation study report. https://www.efset.org/research/\u02dc/media/centralefcom/efset/pdf/ EFSET_TOEFL_correlational_report_ Sep_v1.pdf.\nSection Titles (if exists):  ['4 English Proficiency Scoring Based on Eye Movements in Reading', '4.1 Correlation with MET and TOEFL']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document \nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://en.wikipedia.org/wiki/\nCitation Context: Sil et al. (2010) extract sequences of verb constructions from webpages to learn common 8 See [URL_CITE] https://en.wikipedia.org/wiki/ preconditions of actions and events, and Cham- Wikipedia:Notability_(events) be transferable to the cross-document case. on Empirical Methods in Natural Language Process-To the best of our knowledge, we are the first to ing: System Demonstrations, pages 205\u2013215, On-propose a cheap and high-quality data extraction approach specifically for cross-document event ex-traction and coreference which does not depend on pre-existing resources, combining past work on event extraction from raw newswire text and min-ing of hyperlinks.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Discussion and Future Work']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION:  Compare \n\n\nLet me explain why:\n\n* **TYPE: Website:** The URL points to the main Wikipedia page, indicating a website.\n* **FUNCTION: Compare:** While the citation doesn't explicitly state"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset\nCitation Context: The proposed model learns relation representations along the shortest dependency path (SDP) extracted from the structure regularized de-pendency tree, which has the benefits of re-ducing the complexity of the whole model. Experimental results show that the proposed method significantly improves the F 1 score by 10.3, and outperforms the state-of-the-art ap-proaches on Chinese literature text [URL_CITE] .\nFootnote or Reference text (if exists): 1 The Chinese literature text corpus for relation classi-fication, developed and used by this paper, is available at https://github.com/lancopku/Chinese-Li terature-NER-RE-Dataset\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pstadler1990/nmt_paper21_appendix\nCitation Context: We created 10 sentences per phe-nomenon, resulting in a total of 585 sentences, ex-amining 49 phenomena organised in 13 categories. The raw test items, as well as the translations eval-uated can be found in our repository [URL_CITE] . The phe-nomena selected for this experiment are a subset of the ones of German\u2192English MT, as described in Macketanz et al.\nFootnote or Reference text (if exists): 1 https://github.com/pstadler1990/nmt_ paper21_appendix\nSection Titles (if exists):  ['4 Experiment setup', '4.1 Test suite setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION:  Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://archive.ics.uci.edu/ml/\nCitation Context: Two multiclass document classification datasets were used: Reuters Transcribed and Mini News-groups, distributed at [URL_CITE] http://archive.ics.uci.edu/ml/. The properties of the datasets are summarized in Ta-ble 2.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Experiments', '7.2 Document classification', '7.2.1 Task and dataset']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cis.upenn.edu/dbikel/software.html\nCitation Context: The sec-ond largest gain was on PPs, where we improved by 1.7% over 3,775 constituents. We tested the signif-icance of our results (on all the data combined) us-ing Dan Bikel\u2019s randomized parsing evaluation com-parator [URL_CITE] and found that both the precision and recall gains were significant at p \u2264 0.01.\nFootnote or Reference text (if exists): 6 Available at http://www.cis.upenn.edu/dbikel/software.html\nSection Titles (if exists):  ['5 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.npm.gov.tw\nCitation Context: We use the Chinese/English web pages of the National Palace Museum [URL_CITE] as our underlying parallel corpus. It contains about 30,000 sentences in each language.\nFootnote or Reference text (if exists): 2 http://www.npm.gov.tw\nSection Titles (if exists):  ['3 Experimental Results', '3.1 Experimental Setting']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://dx.doi.org/10.3765/sp.11.10\nCitation Context: These player ut-terances are the \u201clinguistic\u201d turns. In addition the corpus contains information given visually in the game interface but transcribed in the corpus into Server or interface messages, \u201cnon-linguistic\u201d turns (Hunter et al., 2018) [URL_CITE] . All turns are seg-mented into DUs, and these units are then con-nected by semantic relations.\nFootnote or Reference text (if exists): Julie Hunter, Nicholas Asher, and Alex Lascarides. 2018. A formal semantics for situated conver-sation. Semantics and Pragmatics, 11. DOI: http://dx.doi.org/10.3765/sp.11.10.\nSection Titles (if exists):  ['3 The STAC Annotated Corpus', '3.1 Overview']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://zenodo.org/record/4421380\nCitation Context: All models are of dimensionality d = 768 and have 12 layers, plus one static embedding layer. We also include two 300 dimensional non-contextual mod-els, Word2Vec [URL_CITE] and GloVe, for comparison. Our corpus O is an 85k token sample of random arti-cles from English Wikipedia.\nFootnote or Reference text (if exists): 3 https://zenodo.org/record/4421380\nSection Titles (if exists):  ['3 Rogue Dimensions and', '3.1.2 Experiment']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/NLPIR-team/NLPIR\nCitation Context: If use the maximum length of all conversations as the input length for en-coders, padding the inputs will lead to a sparse ma-trix. Therefore, for long conversations (with more than 10 messages), we use KLSum (Haghighi and Vanderwende, 2009) to produce summaries with a length of [URL_CITE] messages and then encode the pro-duced summaries. In contrast, we do not sum-marize Twitter conversations because their length range is much narrower (from 4 to 1,035 words).\nFootnote or Reference text (if exists): 10 https://github.com/NLPIR-team/NLPIR\nSection Titles (if exists):  ['3 Experiment Setup', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\nLet me know if you have any other URLs and citations you'd like me to classify!\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/IBM/twitter-customer-care-document-prediction\nCitation Context: Two of these datasets are internal: one from an internal customer support service on Mac devices (Mac-Support) and another from an external client in the telecommunication domain (Telco-Support). We also release a new Twitter dataset, containing conversations between users and CC agents in 25 organizations on the Twitter platform [URL_CITE] . We summarize the statistics of the three datasets in Table 2.\nFootnote or Reference text (if exists): 3 The Twitter dataset is available at: https://github.com/IBM/ twitter-customer-care-document-prediction based language models. In Proceedings of the 24th Annual International ACM SIGIR Conference on Re-search and Development in Information Retrieval, tion set of Telco-Support dataset for dialog context se-quence input handling.\nSection Titles (if exists):  ['2 Data']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://crfpp.sourceforge.net/\nCitation Context: The CRF model we compare with was trained with the CRF++ tool, available at [URL_CITE] http://crfpp.sourceforge.net/. The model is equiva-lent to the one described in (Hahn et al., 2008). As features, we used word and morpho-syntactic cat-egories in a window of [-2, +2] with respect to the current token, plus bigrams of concept tags (see (Hahn et al., 2008) and the CRF++ web site for more details).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Experiments', '5.2 Experimental setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.reddit.com/\nCitation Context: There are a total of 8675 users in this dataset and each user has 45-50 posts. Pan-dora is another dataset collected from Reddit, [URL_CITE] where personality labels are extracted from short descriptions of users with MBTI results to intro-duce themselves. There are dozens to hundreds of posts for each of the 9067 users in this dataset.\nFootnote or Reference text (if exists): 7 https://www.reddit.com/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://github.com/lex4all/lex4all\nCitation Context: We have developed lex4all as a desktop applica-tion for Microsoft Windows, since it relies on the Microsoft Speech Platform (MSP) as explained in Section 4.1. The application and its source code are freely available via GitHub. [URL_CITE]\nFootnote or Reference text (if exists): 6 http://github.com/lex4all/lex4all\nSection Titles (if exists):  ['3 System overview']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www-nlp.stanford.edu/software/sempre/\nCitation Context: Because there can be more than one answer to a question, precision, recall and F 1 are computed based on the system output for each individual question. The average F 1 score is reported as the main evaluation metric [URL_CITE] .\nFootnote or Reference text (if exists): 6 We used the official evaluation script from http://www-nlp.stanford.edu/software/sempre/.\nSection Titles (if exists):  ['4 Experiments', '4.1 Data & evaluation metric']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/dgaddy/silent_speech\nCitation Context: We hope that our public release of data will encourage others to further improve models for this task. [URL_CITE]\nFootnote or Reference text (if exists): 6 Our dataset can be downloaded from https://doi.org/10.5281/zenodo.4064408 and code is available at https://github.com/dgaddy/silent_speech. Samples of predicted outputs can be found in the supplementary material.\nSection Titles (if exists):  ['5 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/nju-websoft/GLRE\nCitation Context: We implemented our GLRE with PyTorch 1.5. The source code and datasets are available online. [URL_CITE] In this section, we report our experimental results.\nFootnote or Reference text (if exists): 1 https://github.com/nju-websoft/GLRE\nSection Titles (if exists):  ['4 Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://bitbucket.org/TomKenter/siamese-cbow\nCitation Context: We use Theano (Theano Development Team, 2016) to implement our network. [URL_CITE] We ran our ex-periments on GPUs in the DAS5 cluster (Bal et al., 2016).\nFootnote or Reference text (if exists): 4 The code for Siamese CBOW is available under an open-source license at https://bitbucket.org/TomKenter/siamese-cbow.\nSection Titles (if exists):  ['3 Experimental Setup', '3.4 Network']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/stanfordnlp/GloVe\nCitation Context: For all other hyper-parameters, we use the default values of previous implementations. [URL_CITE] For each corpus-algorithm pair, we train k = 32 word embedding models using different random seeds.\nFootnote or Reference text (if exists): 6 For SGNS, we use Gensim 3.8.3 (R\u030cehu\u030ar\u030cek and Sojka, 2010) with a window size of 5, a minimum word count of 5 and 5 iterations. For GloVe, we use the official implemen-tation https://github.com/stanfordnlp/GloVe, with a window size of 15, a minimum word count of 5 and 15 iterations. Because we do not fine-tune hyper-parameters, our results do not necessarily indicate which algorithm itself is of better reliability. To investigate the potential impact of this decision, we also include an explorative study on the influence of hyper-parameters in Appendix E.\nSection Titles (if exists):  ['5 Experiments', '5.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.clsp.jhu.edu/workshops/18-workshop/\nCitation Context: This work was mostly conducted at the 2018 Fred-erick Jelinek Memorial Summer Workshop on Speech and Language Technologies, [URL_CITE] hosted and sponsored by Johns Hopkins University. Shruti Palaskar received funding from Facebook and Ama-zon grants.\nFootnote or Reference text (if exists): 1 https://www.clsp.jhu.edu/workshops/18-workshop/\nSection Titles (if exists):  ['Acknowledgements']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/pytorch/fairseq\nCitation Context: We query the online API for the first four commercial MT systems, while for the latter two academic models we use the pre-trained models provided by the Fairseq toolkit. [URL_CITE]\nFootnote or Reference text (if exists): 5 https://github.com/pytorch/fairseq\nSection Titles (if exists):  ['3 Evaluation', '3.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://spacy.io/\nCitation Context: For all English processing we will use tools available in the NLTK toolkit (Bird et al., 2009) or SpaCy. [URL_CITE]\nFootnote or Reference text (if exists): 2 https://spacy.io/\nSection Titles (if exists):  ['3 Experimental Framework', '3.3 Tools and Models']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://babelnet.org\nCitation Context: To cope with these issues, we exploit Babel-Net, [URL_CITE] a huge multilingual semantic network ob-tained from the automatic integration of WordNet, Wikipedia, Wiktionary and other resources (Nav-igli and Ponzetto, 2012), and create the Babel-Net subgraph induced by the WordNet vertices. The result is a graph whose vertices are BabelNet synsets that contain at least one WordNet synset and whose edge set includes all those relations in BabelNet coming either from WordNet itself or from links in other resources mapped to Word-Net (such as hyperlinks in a Wikipedia article con-necting it to other articles). The greatest contribu-tion of syntagmatic relations comes, indeed, from Wikipedia, as its articles are linked to related ar-ticles (e.g., the English Wikipedia Bus article is linked to Passenger, Tourism, Bus lane, Timetable, School, and many more).\nFootnote or Reference text (if exists): 2 http://babelnet.org\nSection Titles (if exists):  ['3 Creating a Denser and Multilingual Semantic Network']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Knowledge\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ofai.at/\nCitation Context: For comparison, we also tested two recently pro-posed approaches to hub reduction: transformation of the base similarity measure (in our case, K) by Mutual Proximity (Schnitzer et al., 2012) [URL_CITE] , and the one (Suzuki et al., 2012) based on graph Laplacian kernels. Since the Laplacian kernels are defined for graph nodes, we computed them by taking the co-sine similarity matrix K as the weighted adjacency (affinity) matrix of a graph. For Laplacian kernels, we computed both the regularized Laplacian ker-nel (Chebotarev and Shamis, 1997; Smola and Kon-dor, 2003) with several parameter values, as well as the commute-time kernel (Saerens et al., 2004), but present only the best results among these kernels.\nFootnote or Reference text (if exists): 2 We used the Matlab script downloaded from http://www.ofai.at/ \u223c dominik.schnitzer/mp/.\nSection Titles (if exists):  ['7 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\nThe citation refers to a Matlab script downloaded from the provided URL, which is used for computing Mutual Proximity.\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://open-platform.theguardian.com/\nCitation Context: Input Articles: For each entity from the ground-truth timelines, we search for news articles using TheGuardian API [URL_CITE] . We use this source because it provides access to all published articles starting from 1999.\nFootnote or Reference text (if exists): 7 http://open-platform.theguardian.com/\nSection Titles (if exists):  ['4 Dataset']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: DataSource\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://homepages.inf.ed.ac.uk/s0677528/data.html\nCitation Context: As mentioned earlier, we use the dataset created in Feng and Lapata (2008). [URL_CITE] It contains 3,361 articles that have been downloaded from the BBC News website . Each article contains a news image which in turn is associated with a caption.\nFootnote or Reference text (if exists): 2 Available from http://homepages.inf.ed.ac.uk/s0677528/data.html.\nSection Titles (if exists):  ['3 Problem Formulation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/slavpetrov/berkeleyparser\nCitation Context: We choose NIST MT 06 dataset (1664 sentence pairs) as our develop-ment set, and NIST MT 02, 03, 04, and 05 datasets (878, 919, 1788 and 1082 sentence pairs, respec-tively) as our test sets. To get the source syn-tax for sentences on the source-side, we parse the Chinese sentences with Berkeley Parser [URL_CITE] (Petrov and Klein, 2007) trained on Chinese TreeBank 7.0 (Xue et al., 2005). We use the case insensitive 4-gram NIST BLEU score (Papineni et al., 2002) for the translation task.\nFootnote or Reference text (if exists): 6 https://github.com/slavpetrov/ berkeleyparser\nSection Titles (if exists):  ['4 Experimentation', '4.1 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.18653/v1/P17-1070\nCitation Context: We use a bidirectional LSTM (Hochreiter and Schmidhu-ber, 1997) architecture for sentence classification, with dynamic attention over words for construct-ing the sentence representations. Related archi-tectures have been successful for machine trans-lation (Bahdanau et al., 2015), sentence summa-rization (Rush and Weston, 2015), entailment de-tection (Rockta\u0308schel et al., 2016), and error cor-rection (Ji et al., 2017) [URL_CITE] . In this work, we modify the attention mechanism and training objective in order to make the resulting network suitable for also inferring binary token labels, while still per-forming well as a sentence classifier.\nFootnote or Reference text (if exists): Jianshu Ji, Qinlong Wang, Kristina Toutanova, Yongen Gong, Steven Truong, and Jianfeng Gao. 2017. A Nested Attention Neural Hybrid Model for Gram-matical Error Correction. In ACL 2017. pages 753\u2013762. https://doi.org/10.18653/v1/P17-1070.\nSection Titles (if exists):  ['2 Network Architecture']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.wikidata.org/wiki/Wikidata:List_of_properties\nCitation Context: For Freebase we select 5, 000 triples as the validation set, while for Wikidata we use the validation set provided in the transductive setting (5, 136 triples). A.4 W IKI D ISTANT Relation Categories Since W IKI D ISTANT contains 454 relations, their labels are used directly from the WikiData proper-ties [URL_CITE] . Here, we add explanations about the top 10 most frequent categories used in Figures 4c, 4d.\nFootnote or Reference text (if exists): 9 https://www.wikidata.org/wiki/Wikidata: List_of_properties\nSection Titles (if exists):  ['A Appendix', 'A.3 Hyper-parameter Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Knowledge\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://doi.org/10.1016/j.engappai.2020.103641\nCitation Context: Since it has been proven that sentences that contain few typos, misspellings, or minor character-level errors can be still fully understandable to humans (Belinkov and Bisk, 2018; Xu and Du, 2020 [URL_CITE] ), character-level perturbations are not expected to change the text\u2019s meaning in most cases. Therefore, they can be automatically produced and used for testing the robustness of NLP systems.\nFootnote or Reference text (if exists): Jincheng Xu, and Qingfeng Du. 2020. TextTricker: Loss-based and gradient-based adversarial attacks on text classification models. Engineering Applications of Artificial Intelligence, 92: 103641. https://doi.org/10.1016/j.engappai.2020.103641.\nSection Titles (if exists):  ['5 Experimental results', '5.1 Performance on perturbed inputs']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://opennlp.apache.org/\nCitation Context: K E LP is a machine learning library completely written in Java. The Java language has been cho-sen in order to be compatible with many Java NLP/IR tools that are developed by the commu-nity, such as Stanford CoreNLP , OpenNLP [URL_CITE] or Lucene . K E LP is released as open source soft-ware under the Apache 2.0 license and the source code is available on github .\nFootnote or Reference text (if exists): 2 https://opennlp.apache.org/\nSection Titles (if exists):  ['2 Framework Overview']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hub.microsofttranslator.com\nCitation Context: To improve the translation quality for terms like clutch, we used an interface provided by a third party machine translation service [URL_CITE] to train a cus-tom MT engine for English to French translations. To validate that the retrained MT systems were materially improved, we used a two step valida-tion process, first using crowd-sourced evaluations with Amazon\u2019s Mechanical Turk, and secondly us-ing A/B testing, a way of conducting randomized experiments on web sites, to measure the effect of the trained system on user behavior.\nFootnote or Reference text (if exists): 2 http://hub.microsofttranslator.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.dcs.shef.ac.uk/nlp/meter\nCitation Context: A prototype browser-based demo of both the GST algorithm and alignment program, allow-ing users to test arbitrary text pairs for simi-larity, is now available [URL_CITE] and will continue to be enhanced. helpful comments on earlier drafts.\nFootnote or Reference text (if exists): 4 See http://www.dcs.shef.ac.uk/nlp/meter.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: For experimental evaluation of the proposed method we use the publicly available Multi-Perspective Question Answering (MPQA) [URL_CITE] corpus (Wiebe et al., 2005) version 1.2, which contains 535 newswire documents that are manually annotated with phrase-level subjectivity and intensity. We use the expression-level boundary markings in MPQA to extract phrases.\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['3 Experimental Methodology']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://zhidao.baidu.com/\nCitation Context: Community Question Answering (cQA) services like Yahoo! Answers , Baidu Zhidao [URL_CITE] , Quora , StackOverflow etc. provide a platform for interaction with experts and help users to obtain precise and accurate answers to their questions.\nFootnote or Reference text (if exists): 2 http://zhidao.baidu.com/\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://statnlp.org/tutorials/\nCitation Context: This tutorial consists of the following 3 main sections. [URL_CITE]\nFootnote or Reference text (if exists): 2 The material associated with this tutorial will be avail-able at http://statnlp.org/tutorials/.\nSection Titles (if exists):  ['-']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf\nCitation Context: Soft attention has firstly been used for syntactic constituency parsing by Vinyals et al. (2015) [URL_CITE] but has been widely used for translation tasks ever since. One should note that it slightly differs from Bahdanau et al.\nFootnote or Reference text (if exists): Oriol Vinyals, \u0141 ukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. 2015. Gram-mar as a foreign language. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, Curran Associates, Inc., pages 2773\u2013 2781. http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf.\nSection Titles (if exists):  ['3 Attention-based Models', '3.1 Soft attention']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Paper\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/PlusLabNLP/ee-wiki-bias\nCitation Context: To facilitate the study, we collect a corpus that contains demographic information, personal life de-scription, and career description from Wikipedia. [URL_CITE] We first detect events in the collected corpus using a state-of-the-art event extraction model (Han et al., 2019). Then, we extract gender-distinct events with a higher chance to occur for one group than the other.\nFootnote or Reference text (if exists): 2 https://github.com/PlusLabNLP/ ee-wiki-bias\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www2.crl.go.jp/jt/a132/members/mutiyama/software.html\nCitation Context: When we use SVM, we have to choose a good linear kernel ( = 6 kernel for better performance &? [URL_CITE] C ? .)\nFootnote or Reference text (if exists): 6 http://www2.crl.go.jp/jt/a132/members/mutiyama/software. html\nSection Titles (if exists):  ['3 Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool \nFUNCTION: Use \n\n\nLet me explain:\n\n* **TYPE: Tool** - The URL points to a webpage that likely describes software or a tool related to SVM (Support Vector Machine), a machine learning algorithm. \n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/RishabhMaheshwary/query-attack\nCitation Context: Also, all the past works evaluate their search methods only on a single search space. In this paper [URL_CITE] , we address the above discussed drawbacks through following contributions:\nFootnote or Reference text (if exists): 1 Code and adversarial examples available at: https://github.com/RishabhMaheshwary/query-attack\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/duyvuleo/Mantidae\nCitation Context: NMT Models. We implemented our continuous-optimisation based decoding method on top of the Mantidae toolkit [URL_CITE] (Cohn et al., 2016), and using the dynet deep learning library (Neubig et al., 2017). All neural network models were configured with 512 input embedding and hidden layer dimensions, and 256 alignment dimension, with 1 and 2 hidden layers in the source and target, respectively.\nFootnote or Reference text (if exists): 4 https://github.com/duyvuleo/Mantidae\nSection Titles (if exists):  ['5 Experiments', '5.1 Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.w3.org/TR/pronunciation-lexicon/\nCitation Context: Once pronunciations for all terms in the vocab-ulary have been generated, the application outputs a pronunciation lexicon for the given terms as an XML file conforming to the Pronunciation Lexi-con Specification. [URL_CITE] This lexicon can then be di-rectly included in a speech recognition application built using the MSP API or a similar toolkit.\nFootnote or Reference text (if exists): 7 http://www.w3.org/TR/pronunciation-lexicon/\nSection Titles (if exists):  ['3 System overview']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Document\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/allenai/label_rationale_association\nCitation Context: Via two tests, robustness equivalence and feature importance agreement, we find that state-of-the-art T5-based joint models exhibit desir-able properties for explaining commonsense question-answering and natural language infer-ence, indicating their potential for producing faithful free-text rationales. [URL_CITE]\nFootnote or Reference text (if exists): 1 Our code is available at https://github.com/allenai/label_rationale_association.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.babelnet.org/\nCitation Context: Throughout the paper, by a concept we mean a tuple b = (p, s) where p is a Wikipedia page and s is the corresponding WordNet synset. As a bridge between the two resources we use the synset-to-article mappings provided by BabelNet [URL_CITE] (Navigli and Ponzetto, 2012), a high coverage mul-tilingual encyclopedic dictionary and semantic net-work that merges, among other resources, Wikipedia and WordNet. Note that the concept b can also con-tain a Wikipedia page or a WordNet synset only, if a mapping is not provided by BabelNet.\nFootnote or Reference text (if exists): 1 http://www.babelnet.org/\nSection Titles (if exists):  ['2 Semantic Representation of Concepts']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Knowledge\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.tensorflow.org/hub/modules/google/elmo/1\nCitation Context: ELMo embeddings are essen-tially the internal states of a deep LSTM-based language model, pre-trained on a large text cor-pus. We used the 1024-d pre-trained models [URL_CITE] for two configurations: ELMo 1 , the first LSTM hid-den state, and ELMo 3 , the weighted sum of the 3 layers of LSTM. A more recent contextualized model is BERT (Devlin et al., 2019).\nFootnote or Reference text (if exists): 8 https://www.tensorflow.org/hub/modules/google/elmo/1\nSection Titles (if exists):  ['3 Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/machelreid/afromt\nCitation Context: All code and pre-trained models will be released as further steps towards larger reproducible benchmarks for African languages. [URL_CITE]\nFootnote or Reference text (if exists): 1 Source code, pretrained models, and data can be found at https://github.com/machelreid/afromt\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/qingsongma/percentage-refBias\nCitation Context: Table 2 shows proportions of all judge pairs with significant differences in Kappa point esti-mates (non-overlapping confidence intervals) for each combination of settings (Revelle, 2014). [URL_CITE] The number of significant differences in Kappa point estimates for pairs of judges in SAME and DIFF is only 13%, or, in other words, 87% of judge pairs across SAME and DIFF have no significant difference in agreement levels. Table 2 also in-cludes proportions of significant differences for Kappa point estimates resulting from judges be-longing to a single setting (significance testing all Kappa of SAME with respect to all other Kappa be-longing to SAME , for example), revealing that the proportion of significant differences within SAME (12%) to be very similar to that of SAME \u00d7 DIFF (13%), and similarly for DIFF (12%), with only a single percentage point difference in both cases in proportions of significant differences.\nFootnote or Reference text (if exists): 7 Our re-analysis code is available at https://github.com/qingsongma/percentage-refBias\nSection Titles (if exists):  ['2 Background', '2.1 Measures of Central Tendency']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tensorflow/models/tree/master/official/nlp/bert\nCitation Context: (2019). [URL_CITE] Ta-ble 1 shows that using the official code to train BERT BASE could take almost 6 days under our hard-ware assumptions (Section 2), and a large model might require close to a month of non-stop compu-tation. In contrast, our recipe significantly speeds up training, allowing one to train BERT LARGE with the original number of steps (1M) in a third of the time (8 days), or converge in 2-3 days by enlarging the batch size.\nFootnote or Reference text (if exists): 3 https://github.com/tensorflow/models/tree/master/official/nlp/bert\nSection Titles (if exists):  ['3 Combining Efficient Training Methods', '3.2 Combined Speedup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/DeepLearnXMU/NSEG\nCitation Context: The experiments are conducted on six public datasets in different domains: NIPS abstract, AAN abstract, NSF abstract, arXiv abstract: These datasets contain ab-stracts of research papers. NIPS abstract [URL_CITE] is from conference papers in NIPS, where pa-pers in years 2005-2013/2014/2015 for train-ing/validation/testing (Logeswaran et al., 2018). AAN abstract (Logeswaran et al., 2018) is col-lected from ACL Anthology Network corpus.\nFootnote or Reference text (if exists): 1 https://github.com/DeepLearnXMU/NSEG\nSection Titles (if exists):  ['3 Experiments', '3.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ankara.lti.cs.cmu.edu/side/video.swf\nCitation Context: In this type-II demo, we introduce SIDE [URL_CITE] (the Summarization Integrated Development Envi-ronment), an infrastructure that facilitates construction of summaries tailored to the needs of the user. It aims to address the issue that there is no such thing as the perfect sum-mary for all purposes.\nFootnote or Reference text (if exists): 1 The working system can be downloaded from http://www.cs.cmu.edu/~cprose/SIDE.html, and a video of an example of SIDE use can be found at http://ankara.lti.cs.cmu.edu/side/video.swf. This project is supported by ONR Cognitive and Neural Sciences Division, Grant number N000140510043\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Media \nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.ffzg.hr/resources/corpora/setimes/\nCitation Context: Much of our data comes from WikiMatrix (Schwenk et al., 2019), a large collection of parallel data extracted from Wikipedia, and for more domain variety, we added Global Voices, EuroParl (Koehn, 2005) (random subset of to 100k sentence pairs per language pair), SETimes, [URL_CITE] United Nations (Eisele and Chen, 2010) (random sample of 1M sentence pairs per language pair). We also included WMT Kazakh\u2013English and Kazakh\u2013Russian data from WMT, to be able to evaluate on Kazakh.\nFootnote or Reference text (if exists): 11 http://nlp.ffzg.hr/resources/corpora/setimes/\nSection Titles (if exists):  ['B Data Details for Replication']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://trec.nist.gov/tracks.html\nCitation Context: We rely on the widely-used 2009\u20132014 T REC Web Track ad-hoc task benchmarks [URL_CITE] . The benchmarks are based on the C LUE W EB 09 and C LUE W EB 12 datasets as document collections.\nFootnote or Reference text (if exists): 3 http://trec.nist.gov/tracks.html\nSection Titles (if exists):  ['3 Evaluation', '3.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.freedict.com\nCitation Context: \u2022 An English-French dictionary (a total of 34,808 entries, 4,021 of which are not one-to-one). [URL_CITE] It contains morphological variants but does not include character accents. Each n-to-m entry was processed by stoplisting and then extracting all word-pairs in the remaining cross-product as in section 4.1.\nFootnote or Reference text (if exists): 9 This dictionary was generated using a dictionary de-rived from one available at http://www.freedict.com.\nSection Titles (if exists):  ['5 Experiment: English-French', '5.1 Translation Lexicon']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: DataSource\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk\nCitation Context: \u2022 ATIS (AT) (Hemphill et al., 1990) contains 4,978 utterances with 79 slots and 17 intents in the flights domain. [URL_CITE]\nFootnote or Reference text (if exists): 9 We used the ATIS data version from https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk.\nSection Titles (if exists):  ['5 Experiments', '5.1 Datasets and Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://code.google.com/p/jacana/\nCitation Context: In the following we first provide background on the TED model, going on to evaluate our implemen-tation against prior work in the context of question answer sentence ranking (QASR), achieving state of the art in that task. We then describe how we cou-ple TED features to a linear-chain CRF for answer extraction, providing the set of features used, and fi-nally experimental results on an extraction dataset we make public (together with the software) to the community. [URL_CITE] Related prior work is interspersed throughout the paper.\nFootnote or Reference text (if exists): 3 http://code.google.com/p/jacana/\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/connorbrinton/polyai-models/releases/tag/v1.0\nCitation Context: (2020) showed that the \u201cUSE+ConveRT\u201d outperformed a BERT classifier on the CLINC150 dataset, while it was not evaluated along with the OOS detec-tion task. We modified their original code [URL_CITE] to apply the uncertainty-based OOS detection.\nFootnote or Reference text (if exists): 6 https://github.com/connorbrinton/polyai-models/releases/tag/v1.0.\nSection Titles (if exists):  ['4 Experimental Settings', '4.3 Model Training and Configurations']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.nist.gov\nCitation Context: Our first experiment evaluates the models we have proposed on a corpus with traditional an-notation on a seven-point scale, namely the NIST OpenMT 2008 corpus. [URL_CITE] The corpus contains trans-lations of newswire text into English from three source languages (Arabic (Ar), Chinese (Ch), Urdu (Ur)). Each language consists of 1500\u20132800 sen-tence pairs produced by 7\u201315 MT systems.\nFootnote or Reference text (if exists): 4 Available from http://www.nist.gov.\nSection Titles (if exists):  ['5 Expt. 1: Predicting Absolute Scores']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: DataSource \nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/emorynlp/reading-comprehension\nCitation Context: For the future work, we will expand the annotation for more entity types and automatically link men-tions with respect to their entities using an entity linker. All our resources including the annotated corpus and source codes of the models are avail-able at: [URL_CITE] https://github.com/emorynlp/reading-comprehension.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://pytorch.org/docs/master/index.html\nCitation Context: We use PyTorch [URL_CITE] to implement our models.\nFootnote or Reference text (if exists): 6 http://pytorch.org/docs/master/index.html\nSection Titles (if exists):  ['4 Experiments', '4.3 Implementation Detail']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.allenai.org/paper-appendix/emnlp2016-p3\nCitation Context: Code, data and supplementary material for this paper are available at: [URL_CITE] http://www.allenai.org/paper-appendix/emnlp2016-p3\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  Document \nFUNCTION:  Other (Supplementary material) \n\n\nLet me explain:\n\n* **TYPE: Document** - The URL points to a webpage that hosts supplementary materials (code, data) related to a paper. This makes"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.geniaproject.org/genia-corpus/treebank\nCitation Context: In all our experiments, both the constituency and dependency parse trees are produced by Stan-ford Parser . Specially, we train the parser on the GENIA Treebank 1.0 [URL_CITE] (Tateisi et al., 2005), which contains Penn Treebank-style syntactic (phrase structure) annotation for the GENIA corpus. The parser achieves the performance of 87.12% in F1-score in terms of 10-fold cross-validation on GENIA TreeBank 1.0.\nFootnote or Reference text (if exists): 3 http://www.geniaproject.org/genia-corpus/treebank\nSection Titles (if exists):  ['4 Experimentation', '4.2 Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/adapt-sjtu/socvec\nCitation Context: Future di-rections include: 1) mining cross-cultural differ-ences in general concepts other than names and slang, 2) merging the mined knowledge into exist-ing knowledge bases, and 3) applying the SocVec in downstream tasks like machine translation. [URL_CITE]\nFootnote or Reference text (if exists): 14 We will make our code and data available at https: //github.com/adapt-sjtu/socvec.\nSection Titles (if exists):  ['7 Conclusion']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://hierplane.allenai.org/explain\nCitation Context: In this section, we describe our key features for fa-cilitating a rapid understanding of linguistic struc-ture. As a companion to this section, we invite readers to use our web demonstration at [URL_CITE] http://hierplane.allenai.org/explain to in-teractively explore examples. 1\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['3 Key Features']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/huggingface/transformers\nCitation Context: Both the MRC and RCI training was carried out using the pytorch transformers toolkit made avail-able by Huggingface [URL_CITE] . Table 9 gives the number of parameters for each introduced model.\nFootnote or Reference text (if exists): 5 https://github.com/huggingface/ transformers\nSection Titles (if exists):  ['A Appendix']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ecdf.ed.ac.uk\nCitation Context: We would like to thank Phil Blunsom, Prachya Boonkwan, Christos Christodoulopoulos, Stephen Clark, Michael Collins, Chris Dyer, Timothy Fowler, Mark Granroth-Wilding, Philipp Koehn, Terry Koo, Tom Kwiatkowski, Andre\u0301 Martins, Matt Post, David Smith, David Sontag, Mark Steed-man, and Charles Sutton for helpful discussion re-lated to this work and comments on previous drafts, and the anonymous reviewers for helpful comments. We also acknowledge funding from EPSRC grant EP/P504171/1 (Auli); the EuroMatrixPlus project funded by the European Commission, 7th Frame-work Programme (Lopez); and the resources pro-vided by the Edinburgh Compute and Data Fa-cility ( [URL_CITE] http://www.ecdf.ed.ac.uk). The ECDF is partially supported by the eDIKT initiative (http://www.edikt.org.uk).\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: DataSource\nFUNCTION:  Acknowledge \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://www.mturk.com\nCitation Context: Once post-edits had been created, DA was em-ployed in two separate runs on Amazon Mechani-cal Turk, [URL_CITE] once for GEN - REF and once for POST - EDIT . Besides employing distinct reference trans-lations in the assessment, all other set-up crite-ria were identical for both evaluation settings, in-cluding the conventional segment-level DA set-ting, where a minimum of 15 human assessments are combined into a mean DA score for a given translation, after strict quality control measures and score standardization have been applied.\nFootnote or Reference text (if exists): 11 https://www.mturk.com\nSection Titles (if exists):  ['3 Alternate Reference Bias Investigation', '3.1 Reference Bias Experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/mlpc-ucsd/BERT_Convolutions\nCitation Context: Full pre-training and fine-tuning details are outlined in Appendix A.1. [URL_CITE] Evaluation Models were evaluated on the GLUE benchmark, a suite of sentence classification tasks including natural language inference (NLI), gram-maticality judgments, sentiment classification, and textual similarity (Wang et al., 2018). For each task, we ran ten fine-tuning runs and used the model with the best score on the development set.\nFootnote or Reference text (if exists): 2 Code is available at https://github.com/mlpc-ucsd/BERT_Convolutions, built upon the Huggingface Transformers library (Wolf et al., 2020).\nSection Titles (if exists):  ['3 Integrating lightweight convolutions', '3.2 Composite attention and lightweight convolution experiments']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/ghpaetzold/questplusplus\nCitation Context: The source code for the framework, the datasets and extra resources can be downloaded from [URL_CITE] https://github.com/ghpaetzold/questplusplus.\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['5 Remarks']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/udapi/udapi-python/blob/master/udapi/block/eval/conll17.py\nCitation Context: For evaluation we use labeled attachment score (LAS). Significance testing is performed using a randomization test, with the script from the CoNLL 2017 Shared Task. [URL_CITE]\nFootnote or Reference text (if exists): 1 https://github.com/udapi/udapi-python/blob/master/udapi/block/eval/conll17.py\nSection Titles (if exists):  ['3 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/google-research/bert\nCitation Context: We also calculate the answer recall after document prun-ing, which indicates the performance upper bound. Model settings We initialize our model us-ing two publicly available uncased versions of BERT [URL_CITE] : BERT BASE and BERT LARGE , and refer readers to Devlin et al. (2018) for details on model sizes.\nFootnote or Reference text (if exists): 5 https://github.com/google-research/bert\nSection Titles (if exists):  ['4 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://ai.stanford.edu/\nCitation Context: We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outper-forms competitive baselines and other neural language models. [URL_CITE]\nFootnote or Reference text (if exists): 1 The dataset and word vectors can be downloaded at http://ai.stanford.edu/ \u223c ehhuang/.\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE:  DataSource \nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://ibm.biz/acl21-loa\nCitation Context: Our LOA also provides open-sourced implementation in Python for the reinforce-ment learning environment to facilitate an ex-periment for studying neuro-symbolic agents. Demo site: [URL_CITE] https://ibm.biz/acl21-loa, Code: https://github.com/ibm/loa\nFootnote or Reference text (if exists): nan\nSection Titles (if exists):  ['References']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://wit3.fbk.eu/\nCitation Context: Datasets We evaluate our method on the IWSLT datasets which contain multiple languages from TED talks. We collect datasets from the IWSLT evaluation campaign [URL_CITE] from years 2011 to 2018, which consist of the translation pairs of 23 languages\u2194English. The detailed description of the training/validation/test set of the 23 transla-tion pairs can be found in Supplementary Mate-rials (Section 1).\nFootnote or Reference text (if exists): 6 https://wit3.fbk.eu/\nSection Titles (if exists):  ['4 Experiment Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://demos.explosion.ai/\nCitation Context: Figure 1 was generated from (Podgursky, 2015), which provides open-source code and a web interface for a static rendering of a con-stituency parse. There are a number of libraries (Stenetorp et al., 2012; Montani, 2016 [URL_CITE] ; Athar, 2010; Yimam et al., 2013) that provide static ren-derings of dependency parses similar to Figure 1 (bottom). Among these, Brat (Stenetorp et al., 2012) provides some interactive elements (like mouseover highlighting of subtrees, and the abil-ity to add dependencies via drag-and-drop).\nFootnote or Reference text (if exists): Ines Montani. 2016. Displacy dependency vi-sualizer. https://demos.explosion.ai/displacy. Accessed: 2017-04-27.\nSection Titles (if exists):  ['2 Related Work']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://slack.com\nCitation Context: Online conversations are increasingly significant for communication, e.g., Slack [URL_CITE] for work com-munication and Reddit for general discussion. To organize overwhelming information from these conversations, researchers have been working on summarizing online conversations (Bhatia et al., 2014; Carenini et al., 2007; Mehdad et al., 2013, 2014; Oya et al., 2014).\nFootnote or Reference text (if exists): 1 https://slack.com\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Introduce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Extend"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.jhu.edu/~ozaidan/AOC\nCitation Context: We ran five experiments to test the effect of MSA to CEA conversion on POS tagging: (a) Standard, where we train the tagger on the ATB MSA data, (b) 3-gram LM, where for each MSA sentence we generate all transformed sentences (see Section 2.1 and Figure 1) and pick the most probable sentence according to a trigram language model built from an 11.5 million words of user contributed comments. [URL_CITE] This corpus is highly dialectal\nFootnote or Reference text (if exists): 1 Available from http://www.cs.jhu.edu/~ozaidan/AOC\nSection Titles (if exists):  ['3.2. Experiments and Results']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.biography.com/search/index.jsp\nCitation Context: We download from infoplease.com and biogra-phy.com [URL_CITE] two corpora of people\u2019s biographies, which include 24,975 and 24,345 bios respectively. We scan each whole corpus and extract people having spouse information.\nFootnote or Reference text (if exists): 3 http://www.biography.com/search/index.jsp\nSection Titles (if exists):  ['4 Experiments and Results', '4.1 Experimental Setup']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/tuhinjubcse/SimileGeneration-EMNLP2020\nCitation Context: To the best of our knowledge, this is the first work in attempting to generate simi-les. By framing the task as a style-transfer problem we make three contributions: [URL_CITE]\nFootnote or Reference text (if exists): 4 Code & Data at https://github.com/tuhinjubcse/SimileGeneration-EMNLP2020\nSection Titles (if exists):  ['1 Introduction']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Produce"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://github.com/thunlp/Fast-TransX\nCitation Context: In fact, we often rely on simple personal computers for model validation. Hence, we enable OpenKE to adapt models for parallel learning on CPU [URL_CITE] be-sides employing GPU learning, which allow users to make full use of all available computing re-sources. The parallel learning method is shown in Algorithm 1.\nFootnote or Reference text (if exists): 2 https://github.com/thunlp/Fast-TransX\nSection Titles (if exists):  ['4 Implementations', '4.2 Parallel Learning']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://ifttt.com/\nCitation Context: If the condition is satisfied, the required processing con-sists of calling the execution of actions grounded in the effectors. Giving a conversational assistant the capacity to learn rules verbally opens the pos-sibility of teaching more complex and personal-ized rules, especially compared to visual program-ming tools such as IFTTT and Zapier [URL_CITE] . LIA can ask questions if it cannot parse specifics parts of a user-statement (e.g., if it cannot understand the if-condition, see Figure 2 for an example).\nFootnote or Reference text (if exists): 1 https://ifttt.com/, https://zapier.com/\nSection Titles (if exists):  ['2 Core competencies', '2.1 Learning Procedures']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Compare \n\n\n"
                }
            ]
        }
    ],
    [
        {
            "generated_text": [
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.pitt.edu/mpqa/\nCitation Context: To evaluate the effectiveness of SDRN, we conduct extensive experiments on five benchmark datasets from SemEval 2014 (Pontiki et al., 2014), Se-mEval 2015 (Pontiki et al., 2015), MPQA ver-sion 2.0 corpus [URL_CITE] (Wiebe et al., 2005), and J.D. Power and Associates Sentiment Corpora (JDPA) (Kessler et al., 2010).\nFootnote or Reference text (if exists): 6 http://www.cs.pitt.edu/mpqa/\nSection Titles (if exists):  ['4 Experiments', '4.1 Datasets']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Dataset\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Your task is to classify the type of artifact (TYPE) reffered to the URL and the citation reason (FUNCTION). I will provide you with a URL and citation context, section titles.\n\nHere is the classification schema for the artifact type:\n1. Tool: toolkit, software, system\n2. Code: codebase, library, API\n3. Dataset: corpus, image, sets\n4. Knowledge: lexicon, knowledge graph\n5. DataSource: source data for the Dataset/Knowledge\n6. Document: specifications, guidelines\n7. Paper: scholarly papers\n8. Media: games, music, videos\n9. Website: services, homepages\n10. Mixed: citations referring to multiple resources\n    \nHere is the classification schema for the citation reason:\n1. Use: Used in the citing paper\u2019s research\n2. Produce: First produced or released by the citing paper\u2019s research\n3. Compare: Compared with other resources\n4. Extend: Used in the citing paper\u2019s research but are improved, upgraded, or changed during the research\n5. Introduce: The resources or the related information\n6. Other: The URL citation does not belong to the above categories\nPlease classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  https://huggingface.co/transformers/\nCitation Context: We compare the above-proposed curricula (CWA, Skip\u2013fact) against a baseline curriculum (Original) where we initialize the verification models with standard pretrained BERT weights (bert-base-cased). We use huggingface transform-ers (Wolf et al., 2019) in all of our experiments. [URL_CITE]\nFootnote or Reference text (if exists): 7 https://huggingface.co/transformers/\nSection Titles (if exists):  ['2 Constrained Verification', '2.3 Methodology', 'Taker datasets following Clark et al. (2020).']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://nlp.stanford.edu/projects/glove/\nCitation Context: We use as word representation the concatena-tion of word vectors initialized to GloVe [URL_CITE] (Pen-nington et al., 2014), and randomly initialized pre-fix and suffix vectors of the length 1 to 4, which is inspired by Lewis et al. (2016). All affixes ap-pearing less than two times in the training data are mapped to \u201cUNK\u201d.\nFootnote or Reference text (if exists): 8 http://nlp.stanford.edu/projects/glove/\nSection Titles (if exists):  ['6 Experiments', '6.1 English Experimental Settings']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Code\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.ted.com/translate/\nCitation Context: Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators. To give just a few ex-ample: there are vibrant communities that concern themselves with the translation of Wikipedia arti-cles (Kumaran et al., 2008), open source software documentation, movie subtitles, and even material such as the TED conference talks. [URL_CITE]\nFootnote or Reference text (if exists): 7 http://www.ted.com/translate/\nSection Titles (if exists):  ['2 Human Translation', '2.2 Translation Skills']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Website\nFUNCTION: Use"
                },
                {
                    "role": "user",
                    "content": "Please classify the artifact type and the citation reason for the following URL and citation sentence.\nURL:  http://www.cs.cornell.edu/~rs/sfour/\nCitation Context: \u2022 SFOUR: SFOUR is a structured prediction approach that trains an end-to-end system with a large-margin method to optimize a convex relaxation of ROUGE (Sipos et al., 2012). We use the publicly available imple-mentation. [URL_CITE]\nFootnote or Reference text (if exists): 6 http://www.cs.cornell.edu/\u02dcrs/sfour/\nSection Titles (if exists):  ['4 Evaluation', '4.3 End-to-End Evaluation']"
                },
                {
                    "role": "assistant",
                    "content": "TYPE: Tool\nFUNCTION: Use \n\n\n"
                }
            ]
        }
    ]
]